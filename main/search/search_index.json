{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p><code>aresilient</code> is a Python library that provides resilient HTTP request functionality with automatic retry logic and exponential backoff. Built on top of the modern httpx library, it simplifies handling transient failures in HTTP communications, making your applications more robust and fault-tolerant.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Automatic Retry Logic: Automatically retries failed requests for configurable HTTP status   codes (429, 500, 502, 503, 504 by default)</li> <li>Multiple Backoff Strategies: Choose from Exponential (default), Linear, Fibonacci, or Constant   backoff, or implement your own custom strategy</li> <li>Optional Jitter: Add randomized jitter to prevent thundering herd problems and avoid   overwhelming servers</li> <li>Retry-After Header Support: Respects server-specified retry delays from <code>Retry-After</code> headers   (supports both integer seconds and HTTP-date formats)</li> <li>Circuit Breaker Pattern: Prevent cascading failures with built-in circuit breaker support   (CLOSED, OPEN, HALF_OPEN states)</li> <li>Context Manager API: Manage multiple requests with shared configuration using ResilientClient   and AsyncResilientClient</li> <li>Complete HTTP Method Support: Supports all common HTTP methods (GET, POST, PUT, DELETE, PATCH,   HEAD, OPTIONS)</li> <li>Full Async Support: Fully supports asynchronous requests for high-performance applications</li> <li>Built on httpx: Leverages the modern, async-capable httpx library</li> <li>Advanced Configuration: Customize timeout, retry attempts, backoff strategies, jitter,   retryable   status codes, max total time, and max wait time</li> <li>Custom Retry Predicates: Define custom logic for retry decisions based on response content,   headers, or business rules using the <code>retry_if</code> parameter</li> <li>Callbacks for Observability: Built-in callback system for logging, metrics, and alerting   (on_request, on_retry, on_success, on_failure)</li> <li>Type-Safe: Fully typed with comprehensive type hints</li> <li>Well-Tested: Extensive test coverage ensuring reliability</li> </ul>"},{"location":"#quick-examples","title":"Quick Examples","text":""},{"location":"#basic-get-request","title":"Basic GET Request","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n# Simple GET request with automatic retry\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\nprint(response.json())\n</code></pre>"},{"location":"#basic-post-request","title":"Basic POST Request","text":"<pre><code>from aresilient import post_with_automatic_retry\n\n# POST request with JSON payload\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\", json={\"key\": \"value\"}\n)\nprint(response.status_code)\n</code></pre>"},{"location":"#customizing-retry-behavior","title":"Customizing Retry Behavior","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n# Custom retry configuration\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=5,  # Retry up to 5 times\n    backoff_factor=1.0,  # Exponential backoff factor\n    timeout=30.0,  # 30 second timeout\n    status_forcelist=(429, 503),  # Only retry on these status codes\n)\n</code></pre>"},{"location":"#using-different-backoff-strategies","title":"Using Different Backoff Strategies","text":"<pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import FibonacciBackoff, LinearBackoff\n\n# Linear backoff (1s, 2s, 3s, 4s...)\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=LinearBackoff(base_delay=1.0, max_delay=10.0),\n)\n\n# Fibonacci backoff (1s, 1s, 2s, 3s, 5s, 8s...)\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=FibonacciBackoff(base_delay=1.0, max_delay=10.0),\n)\n</code></pre>"},{"location":"#using-context-manager-for-multiple-requests","title":"Using Context Manager for Multiple Requests","text":"<pre><code>from aresilient import ResilientClient\n\n# Manage multiple requests with shared configuration\nwith ResilientClient(max_retries=5, timeout=30.0) as client:\n    response1 = client.get(\"https://api.example.com/users\")\n    response2 = client.post(\"https://api.example.com/data\", json={\"key\": \"value\"})\n    response3 = client.put(\n        \"https://api.example.com/resource/123\", json={\"status\": \"active\"}\n    )\n</code></pre>"},{"location":"#using-circuit-breaker","title":"Using Circuit Breaker","text":"<pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.circuit_breaker import CircuitBreaker\n\n# Prevent cascading failures with circuit breaker\ncircuit_breaker = CircuitBreaker(\n    failure_threshold=5,  # Open circuit after 5 consecutive failures\n    recovery_timeout=60.0,  # Try again after 60 seconds\n)\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    circuit_breaker=circuit_breaker,\n)\n</code></pre>"},{"location":"#using-async","title":"Using Async","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n\n\n# Run the async function\ndata = asyncio.run(fetch_data())\nprint(data)\n</code></pre>"},{"location":"#async-with-multiple-requests","title":"Async with Multiple Requests","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_multiple():\n    urls = [\n        \"https://api.example.com/data1\",\n        \"https://api.example.com/data2\",\n        \"https://api.example.com/data3\",\n    ]\n    tasks = [get_with_automatic_retry_async(url) for url in urls]\n    responses = await asyncio.gather(*tasks)\n    return [r.json() for r in responses]\n\n\n# Fetch multiple URLs concurrently\nresults = asyncio.run(fetch_multiple())\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>Install using <code>uv</code> (recommended):</p> <pre><code>uv pip install aresilient\n</code></pre> <p>Or using <code>pip</code>:</p> <pre><code>pip install aresilient\n</code></pre>"},{"location":"#api-stability","title":"API stability","text":"<p> While <code>aresilient</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>aresilient</code> to a new version will possibly break any code that was using the old version of <code>aresilient</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>aresilient</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p>"},{"location":"backoff_strategies/","title":"Backoff Strategies","text":"<p>This guide explains the different backoff strategies available in <code>aresilient</code> and how to use them to fine-tune retry behavior for your specific use case.</p>"},{"location":"backoff_strategies/#overview","title":"Overview","text":"<p>Backoff strategies determine how long to wait between retry attempts when a request fails. Choosing the right strategy can significantly improve the resilience and efficiency of your application when dealing with transient failures or rate-limited APIs.</p>"},{"location":"backoff_strategies/#available-strategies","title":"Available Strategies","text":""},{"location":"backoff_strategies/#exponential-backoff-default","title":"Exponential Backoff (Default)","text":"<p>Exponential backoff doubles the delay with each retry attempt. This is the default strategy and works well for most scenarios where you want progressively longer delays between retries.</p> <p>Formula: <code>base_delay * (2 ** attempt)</code></p> <p>When to use:</p> <ul> <li>Most general-purpose retry scenarios</li> <li>Services that need time to recover from failures</li> <li>Preventing overwhelming a struggling service</li> </ul> <p>Example:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import ExponentialBackoff\n\n# Explicit exponential backoff with max delay cap\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ExponentialBackoff(base_delay=0.5, max_delay=10.0),\n)\n# Delays: 0.5s, 1s, 2s, 4s, 8s, 10s (capped), 10s (capped)...\n</code></pre> <p>Default behavior (when no <code>backoff_strategy</code> is specified):</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Uses exponential backoff with backoff_factor\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_factor=0.3,  # Equivalent to ExponentialBackoff(base_delay=0.3)\n)\n# Delays: 0.3s, 0.6s, 1.2s, 2.4s...\n</code></pre>"},{"location":"backoff_strategies/#linear-backoff","title":"Linear Backoff","text":"<p>Linear backoff provides evenly spaced retry delays, increasing linearly with each attempt. This is useful for services with predictable recovery times.</p> <p>Formula: <code>base_delay * (attempt + 1)</code></p> <p>When to use:</p> <ul> <li>Services that recover quickly and predictably</li> <li>Testing scenarios where you want consistent delays</li> <li>APIs with linear rate limit recovery</li> </ul> <p>Example:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import LinearBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=LinearBackoff(base_delay=1.0),\n)\n# Delays: 1s, 2s, 3s, 4s, 5s...\n\n# With max_delay cap\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=LinearBackoff(base_delay=2.0, max_delay=8.0),\n)\n# Delays: 2s, 4s, 6s, 8s (capped), 8s (capped)...\n</code></pre>"},{"location":"backoff_strategies/#fibonacci-backoff","title":"Fibonacci Backoff","text":"<p>Fibonacci backoff provides a middle ground between linear and exponential backoff, with delays following the Fibonacci sequence. This provides a more gradual increase than exponential backoff.</p> <p>Formula: <code>base_delay * fibonacci(attempt + 1)</code></p> <p>When to use:</p> <ul> <li>When exponential backoff is too aggressive</li> <li>Services that need gradual recovery time</li> <li>Balancing between quick retries and giving services time to recover</li> </ul> <p>Example:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import FibonacciBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=FibonacciBackoff(base_delay=1.0),\n)\n# Delays: 1s, 1s, 2s, 3s, 5s, 8s, 13s...\n\n# With max_delay cap\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=FibonacciBackoff(base_delay=1.0, max_delay=10.0),\n)\n# Delays: 1s, 1s, 2s, 3s, 5s, 8s, 10s (capped)...\n</code></pre>"},{"location":"backoff_strategies/#constant-backoff","title":"Constant Backoff","text":"<p>Constant backoff uses a fixed delay for all retry attempts, regardless of the attempt number. This is useful for testing or when you know the exact delay that works best.</p> <p>Formula: <code>delay</code> (constant)</p> <p>When to use:</p> <ul> <li>Testing and debugging scenarios</li> <li>APIs with specific retry delay requirements</li> <li>Situations where you know the optimal wait time</li> </ul> <p>Example:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import ConstantBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ConstantBackoff(delay=2.5),\n)\n# Delays: 2.5s, 2.5s, 2.5s, 2.5s...\n</code></pre>"},{"location":"backoff_strategies/#custom-backoff-strategy","title":"Custom Backoff Strategy","text":"<p>You can implement your own backoff strategy by subclassing <code>BackoffStrategy</code> and implementing the <code>calculate()</code> method:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import BackoffStrategy\n\n\nclass SquareBackoff(BackoffStrategy):\n    \"\"\"Custom backoff using square of attempt number.\"\"\"\n\n    def __init__(self, base_delay: float = 1.0):\n        self.base_delay = base_delay\n\n    def calculate(self, attempt: int) -&gt; float:\n        \"\"\"Calculate delay as square of (attempt + 1).\"\"\"\n        return self.base_delay * ((attempt + 1) ** 2)\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=SquareBackoff(base_delay=0.5),\n)\n# Delays: 0.5s, 2s, 4.5s, 8s, 12.5s...\n</code></pre>"},{"location":"backoff_strategies/#using-backoff-strategies-with-jitter","title":"Using Backoff Strategies with Jitter","text":"<p>Jitter adds randomization to backoff delays to prevent the \"thundering herd\" problem where multiple clients retry simultaneously. Jitter works with all backoff strategies:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import LinearBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=LinearBackoff(base_delay=1.0),\n    jitter_factor=0.1,  # Add up to 10% random jitter\n)\n# Delays: 1.0-1.1s, 2.0-2.2s, 3.0-3.3s...\n</code></pre>"},{"location":"backoff_strategies/#retry-after-header-support","title":"Retry-After Header Support","text":"<p>When a server returns a <code>Retry-After</code> header (commonly with 429 or 503 status codes), the library automatically uses the server's suggested wait time instead of the configured backoff strategy. This ensures compliance with server requirements:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import ExponentialBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ExponentialBackoff(base_delay=1.0),\n)\n# If server returns \"Retry-After: 60\", waits 60 seconds\n# Otherwise uses the configured strategy\n</code></pre>"},{"location":"backoff_strategies/#max-delay-cap","title":"Max Delay Cap","text":"<p>Most strategies support an optional <code>max_delay</code> parameter to prevent extremely long waits:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.backoff import ExponentialBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ExponentialBackoff(base_delay=1.0, max_delay=30.0),\n    max_retries=10,\n)\n# Delays won't exceed 30 seconds, even with many retries\n</code></pre>"},{"location":"backoff_strategies/#comparison-of-strategies","title":"Comparison of Strategies","text":"<p>Here's how different strategies compare for the first 6 retry attempts (with <code>base_delay=1.0</code>):</p> Attempt Exponential Linear Fibonacci Constant 1 1s 1s 1s 1s 2 2s 2s 1s 1s 3 4s 3s 2s 1s 4 8s 4s 3s 1s 5 16s 5s 5s 1s 6 32s 6s 8s 1s"},{"location":"backoff_strategies/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use exponential backoff by default - It works well for most scenarios and prevents    overwhelming failing services.</p> </li> <li> <p>Add jitter in production - Set <code>jitter_factor=0.1</code> to prevent thundering herd issues when    multiple clients retry simultaneously.</p> </li> <li> <p>Set max_delay caps - Prevent extremely long waits by setting a reasonable <code>max_delay</code>,    especially with exponential or Fibonacci backoff.</p> </li> <li> <p>Respect Retry-After headers - The library automatically honors these, but be aware that they    take precedence over your configured strategy.</p> </li> <li> <p>Choose strategy based on service behavior:</p> <ul> <li>Exponential: Services that need increasing recovery time</li> <li>Linear: Services with predictable recovery patterns</li> <li>Fibonacci: When you want gradual increase without exponential growth</li> <li>Constant: Testing or APIs with specific requirements</li> </ul> </li> <li> <p>Test your strategy - Use different strategies in staging to find what works best for your    specific API.</p> </li> </ol>"},{"location":"backoff_strategies/#async-support","title":"Async Support","text":"<p>All backoff strategies work identically with async functions:</p> <pre><code>from aresilient import get_with_automatic_retry_async\nfrom aresilient.backoff import FibonacciBackoff\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\n        \"https://api.example.com/data\",\n        backoff_strategy=FibonacciBackoff(base_delay=1.0, max_delay=10.0),\n    )\n    return response.json()\n</code></pre>"},{"location":"backoff_strategies/#using-with-context-managers","title":"Using with Context Managers","text":"<p>Backoff strategies work seamlessly with <code>ResilientClient</code> and <code>AsyncResilientClient</code>:</p> <pre><code>from aresilient import ResilientClient\nfrom aresilient.backoff import ConstantBackoff, LinearBackoff\n\n# All requests in the context use the same backoff strategy\nwith ResilientClient(\n    backoff_strategy=LinearBackoff(base_delay=1.0, max_delay=8.0),\n    max_retries=5,\n) as client:\n    response1 = client.get(\"https://api.example.com/data1\")\n    response2 = client.post(\"https://api.example.com/data2\", json={\"key\": \"value\"})\n\n    # Override strategy for a specific request\n    response3 = client.get(\n        \"https://api.example.com/data3\",\n        backoff_strategy=ConstantBackoff(delay=2.0),\n    )\n</code></pre> <p>Async context manager example:</p> <pre><code>import asyncio\n\nfrom aresilient import AsyncResilientClient\nfrom aresilient.backoff import ExponentialBackoff\n\n\nasync def fetch_all():\n    async with AsyncResilientClient(\n        backoff_strategy=ExponentialBackoff(base_delay=0.5, max_delay=15.0),\n        max_retries=3,\n    ) as client:\n        results = await asyncio.gather(\n            client.get(\"https://api.example.com/data1\"),\n            client.get(\"https://api.example.com/data2\"),\n            client.get(\"https://api.example.com/data3\"),\n        )\n        return [r.json() for r in results]\n</code></pre>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-uv-recommended","title":"Installing with <code>uv</code> (recommended)","text":"<p>The following command installs the latest stable version of the library:</p> <pre><code>uv pip install aresilient\n</code></pre> <p>To install the latest development version from GitHub:</p> <pre><code>uv pip install git+https://github.com/durandtibo/aresilient.git\n</code></pre> <p>To install a specific version:</p> <pre><code>uv pip install aresilient==0.3.0\n</code></pre>"},{"location":"get_started/#installing-with-pip","title":"Installing with <code>pip</code>","text":"<p>The following command installs the latest stable version of the library:</p> <pre><code>pip install aresilient\n</code></pre> <p>To install the latest development version from GitHub:</p> <pre><code>pip install git+https://github.com/durandtibo/aresilient.git\n</code></pre> <p>To install a specific version:</p> <pre><code>pip install aresilient==0.3.0\n</code></pre>"},{"location":"get_started/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, you can verify that aresilient is correctly installed by running:</p> <pre><code>python -c \"import aresilient; print(aresilient.__version__)\"\n</code></pre> <p>Or try a simple example:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Make a simple GET request (this is a safe example that won't actually execute)\n# response = get_with_automatic_retry(\"https://api.example.com/data\")\n# print(response.json())\n\n# Verify the module is properly imported\nprint(\"aresilient imported successfully!\")\n</code></pre>"},{"location":"get_started/#testing-async-support","title":"Testing Async Support","text":"<p>To verify async support is working:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def test_async():\n    print(\"Async support is working!\")\n    return True\n\n\nresult = asyncio.run(test_async())\nprint(f\"Test result: {result}\")\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>aresilient</code> from source, you can follow the steps below.</p>"},{"location":"get_started/#prerequisites","title":"Prerequisites","text":"<p>This project uses <code>uv</code> for dependency management. Please refer to the uv installation documentation for installation instructions.</p>"},{"location":"get_started/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone git@github.com:durandtibo/aresilient.git\ncd aresilient\n</code></pre>"},{"location":"get_started/#create-a-virtual-environment","title":"Create a Virtual Environment","text":"<p>It is recommended to create a Python 3.10+ virtual environment:</p> <pre><code>make setup-venv\n</code></pre> <p>This command creates a virtual environment using <code>uv</code> and installs all dependencies including development tools.</p> <p>Alternatively, you can create a conda virtual environment:</p> <pre><code>make conda\nconda activate aresilient\nmake install\n</code></pre>"},{"location":"get_started/#install-dependencies","title":"Install Dependencies","text":"<p>To install only the core dependencies:</p> <pre><code>make install\n</code></pre> <p>To install all dependencies including documentation tools:</p> <pre><code>make install-all\n</code></pre>"},{"location":"get_started/#verify-installation","title":"Verify Installation","text":"<p>You can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre> <p>This will run the test suite with coverage reporting.</p>"},{"location":"get_started/#development-setup","title":"Development Setup","text":"<p>If you plan to contribute to aresilient, please also install the development tools.</p> <p>Using <code>uv</code>:</p> <pre><code>uv pip install -e \".[dev,docs]\"\n</code></pre> <p>Using <code>pip</code>:</p> <pre><code>pip install -e \".[dev,docs]\"\n</code></pre> <p>Then install the pre-commit hooks:</p> <pre><code>pre-commit install\n</code></pre> <p>See CONTRIBUTING.md for more information about contributing.</p>"},{"location":"user_guide/","title":"User Guide","text":"<p>This guide provides comprehensive instructions on how to use <code>aresilient</code> for making resilient HTTP requests with automatic retry logic.</p>"},{"location":"user_guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Basic Usage</li> <li>Async Usage</li> <li>Configuration Options</li> <li>Context Manager API</li> <li>Advanced Usage</li> <li>Circuit Breaker Pattern</li> <li>Custom Retry Predicates</li> <li>Callbacks and Observability</li> <li>Error Handling</li> <li>Custom HTTP Methods</li> <li>Best Practices</li> </ul>"},{"location":"user_guide/#basic-usage","title":"Basic Usage","text":""},{"location":"user_guide/#making-get-requests","title":"Making GET Requests","text":"<p>The simplest way to make an HTTP GET request with automatic retry:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Basic GET request\nresponse = get_with_automatic_retry(\"https://api.example.com/users\")\nprint(response.json())\n</code></pre>"},{"location":"user_guide/#making-post-requests","title":"Making POST Requests","text":"<p>POST requests work similarly with support for JSON payloads and form data:</p> <pre><code>from aresilient import post_with_automatic_retry\n\n# POST with JSON payload\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/users\",\n    json={\"name\": \"John Doe\", \"email\": \"john@example.com\"},\n)\nprint(response.status_code)\n\n# POST with form data\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\", data={\"field1\": \"value1\", \"field2\": \"value2\"}\n)\n</code></pre>"},{"location":"user_guide/#other-http-methods","title":"Other HTTP Methods","text":"<p><code>aresilient</code> supports all common HTTP methods:</p> <pre><code>from aresilient import (\n    put_with_automatic_retry,\n    delete_with_automatic_retry,\n    patch_with_automatic_retry,\n)\n\n# PUT request to update a resource\nresponse = put_with_automatic_retry(\n    \"https://api.example.com/resource/123\", json={\"name\": \"updated\"}\n)\n\n# DELETE request to remove a resource\nresponse = delete_with_automatic_retry(\"https://api.example.com/resource/123\")\n\n# PATCH request to partially update a resource\nresponse = patch_with_automatic_retry(\n    \"https://api.example.com/resource/123\", json={\"status\": \"active\"}\n)\n</code></pre>"},{"location":"user_guide/#async-usage","title":"Async Usage","text":"<p><code>aresilient</code> provides asynchronous versions of all HTTP methods for use in async applications. All async functions have the same parameters as their synchronous counterparts.</p>"},{"location":"user_guide/#making-async-get-requests","title":"Making Async GET Requests","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n\n\n# Run the async function\ndata = asyncio.run(fetch_data())\nprint(data)\n</code></pre>"},{"location":"user_guide/#making-async-post-requests","title":"Making Async POST Requests","text":"<pre><code>import asyncio\nfrom aresilient import post_with_automatic_retry_async\n\n\nasync def create_user():\n    response = await post_with_automatic_retry_async(\n        \"https://api.example.com/users\",\n        json={\"name\": \"Jane Doe\", \"email\": \"jane@example.com\"},\n    )\n    return response.status_code\n\n\n# Run the async function\nstatus = asyncio.run(create_user())\nprint(f\"Status: {status}\")\n</code></pre>"},{"location":"user_guide/#other-async-http-methods","title":"Other Async HTTP Methods","text":"<p>All HTTP methods have async versions with identical parameters and callback support:</p> <pre><code>from aresilient import (\n    put_with_automatic_retry_async,\n    delete_with_automatic_retry_async,\n    patch_with_automatic_retry_async,\n    head_with_automatic_retry_async,\n    options_with_automatic_retry_async,\n)\n</code></pre> <p>Note: All async functions support the same parameters as their synchronous counterparts, including:</p> <ul> <li><code>max_retries</code>, <code>backoff_factor</code>, <code>jitter_factor</code></li> <li><code>status_forcelist</code>, <code>retry_if</code></li> <li><code>on_request</code>, <code>on_retry</code>, <code>on_success</code>, <code>on_failure</code> callbacks</li> </ul>"},{"location":"user_guide/#using-async-with-httpxasyncclient","title":"Using Async with httpx.AsyncClient","text":"<p>For better performance with multiple async requests, reuse an <code>httpx.AsyncClient</code>:</p> <pre><code>import asyncio\nimport httpx\nfrom aresilient import get_with_automatic_retry_async, post_with_automatic_retry_async\n\n\nasync def fetch_multiple_resources():\n    async with httpx.AsyncClient(timeout=30.0) as client:\n        # Make multiple concurrent requests\n        users_task = get_with_automatic_retry_async(\n            \"https://api.example.com/users\", client=client\n        )\n        posts_task = get_with_automatic_retry_async(\n            \"https://api.example.com/posts\", client=client\n        )\n\n        # Wait for both requests to complete\n        users, posts = await asyncio.gather(users_task, posts_task)\n\n        return users.json(), posts.json()\n\n\n# Run the async function\nusers_data, posts_data = asyncio.run(fetch_multiple_resources())\n</code></pre>"},{"location":"user_guide/#concurrent-async-requests","title":"Concurrent Async Requests","text":"<p>Process multiple URLs concurrently for better performance:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_all(urls):\n    tasks = [get_with_automatic_retry_async(url) for url in urls]\n    responses = await asyncio.gather(*tasks, return_exceptions=True)\n    return responses\n\n\n# Fetch multiple URLs concurrently\nurls = [\n    \"https://api.example.com/data1\",\n    \"https://api.example.com/data2\",\n    \"https://api.example.com/data3\",\n]\nresponses = asyncio.run(fetch_all(urls))\n</code></pre>"},{"location":"user_guide/#configuration-options","title":"Configuration Options","text":""},{"location":"user_guide/#default-configuration","title":"Default Configuration","text":"<p><code>aresilient</code> comes with sensible defaults:</p> <pre><code>from aresilient import (\n    DEFAULT_TIMEOUT,  # 10.0 seconds\n    DEFAULT_MAX_RETRIES,  # 3 retries (4 total attempts)\n    DEFAULT_BACKOFF_FACTOR,  # 0.3 seconds\n    RETRY_STATUS_CODES,  # (429, 500, 502, 503, 504)\n)\n\nprint(f\"Timeout: {DEFAULT_TIMEOUT}\")\nprint(f\"Max retries: {DEFAULT_MAX_RETRIES}\")\nprint(f\"Backoff factor: {DEFAULT_BACKOFF_FACTOR}\")\nprint(f\"Retry on status codes: {RETRY_STATUS_CODES}\")\n</code></pre>"},{"location":"user_guide/#customizing-timeout","title":"Customizing Timeout","text":"<p>Control how long to wait for a server response:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Short timeout for quick responses\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/health\", timeout=5.0  # 5 seconds\n)\n\n# Longer timeout for slow endpoints\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/slow-endpoint\", timeout=60.0  # 60 seconds\n)\n</code></pre> <p>You can also use httpx.Timeout for fine-grained control:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry\n\n# Different timeouts for different operations\ntimeout = httpx.Timeout(\n    connect=5.0,  # 5 seconds to establish connection\n    read=30.0,  # 30 seconds to read response\n    write=10.0,  # 10 seconds to send request\n    pool=5.0,  # 5 seconds to get connection from pool\n)\n\nresponse = get_with_automatic_retry(\"https://api.example.com/data\", timeout=timeout)\n</code></pre>"},{"location":"user_guide/#customizing-retry-behavior","title":"Customizing Retry Behavior","text":"<p>Control how many times and how long between retries:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# More aggressive retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=5,  # Retry up to 5 times\n    backoff_factor=0.5,  # Longer waits between retries\n)\n\n# Less aggressive retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=1,  # Only retry once\n    backoff_factor=0.1,  # Shorter waits between retries\n)\n\n# With jitter to prevent thundering herd\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=3,\n    backoff_factor=0.5,\n    jitter_factor=0.1,  # Add 10% random jitter\n)\n\n# No retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", max_retries=0  # No retries, fail immediately\n)\n</code></pre>"},{"location":"user_guide/#understanding-backoff-strategies","title":"Understanding Backoff Strategies","text":"<p><code>aresilient</code> supports multiple backoff strategies to control the wait time between retry attempts. By default, exponential backoff is used.</p>"},{"location":"user_guide/#exponential-backoff-default","title":"Exponential Backoff (Default)","text":"<p>The wait time between retries is calculated using the exponential backoff formula:</p> <pre><code>base_wait_time = backoff_factor * (2 ** attempt)\n# If jitter_factor is set (e.g., 0.1 for 10% jitter):\njitter = random(0, jitter_factor) * base_wait_time\ntotal_wait_time = base_wait_time + jitter\n</code></pre> <p>Where <code>attempt</code> is 0-indexed (0, 1, 2, ...).</p>"},{"location":"user_guide/#example-with-default-backoff_factor03-no-jitter","title":"Example with default <code>backoff_factor=0.3</code> (no jitter):","text":"<ul> <li>1st retry: 0.3 * (2^0) = 0.3 seconds</li> <li>2nd retry: 0.3 * (2^1) = 0.6 seconds</li> <li>3rd retry: 0.3 * (2^2) = 1.2 seconds</li> </ul>"},{"location":"user_guide/#example-with-backoff_factor10-and-jitter_factor01","title":"Example with <code>backoff_factor=1.0</code> and <code>jitter_factor=0.1</code>:","text":"<ul> <li>1st retry: 1.0-1.1 seconds (base 1.0s + up to 10% jitter)</li> <li>2nd retry: 2.0-2.2 seconds (base 2.0s + up to 10% jitter)</li> <li>3rd retry: 4.0-4.4 seconds (base 4.0s + up to 10% jitter)</li> </ul> <p>Note: Jitter is optional (disabled by default with <code>jitter_factor=0</code>). When enabled, it's randomized for each retry to prevent multiple clients from retrying simultaneously (thundering herd problem). Set <code>jitter_factor=0.1</code> for 10% jitter, which is recommended for production use.</p>"},{"location":"user_guide/#using-different-backoff-strategies","title":"Using Different Backoff Strategies","text":"<p>You can use alternative backoff strategies by providing a <code>backoff_strategy</code> parameter:</p> <pre><code>from aresilient import (\n    get_with_automatic_retry,\n    LinearBackoff,\n    FibonacciBackoff,\n    ConstantBackoff,\n    ExponentialBackoff,\n)\n\n# Linear backoff: 1s, 2s, 3s, 4s...\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=LinearBackoff(base_delay=1.0, max_delay=10.0),\n)\n\n# Fibonacci backoff: 1s, 1s, 2s, 3s, 5s, 8s...\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=FibonacciBackoff(base_delay=1.0, max_delay=10.0),\n)\n\n# Constant backoff: 2s, 2s, 2s, 2s...\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ConstantBackoff(delay=2.0),\n)\n\n# Explicit exponential backoff with custom settings\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ExponentialBackoff(base_delay=0.5, max_delay=30.0),\n)\n</code></pre> <p>See the Backoff Strategies guide for detailed information about each strategy and when to use them.</p>"},{"location":"user_guide/#customizing-retryable-status-codes","title":"Customizing Retryable Status Codes","text":"<p>By default, <code>aresilient</code> retries on status codes 429, 500, 502, 503, and 504. You can customize this:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Only retry on rate limiting\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", status_forcelist=(429,)\n)\n\n# Retry on server errors and rate limiting\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", status_forcelist=(429, 500, 502, 503, 504)\n)\n\n# Add custom status codes\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    status_forcelist=(408, 429, 500, 502, 503, 504),  # Include 408 Request Timeout\n)\n</code></pre>"},{"location":"user_guide/#retry-after-header-support","title":"Retry-After Header Support","text":"<p>When a server returns a <code>Retry-After</code> header (commonly with 429 or 503 status codes), <code>aresilient</code> automatically uses the server's suggested wait time instead of exponential backoff. This ensures compliance with rate limiting and helps avoid overwhelming the server.</p> <p>The <code>Retry-After</code> header supports two formats:</p> <pre><code># Server responds with: Retry-After: 120\n# aresilient will wait 120 seconds before retrying\n\n# Server responds with: Retry-After: Wed, 21 Oct 2015 07:28:00 GMT\n# aresilient will wait until this time before retrying\n</code></pre> <p>The retry delay from the <code>Retry-After</code> header is used automatically - you don't need to configure anything. This works with all HTTP methods (GET, POST, PUT, DELETE, PATCH).</p> <p>Note: If <code>jitter_factor</code> is configured, jitter is still applied to server-specified <code>Retry-After</code> values to prevent thundering herd issues when many clients receive the same retry delay from a server.</p>"},{"location":"user_guide/#max-total-time-and-max-wait-time","title":"Max Total Time and Max Wait Time","text":"<p>Control the total time budget and maximum wait time for retries:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Limit total time for all retry attempts\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=10,\n    max_total_time=30.0,  # Stop retrying after 30 seconds total\n)\n\n# Cap individual backoff delays\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=10,\n    backoff_factor=2.0,\n    max_wait_time=10.0,  # No single wait exceeds 10 seconds\n)\n\n# Combine both for strict SLA guarantees\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=10,\n    backoff_factor=2.0,\n    max_total_time=60.0,  # Total budget: 60 seconds\n    max_wait_time=15.0,  # Max wait between retries: 15 seconds\n)\n</code></pre> <p>max_total_time is useful when you have strict time budgets or SLA requirements. If the total elapsed time (including all request attempts and backoff delays) exceeds this value, the retry loop stops even if <code>max_retries</code> hasn't been reached.</p> <p>max_wait_time caps individual backoff delays. This is particularly useful with exponential backoff or when servers send very large <code>Retry-After</code> values. Without this cap, exponential backoff could lead to very long waits (e.g., 64s, 128s, 256s).</p>"},{"location":"user_guide/#context-manager-api","title":"Context Manager API","text":"<p>The <code>ResilientClient</code> and <code>AsyncResilientClient</code> classes provide a context manager interface for making multiple HTTP requests with shared retry configuration. This is more convenient and efficient than passing the same parameters to every function call.</p>"},{"location":"user_guide/#using-resilientclient-sync","title":"Using ResilientClient (Sync)","text":"<pre><code>from aresilient import ResilientClient\nfrom aresilient.backoff import LinearBackoff\n\n# Create a client with shared configuration\nwith ResilientClient(\n    max_retries=5,\n    timeout=30.0,\n    backoff_strategy=LinearBackoff(base_delay=1.0),\n    jitter_factor=0.1,\n) as client:\n    # All requests use the shared configuration\n    users = client.get(\"https://api.example.com/users\")\n\n    # Override configuration for specific requests\n    posts = client.get(\n        \"https://api.example.com/posts\",\n        max_retries=3,  # Override max_retries for this request\n    )\n\n    # POST request\n    result = client.post(\n        \"https://api.example.com/data\",\n        json={\"key\": \"value\"},\n    )\n\n    # PUT request\n    updated = client.put(\n        \"https://api.example.com/resource/123\",\n        json={\"status\": \"active\"},\n    )\n\n    # DELETE request\n    client.delete(\"https://api.example.com/resource/456\")\n</code></pre>"},{"location":"user_guide/#using-asyncresilientclient-async","title":"Using AsyncResilientClient (Async)","text":"<pre><code>import asyncio\n\nfrom aresilient import AsyncResilientClient\nfrom aresilient.backoff import ExponentialBackoff\n\n\nasync def fetch_all_data():\n    async with AsyncResilientClient(\n        max_retries=3,\n        timeout=20.0,\n        backoff_strategy=ExponentialBackoff(base_delay=0.5, max_delay=10.0),\n    ) as client:\n        # Concurrent async requests with shared configuration\n        users_task = client.get(\"https://api.example.com/users\")\n        posts_task = client.get(\"https://api.example.com/posts\")\n\n        users, posts = await asyncio.gather(users_task, posts_task)\n\n        # POST request\n        result = await client.post(\n            \"https://api.example.com/submit\",\n            json={\"data\": \"value\"},\n        )\n\n        return users.json(), posts.json(), result.json()\n\n\ndata = asyncio.run(fetch_all_data())\n</code></pre>"},{"location":"user_guide/#supported-methods-in-context-manager","title":"Supported Methods in Context Manager","text":"<p>Both <code>ResilientClient</code> and <code>AsyncResilientClient</code> support all HTTP methods:</p> <ul> <li><code>client.get(url, **kwargs)</code> - GET request</li> <li><code>client.post(url, **kwargs)</code> - POST request</li> <li><code>client.put(url, **kwargs)</code> - PUT request</li> <li><code>client.delete(url, **kwargs)</code> - DELETE request</li> <li><code>client.patch(url, **kwargs)</code> - PATCH request</li> <li><code>client.head(url, **kwargs)</code> - HEAD request</li> <li><code>client.options(url, **kwargs)</code> - OPTIONS request</li> <li><code>client.request(method, url, **kwargs)</code> - Custom method</li> </ul>"},{"location":"user_guide/#benefits-of-context-manager-api","title":"Benefits of Context Manager API","text":"<ol> <li>Code Reusability: Define retry configuration once, use for multiple requests</li> <li>Connection Pooling: The underlying httpx client is reused, improving performance</li> <li>Cleaner Code: Less repetition of configuration parameters</li> <li>Easy Override: Per-request overrides of the default configuration</li> <li>Resource Management: Automatic cleanup when exiting the context</li> </ol>"},{"location":"user_guide/#context-manager-with-callbacks","title":"Context Manager with Callbacks","text":"<pre><code>from aresilient import ResilientClient\n\n\ndef log_retry(info):\n    print(f\"Retrying {info.url} after {info.wait_time:.2f}s\")\n\n\ndef log_failure(info):\n    print(f\"Failed {info.url} after {info.attempt} attempts\")\n\n\nwith ResilientClient(\n    max_retries=3,\n    on_retry=log_retry,\n    on_failure=log_failure,\n) as client:\n    # All requests will use these callbacks\n    response1 = client.get(\"https://api.example.com/data1\")\n    response2 = client.get(\"https://api.example.com/data2\")\n</code></pre>"},{"location":"user_guide/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user_guide/#using-a-custom-httpx-client","title":"Using a Custom httpx Client","text":"<p>For advanced configurations like custom headers, authentication, or connection pooling:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry\n\n# Create a client with custom headers\nwith httpx.Client(\n    headers={\"User-Agent\": \"MyApp/1.0\", \"Authorization\": \"Bearer your-token-here\"}\n) as client:\n    response = get_with_automatic_retry(\n        \"https://api.example.com/protected\", client=client\n    )\n    print(response.json())\n</code></pre>"},{"location":"user_guide/#reusing-client-for-multiple-requests","title":"Reusing Client for Multiple Requests","text":"<p>When making multiple requests, reuse the same client for better performance:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry, post_with_automatic_retry\n\nwith httpx.Client(headers={\"Authorization\": \"Bearer token\"}, timeout=30.0) as client:\n    # Multiple requests using the same client\n    users = get_with_automatic_retry(\"https://api.example.com/users\", client=client)\n\n    posts = get_with_automatic_retry(\"https://api.example.com/posts\", client=client)\n\n    result = post_with_automatic_retry(\n        \"https://api.example.com/data\", client=client, json={\"data\": \"value\"}\n    )\n</code></pre>"},{"location":"user_guide/#passing-additional-httpx-arguments","title":"Passing Additional httpx Arguments","text":"<p>All <code>**kwargs</code> are passed directly to the underlying httpx methods:</p> <pre><code>from aresilient import get_with_automatic_retry, post_with_automatic_retry\n\n# GET with query parameters\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/search\", params={\"q\": \"python\", \"page\": 1}\n)\n\n# GET with custom headers (without custom client)\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", headers={\"X-Custom-Header\": \"value\"}\n)\n\n# POST with files\nwith open(\"document.pdf\", \"rb\") as f:\n    response = post_with_automatic_retry(\n        \"https://api.example.com/upload\", files={\"file\": f}\n    )\n\n# POST with both data and files\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\",\n    data={\"title\": \"My Document\"},\n    files={\"attachment\": open(\"file.txt\", \"rb\")},\n)\n</code></pre>"},{"location":"user_guide/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<p>The circuit breaker pattern prevents cascading failures by failing fast when a service is consistently unavailable. After a certain number of consecutive failures, the circuit \"opens\" and immediately rejects requests without attempting them, giving the failing service time to recover.</p>"},{"location":"user_guide/#understanding-circuit-states","title":"Understanding Circuit States","text":"<p>A circuit breaker has three states:</p> <ul> <li>CLOSED: Normal operation - requests are allowed through</li> <li>OPEN: After <code>failure_threshold</code> consecutive failures, the circuit opens and requests fail   immediately without being attempted</li> <li>HALF_OPEN: After <code>recovery_timeout</code> seconds in OPEN state, one test request is allowed   through to check if the service has recovered</li> </ul>"},{"location":"user_guide/#basic-circuit-breaker-usage","title":"Basic Circuit Breaker Usage","text":"<pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.circuit_breaker import CircuitBreaker\n\n# Create a circuit breaker\ncircuit_breaker = CircuitBreaker(\n    failure_threshold=5,  # Open after 5 consecutive failures\n    recovery_timeout=60.0,  # Try again after 60 seconds\n)\n\n# Use with requests\ntry:\n    response = get_with_automatic_retry(\n        \"https://api.example.com/data\",\n        circuit_breaker=circuit_breaker,\n    )\nexcept Exception as e:\n    print(f\"Request failed: {e}\")\n</code></pre>"},{"location":"user_guide/#how-circuit-breaker-works","title":"How Circuit Breaker Works","text":"<ol> <li>Initially CLOSED: All requests are attempted normally with retry logic</li> <li>After N consecutive failures: Circuit opens (state becomes OPEN)</li> <li>While OPEN: All requests fail immediately with <code>CircuitBreakerError</code>, no actual HTTP requests    are made</li> <li>After recovery_timeout: Circuit enters HALF_OPEN state</li> <li>In HALF_OPEN: One test request is attempted<ul> <li>If successful: Circuit closes (back to CLOSED state)</li> <li>If fails: Circuit reopens (back to OPEN state) for another recovery_timeout period</li> </ul> </li> </ol>"},{"location":"user_guide/#circuit-breaker-with-multiple-endpoints","title":"Circuit Breaker with Multiple Endpoints","text":"<p>Share a circuit breaker across multiple endpoints:</p> <pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.circuit_breaker import CircuitBreaker\n\n# Shared circuit breaker for API service\napi_circuit = CircuitBreaker(failure_threshold=3, recovery_timeout=30.0)\n\n# All requests to this API share the circuit breaker\nresponse1 = get_with_automatic_retry(\n    \"https://api.example.com/users\",\n    circuit_breaker=api_circuit,\n)\n\nresponse2 = get_with_automatic_retry(\n    \"https://api.example.com/posts\",\n    circuit_breaker=api_circuit,\n)\n</code></pre>"},{"location":"user_guide/#circuit-breaker-with-context-manager","title":"Circuit Breaker with Context Manager","text":"<pre><code>from aresilient import ResilientClient\nfrom aresilient.circuit_breaker import CircuitBreaker\n\n# Create circuit breaker\ncircuit = CircuitBreaker(failure_threshold=5, recovery_timeout=60.0)\n\n# Use with ResilientClient\nwith ResilientClient(\n    max_retries=3,\n    circuit_breaker=circuit,\n) as client:\n    # All requests share the circuit breaker\n    response1 = client.get(\"https://api.example.com/data1\")\n    response2 = client.get(\"https://api.example.com/data2\")\n</code></pre>"},{"location":"user_guide/#handling-circuit-breaker-errors","title":"Handling Circuit Breaker Errors","text":"<pre><code>from aresilient import get_with_automatic_retry\nfrom aresilient.circuit_breaker import CircuitBreaker, CircuitBreakerError\n\ncircuit = CircuitBreaker(failure_threshold=3, recovery_timeout=30.0)\n\ntry:\n    response = get_with_automatic_retry(\n        \"https://api.example.com/data\",\n        circuit_breaker=circuit,\n    )\nexcept CircuitBreakerError as e:\n    print(f\"Circuit breaker is open: {e}\")\n    # Service is down, use fallback or cached data\nexcept Exception as e:\n    print(f\"Other error: {e}\")\n</code></pre>"},{"location":"user_guide/#monitoring-circuit-state","title":"Monitoring Circuit State","text":"<pre><code>from aresilient.circuit_breaker import CircuitBreaker, CircuitState\n\ncircuit = CircuitBreaker(failure_threshold=5, recovery_timeout=60.0)\n\n# Check circuit state\nif circuit.state == CircuitState.OPEN:\n    print(\"Circuit is open - service is down\")\nelif circuit.state == CircuitState.CLOSED:\n    print(\"Circuit is closed - service is healthy\")\nelif circuit.state == CircuitState.HALF_OPEN:\n    print(\"Circuit is half-open - testing recovery\")\n\n# Access circuit metrics\nprint(f\"Consecutive failures: {circuit.failure_count}\")\n</code></pre>"},{"location":"user_guide/#when-to-use-circuit-breakers","title":"When to Use Circuit Breakers","text":"<p>Circuit breakers are most useful when:</p> <ol> <li>Calling external services: Protect your application from external service outages</li> <li>Microservices architecture: Prevent cascading failures across services</li> <li>Rate-limited APIs: Avoid wasting attempts when you're blocked</li> <li>Expensive operations: Save resources by not attempting doomed requests</li> <li>User-facing applications: Fail fast and provide better user experience</li> </ol>"},{"location":"user_guide/#circuit-breaker-best-practices","title":"Circuit Breaker Best Practices","text":"<ol> <li>Tune thresholds carefully: Set <code>failure_threshold</code> based on expected failure patterns</li> <li>Appropriate recovery time: Set <code>recovery_timeout</code> long enough for services to recover</li> <li>Monitor circuit state: Log state transitions for observability</li> <li>Use with callbacks: Combine with <code>on_failure</code> callbacks to track circuit opens</li> <li>Share circuits wisely: Share circuit breakers for the same backend service, separate for    different services</li> </ol>"},{"location":"user_guide/#custom-retry-predicates","title":"Custom Retry Predicates","text":"<p>The <code>retry_if</code> parameter allows you to define custom logic for determining whether a request should be retried based on the response content, headers, or business logic. This is more powerful than <code>status_forcelist</code> alone.</p>"},{"location":"user_guide/#basic-retry-predicate","title":"Basic Retry Predicate","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n\ndef should_retry(response, exception):\n    \"\"\"Custom retry logic.\n\n    Args:\n        response: httpx.Response or None if exception occurred\n        exception: Exception or None if request succeeded\n\n    Returns:\n        True to retry, False to not retry\n    \"\"\"\n    # Retry on exceptions\n    if exception:\n        return True\n\n    # Retry on specific status codes\n    if response.status_code in (429, 500, 502, 503, 504):\n        return True\n\n    # Don't retry on success\n    return False\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    retry_if=should_retry,\n)\n</code></pre>"},{"location":"user_guide/#retry-based-on-response-content","title":"Retry Based on Response Content","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n\ndef retry_on_error_field(response, exception):\n    \"\"\"Retry if response contains an error field.\"\"\"\n    # Always retry on exceptions\n    if exception:\n        return True\n\n    # Don't retry on client errors (4xx except 429)\n    if 400 &lt;= response.status_code &lt; 500 and response.status_code != 429:\n        return False\n\n    # Retry on server errors\n    if response.status_code &gt;= 500:\n        return True\n\n    # Check response body for application-level errors\n    try:\n        data = response.json()\n        # Retry if API returned an error in the response\n        if data.get(\"error\") == \"temporary_unavailable\":\n            return True\n    except Exception:\n        pass  # Can't parse JSON, use status code logic\n\n    return False\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    retry_if=retry_on_error_field,\n    max_retries=5,\n)\n</code></pre>"},{"location":"user_guide/#retry-based-on-response-headers","title":"Retry Based on Response Headers","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n\ndef retry_on_header(response, exception):\n    \"\"\"Retry based on custom response headers.\"\"\"\n    if exception:\n        return True\n\n    # Retry if server indicates the operation is still processing\n    if response.headers.get(\"X-Processing\") == \"true\":\n        return True\n\n    # Retry on rate limit\n    if response.status_code == 429:\n        return True\n\n    # Retry on server errors\n    if response.status_code &gt;= 500:\n        return True\n\n    return False\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/long-running-task\",\n    retry_if=retry_on_header,\n    max_retries=10,\n)\n</code></pre>"},{"location":"user_guide/#complex-business-logic","title":"Complex Business Logic","text":"<pre><code>from aresilient import post_with_automatic_retry\nimport httpx\n\n\ndef complex_retry_logic(response, exception):\n    \"\"\"Complex retry logic for specific business requirements.\"\"\"\n    # Network errors and timeouts - always retry\n    if isinstance(exception, (httpx.ConnectError, httpx.TimeoutException)):\n        return True\n\n    # Other exceptions - don't retry\n    if exception:\n        return False\n\n    # Success - don't retry\n    if 200 &lt;= response.status_code &lt; 300:\n        return False\n\n    # Client errors (except specific ones) - don't retry\n    if 400 &lt;= response.status_code &lt; 500:\n        # Retry on rate limit and request timeout\n        if response.status_code in (429, 408):\n            return True\n        return False\n\n    # Server errors - check response content\n    if response.status_code &gt;= 500:\n        try:\n            error_data = response.json()\n            # Don't retry on permanent errors\n            if error_data.get(\"error_type\") == \"permanent\":\n                return False\n            # Retry on transient errors\n            if error_data.get(\"error_type\") == \"transient\":\n                return True\n        except Exception:\n            pass  # Can't parse, default to retry\n\n        # Default: retry on 500-level errors\n        return True\n\n    return False\n\n\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/process\",\n    json={\"task\": \"data_processing\"},\n    retry_if=complex_retry_logic,\n    max_retries=3,\n)\n</code></pre>"},{"location":"user_guide/#combining-retry_if-with-status_forcelist","title":"Combining retry_if with status_forcelist","text":"<p>When <code>retry_if</code> is provided, it takes precedence over <code>status_forcelist</code> for determining retry behavior. However, you can reference <code>status_forcelist</code> logic within your predicate:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\ndef custom_with_defaults(response, exception):\n    \"\"\"Custom logic that falls back to default status codes.\"\"\"\n    if exception:\n        return True\n\n    # Custom logic first\n    try:\n        data = response.json()\n        if data.get(\"retry_requested\"):\n            return True\n    except Exception:\n        pass\n\n    # Fall back to common retry status codes\n    return response.status_code in (429, 500, 502, 503, 504)\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    retry_if=custom_with_defaults,\n)\n</code></pre>"},{"location":"user_guide/#retry-predicate-with-async","title":"Retry Predicate with Async","text":"<p>The <code>retry_if</code> predicate works identically with async functions:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\ndef should_retry_async(response, exception):\n    \"\"\"Note: Predicate itself is still synchronous.\"\"\"\n    if exception:\n        return True\n    return response.status_code &gt;= 500\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\n        \"https://api.example.com/data\",\n        retry_if=should_retry_async,\n    )\n    return response.json()\n\n\ndata = asyncio.run(fetch_data())\n</code></pre>"},{"location":"user_guide/#use-cases-for-custom-retry-predicates","title":"Use Cases for Custom Retry Predicates","text":"<ol> <li>API-specific error codes: Retry when API returns specific error codes in response body</li> <li>Polling operations: Retry until resource is ready (based on response content)</li> <li>Idempotency checks: Only retry idempotent operations</li> <li>Content validation: Retry if response doesn't match expected schema</li> <li>Business rules: Implement domain-specific retry logic</li> <li>Rate limiting: Custom handling of rate limit responses with specific headers</li> </ol>"},{"location":"user_guide/#best-practices-for-retry-predicates","title":"Best Practices for Retry Predicates","text":"<ol> <li>Keep it simple: Complex logic makes debugging harder</li> <li>Handle exceptions safely: Wrap JSON parsing and other operations in try/except</li> <li>Document your logic: Clearly explain why certain conditions trigger retries</li> <li>Test thoroughly: Edge cases in retry logic can cause subtle bugs</li> <li>Consider performance: The predicate is called for every response, keep it fast</li> <li>Default to safe behavior: When in doubt, don't retry (especially for write operations)</li> </ol>"},{"location":"user_guide/#callbacks-and-observability","title":"Callbacks and Observability","text":"<p><code>aresilient</code> provides a comprehensive callback/event system for observability, enabling you to hook into the retry lifecycle for logging, metrics collection, alerting, and custom behavior. This is particularly useful for production applications where you need to monitor HTTP request patterns, track retry rates, and integrate with your observability stack.</p>"},{"location":"user_guide/#available-callbacks","title":"Available Callbacks","text":"<p>The library provides four lifecycle hooks:</p> <ul> <li><code>on_request</code>: Called before each request attempt (including the initial request)</li> <li><code>on_retry</code>: Called before each retry (after backoff delay calculation)</li> <li><code>on_success</code>: Called when a request succeeds</li> <li><code>on_failure</code>: Called when all retries are exhausted and the request fails</li> </ul> <p>All callbacks are optional and can be used independently or together. They work with both synchronous and asynchronous functions.</p>"},{"location":"user_guide/#callback-signatures","title":"Callback Signatures","text":"<p>Each callback receives a dataclass with relevant information:</p>"},{"location":"user_guide/#requestinfo-for-on_request","title":"RequestInfo (for <code>on_request</code>)","text":"<pre><code>@dataclass\nclass RequestInfo:\n    url: str  # The URL being requested\n    method: str  # HTTP method (e.g., \"GET\", \"POST\")\n    attempt: int  # Current attempt number (1-indexed, first attempt is 1)\n    max_retries: int  # Maximum number of retry attempts configured\n</code></pre>"},{"location":"user_guide/#retryinfo-for-on_retry","title":"RetryInfo (for <code>on_retry</code>)","text":"<pre><code>@dataclass\nclass RetryInfo:\n    url: str  # The URL being requested\n    method: str  # HTTP method\n    attempt: int  # Current attempt number (1-indexed, first retry is attempt 2)\n    max_retries: int  # Maximum retry attempts configured\n    wait_time: float  # Sleep time in seconds before this retry\n    error: Exception | None  # Exception that triggered the retry (if any)\n    status_code: int | None  # HTTP status code that triggered retry (if any)\n</code></pre>"},{"location":"user_guide/#responseinfo-for-on_success","title":"ResponseInfo (for <code>on_success</code>)","text":"<pre><code>@dataclass\nclass ResponseInfo:\n    url: str  # The URL that was requested\n    method: str  # HTTP method\n    attempt: int  # Attempt number that succeeded (1-indexed)\n    max_retries: int  # Maximum retry attempts configured\n    response: httpx.Response  # The successful HTTP response object\n    total_time: float  # Total time spent on all attempts including backoff (seconds)\n</code></pre>"},{"location":"user_guide/#failureinfo-for-on_failure","title":"FailureInfo (for <code>on_failure</code>)","text":"<pre><code>@dataclass\nclass FailureInfo:\n    url: str  # The URL that was requested\n    method: str  # HTTP method\n    attempt: int  # Final attempt number (1-indexed)\n    max_retries: int  # Maximum retry attempts configured\n    error: Exception  # The final exception that caused failure\n    status_code: int | None  # Final HTTP status code (if any)\n    total_time: float  # Total time spent on all attempts including backoff (seconds)\n</code></pre>"},{"location":"user_guide/#basic-logging-example","title":"Basic Logging Example","text":"<p>Track each phase of the request lifecycle:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\ndef log_request(info):\n    print(\n        f\"[REQUEST] {info.method} {info.url} - Attempt {info.attempt}/{info.max_retries + 1}\"\n    )\n\n\ndef log_retry(info):\n    reason = (\n        f\"status={info.status_code}\"\n        if info.status_code\n        else f\"error={type(info.error).__name__}\"\n    )\n    print(\n        f\"[RETRY] {info.method} {info.url} - \"\n        f\"Attempt {info.attempt}/{info.max_retries + 1}, \"\n        f\"waiting {info.wait_time:.2f}s, reason={reason}\"\n    )\n\n\ndef log_success(info):\n    print(\n        f\"[SUCCESS] {info.method} {info.url} - \"\n        f\"Succeeded on attempt {info.attempt} \"\n        f\"({info.total_time:.2f}s total, status={info.response.status_code})\"\n    )\n\n\ndef log_failure(info):\n    reason = (\n        f\"status={info.status_code}\"\n        if info.status_code\n        else f\"error={type(info.error).__name__}\"\n    )\n    print(\n        f\"[FAILURE] {info.method} {info.url} - \"\n        f\"Failed after {info.attempt} attempts \"\n        f\"({info.total_time:.2f}s total), reason={reason}\"\n    )\n\n\n# Use callbacks for comprehensive logging\ntry:\n    response = get_with_automatic_retry(\n        \"https://api.example.com/data\",\n        max_retries=3,\n        on_request=log_request,\n        on_retry=log_retry,\n        on_success=log_success,\n        on_failure=log_failure,\n    )\nexcept Exception as e:\n    pass  # Error already logged in on_failure\n</code></pre> <p>Example output:</p> <pre><code>[REQUEST] GET https://api.example.com/data - Attempt 1/4\n[RETRY] GET https://api.example.com/data - Attempt 2/4, waiting 0.30s, reason=status=503\n[REQUEST] GET https://api.example.com/data - Attempt 2/4\n[RETRY] GET https://api.example.com/data - Attempt 3/4, waiting 0.60s, reason=status=503\n[REQUEST] GET https://api.example.com/data - Attempt 3/4\n[SUCCESS] GET https://api.example.com/data - Succeeded on attempt 3 (1.15s total, status=200)\n</code></pre>"},{"location":"user_guide/#metrics-collection-example","title":"Metrics Collection Example","text":"<p>Track statistics across multiple requests:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass RequestMetrics:\n    \"\"\"Collect metrics for HTTP requests with retries.\"\"\"\n\n    def __init__(self):\n        self.total_requests = 0\n        self.total_retries = 0\n        self.successes = 0\n        self.failures = 0\n        self.total_time = 0.0\n        self.retry_reasons = {}  # Track why retries happened\n\n    def on_request(self, info):\n        self.total_requests += 1\n\n    def on_retry(self, info):\n        self.total_retries += 1\n        # Track retry reasons\n        reason = info.status_code if info.status_code else type(info.error).__name__\n        self.retry_reasons[reason] = self.retry_reasons.get(reason, 0) + 1\n\n    def on_success(self, info):\n        self.successes += 1\n        self.total_time += info.total_time\n\n    def on_failure(self, info):\n        self.failures += 1\n        self.total_time += info.total_time\n\n    def summary(self):\n        \"\"\"Print a summary of collected metrics.\"\"\"\n        total_completed = self.successes + self.failures\n        success_rate = (\n            (self.successes / total_completed * 100) if total_completed &gt; 0 else 0\n        )\n        avg_time = (self.total_time / total_completed) if total_completed &gt; 0 else 0\n\n        print(f\"=== Request Metrics Summary ===\")\n        print(f\"Total requests made: {self.total_requests}\")\n        print(f\"Total retries: {self.total_retries}\")\n        print(f\"Successes: {self.successes}\")\n        print(f\"Failures: {self.failures}\")\n        print(f\"Success rate: {success_rate:.1f}%\")\n        print(f\"Average time: {avg_time:.2f}s\")\n        print(f\"Retry reasons: {self.retry_reasons}\")\n\n\n# Collect metrics across multiple requests\nmetrics = RequestMetrics()\n\nurls = [\n    \"https://api.example.com/endpoint1\",\n    \"https://api.example.com/endpoint2\",\n    \"https://api.example.com/endpoint3\",\n]\n\nfor url in urls:\n    try:\n        response = get_with_automatic_retry(\n            url,\n            on_request=metrics.on_request,\n            on_retry=metrics.on_retry,\n            on_success=metrics.on_success,\n            on_failure=metrics.on_failure,\n        )\n    except Exception:\n        pass  # Metrics already tracked\n\nmetrics.summary()\n</code></pre>"},{"location":"user_guide/#integration-with-logging-frameworks","title":"Integration with Logging Frameworks","text":"<p>Integrate with Python's standard logging module:</p> <pre><code>import logging\nfrom aresilient import get_with_automatic_retry\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n)\n\nlogger = logging.getLogger(\"http_client\")\n\n\ndef log_retry_event(info):\n    \"\"\"Log retry events with structured information.\"\"\"\n    logger.warning(\n        \"HTTP request retry\",\n        extra={\n            \"url\": info.url,\n            \"method\": info.method,\n            \"attempt\": info.attempt,\n            \"max_retries\": info.max_retries,\n            \"wait_time\": info.wait_time,\n            \"status_code\": info.status_code,\n            \"error\": str(info.error) if info.error else None,\n        },\n    )\n\n\ndef log_failure_event(info):\n    \"\"\"Log failure events with full context.\"\"\"\n    logger.error(\n        \"HTTP request failed after retries\",\n        extra={\n            \"url\": info.url,\n            \"method\": info.method,\n            \"attempts\": info.attempt,\n            \"total_time\": info.total_time,\n            \"status_code\": info.status_code,\n            \"error\": str(info.error),\n        },\n    )\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_retry=log_retry_event,\n    on_failure=log_failure_event,\n)\n</code></pre>"},{"location":"user_guide/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>Send metrics to a monitoring system:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass MonitoringClient:\n    \"\"\"Send metrics to your monitoring system (e.g., Prometheus, Datadog, CloudWatch).\"\"\"\n\n    def __init__(self):\n        # Initialize your metrics client here\n        pass\n\n    def increment_counter(self, metric_name, tags=None):\n        \"\"\"Increment a counter metric.\"\"\"\n        # Your implementation here\n        pass\n\n    def record_histogram(self, metric_name, value, tags=None):\n        \"\"\"Record a histogram/distribution value.\"\"\"\n        # Your implementation here\n        pass\n\n\nmonitoring = MonitoringClient()\n\n\ndef track_retry(info):\n    \"\"\"Track retry events in monitoring system.\"\"\"\n    monitoring.increment_counter(\n        \"http.retries\",\n        tags={\n            \"method\": info.method,\n            \"status_code\": (\n                str(info.status_code) if info.status_code else \"network_error\"\n            ),\n        },\n    )\n\n\ndef track_success(info):\n    \"\"\"Track successful requests.\"\"\"\n    monitoring.increment_counter(\"http.success\", tags={\"method\": info.method})\n    monitoring.record_histogram(\n        \"http.duration\", info.total_time, tags={\"method\": info.method}\n    )\n\n\ndef track_failure(info):\n    \"\"\"Track failed requests.\"\"\"\n    monitoring.increment_counter(\n        \"http.failure\",\n        tags={\n            \"method\": info.method,\n            \"status_code\": (\n                str(info.status_code) if info.status_code else \"network_error\"\n            ),\n        },\n    )\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_retry=track_retry,\n    on_success=track_success,\n    on_failure=track_failure,\n)\n</code></pre>"},{"location":"user_guide/#async-callbacks","title":"Async Callbacks","text":"<p>Callbacks work identically with async functions:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def async_log_retry(info):\n    \"\"\"Callbacks for async functions are still synchronous.\"\"\"\n    print(f\"Retrying {info.url} after {info.wait_time:.2f}s\")\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\n        \"https://api.example.com/data\", on_retry=async_log_retry\n    )\n    return response.json()\n\n\nasyncio.run(fetch_data())\n</code></pre> <p>Note: Callbacks themselves are synchronous functions even when used with async HTTP methods. If you need to perform async operations in callbacks (e.g., async logging), you'll need to handle that separately.</p>"},{"location":"user_guide/#custom-alerting-on-failures","title":"Custom Alerting on Failures","text":"<p>Send alerts when requests fail after all retries:</p> <pre><code>from aresilient import post_with_automatic_retry\n\n\ndef send_alert_on_failure(info):\n    \"\"\"Send an alert when a critical API request fails.\"\"\"\n    if \"critical-api\" in info.url:\n        alert_message = (\n            f\"CRITICAL: API request failed!\\n\"\n            f\"URL: {info.url}\\n\"\n            f\"Method: {info.method}\\n\"\n            f\"Attempts: {info.attempt}\\n\"\n            f\"Total Time: {info.total_time:.2f}s\\n\"\n            f\"Error: {info.error}\\n\"\n            f\"Status Code: {info.status_code}\"\n        )\n        # Send to your alerting system (PagerDuty, Slack, email, etc.)\n        # send_slack_alert(alert_message)\n        # send_email_alert(alert_message)\n        print(alert_message)\n\n\ntry:\n    response = post_with_automatic_retry(\n        \"https://critical-api.example.com/important\",\n        json={\"data\": \"value\"},\n        on_failure=send_alert_on_failure,\n    )\nexcept Exception:\n    pass  # Alert already sent\n</code></pre>"},{"location":"user_guide/#combining-multiple-callbacks","title":"Combining Multiple Callbacks","text":"<p>You can use multiple callbacks together for comprehensive observability:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass RequestObserver:\n    \"\"\"Comprehensive request observer combining logging, metrics, and alerting.\"\"\"\n\n    def __init__(self, logger, metrics, alerting):\n        self.logger = logger\n        self.metrics = metrics\n        self.alerting = alerting\n\n    def on_request(self, info):\n        self.logger.debug(f\"Starting {info.method} {info.url}\")\n        self.metrics.on_request(info)\n\n    def on_retry(self, info):\n        self.logger.warning(f\"Retrying {info.method} {info.url}\")\n        self.metrics.on_retry(info)\n\n    def on_success(self, info):\n        self.logger.info(f\"Success {info.method} {info.url} in {info.total_time:.2f}s\")\n        self.metrics.on_success(info)\n\n    def on_failure(self, info):\n        self.logger.error(f\"Failed {info.method} {info.url}\")\n        self.metrics.on_failure(info)\n        self.alerting.send_alert(info)\n\n\n# Create observer with your components\nobserver = RequestObserver(logger, metrics, alerting)\n\n# Use all callbacks\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_request=observer.on_request,\n    on_retry=observer.on_retry,\n    on_success=observer.on_success,\n    on_failure=observer.on_failure,\n)\n</code></pre>"},{"location":"user_guide/#best-practices-for-callbacks","title":"Best Practices for Callbacks","text":"<ol> <li> <p>Keep callbacks lightweight: Callbacks are called synchronously and will block the request    flow. Avoid heavy computations or blocking I/O.</p> </li> <li> <p>Handle exceptions in callbacks: If a callback raises an exception, it will propagate and    potentially abort the request. Wrap callback code in try/except if needed.</p> </li> <li> <p>Use structured logging: Include relevant context (URL, method, attempt number) in log    messages for better debugging.</p> </li> <li> <p>Sample high-volume metrics: For high-traffic applications, consider sampling metrics to    reduce overhead.</p> </li> <li> <p>Separate concerns: Use <code>on_retry</code> for retry-specific metrics, <code>on_success</code> for latency    tracking, and <code>on_failure</code> for alerting.</p> </li> </ol>"},{"location":"user_guide/#error-handling","title":"Error Handling","text":""},{"location":"user_guide/#understanding-httprequesterror","title":"Understanding HttpRequestError","text":"<p><code>aresilient</code> raises <code>HttpRequestError</code> when a request fails after all retries:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/data\")\nexcept HttpRequestError as e:\n    print(f\"Request failed: {e}\")\n    print(f\"Method: {e.method}\")  # 'GET'\n    print(f\"URL: {e.url}\")  # 'https://api.example.com/data'\n    print(f\"Status Code: {e.status_code}\")  # e.g., 500\n    if e.response:\n        print(f\"Response body: {e.response.text}\")\n</code></pre>"},{"location":"user_guide/#common-error-scenarios","title":"Common Error Scenarios","text":""},{"location":"user_guide/#timeout-errors","title":"Timeout Errors","text":"<p>When a request times out after all retries:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\n        \"https://slow-api.example.com/data\", timeout=1.0, max_retries=2\n    )\nexcept HttpRequestError as e:\n    # status_code will be None for timeout errors\n    if e.status_code is None:\n        print(\"Request timed out\")\n</code></pre>"},{"location":"user_guide/#network-errors","title":"Network Errors","text":"<p>When the connection fails (DNS errors, connection refused, etc.):</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://nonexistent-domain.invalid\")\nexcept HttpRequestError as e:\n    if e.status_code is None:\n        print(f\"Network error: {e}\")\n</code></pre>"},{"location":"user_guide/#http-error-responses","title":"HTTP Error Responses","text":"<p>When the server returns an error status code:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/not-found\")\nexcept HttpRequestError as e:\n    if e.status_code == 404:\n        print(\"Resource not found\")\n    elif e.status_code == 401:\n        print(\"Unauthorized\")\n    elif e.status_code == 403:\n        print(\"Forbidden\")\n</code></pre>"},{"location":"user_guide/#validating-responses","title":"Validating Responses","text":"<p>Check response status and content:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/data\")\n\n    # Response is automatically successful (2xx or 3xx)\n    # if we get here\n    data = response.json()\n\n    # Additional validation if needed\n    if \"error\" in data:\n        print(f\"API returned an error: {data['error']}\")\n\nexcept HttpRequestError as e:\n    print(f\"Request failed: {e}\")\nexcept ValueError as e:\n    print(f\"Invalid JSON response: {e}\")\n</code></pre>"},{"location":"user_guide/#error-handling-with-async","title":"Error Handling with Async","text":"<p>Error handling works the same way with async functions:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async, HttpRequestError\n\n\nasync def fetch_with_error_handling():\n    try:\n        response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n        return response.json()\n    except HttpRequestError as e:\n        print(f\"Async request failed: {e}\")\n        print(f\"Status Code: {e.status_code}\")\n        return None\n\n\nresult = asyncio.run(fetch_with_error_handling())\n</code></pre>"},{"location":"user_guide/#custom-http-methods","title":"Custom HTTP Methods","text":"<p>For HTTP methods not directly supported or for custom needs, use the <code>request_with_automatic_retry</code> and <code>request_with_automatic_retry_async</code> functions.</p>"},{"location":"user_guide/#synchronous-custom-requests","title":"Synchronous Custom Requests","text":"<pre><code>import httpx\nfrom aresilient import request_with_automatic_retry\n\n# Example: Using HEAD method\nwith httpx.Client() as client:\n    response = request_with_automatic_retry(\n        url=\"https://api.example.com/resource\",\n        method=\"HEAD\",\n        request_func=client.head,\n        max_retries=3,\n    )\n    print(f\"Content-Length: {response.headers.get('content-length')}\")\n\n# Example: Using OPTIONS method\nwith httpx.Client() as client:\n    response = request_with_automatic_retry(\n        url=\"https://api.example.com/resource\",\n        method=\"OPTIONS\",\n        request_func=client.options,\n    )\n    print(f\"Allowed methods: {response.headers.get('allow')}\")\n</code></pre>"},{"location":"user_guide/#async-custom-requests","title":"Async Custom Requests","text":"<pre><code>import asyncio\nimport httpx\nfrom aresilient import request_with_automatic_retry_async\n\n\nasync def make_custom_request():\n    async with httpx.AsyncClient() as client:\n        # Using HEAD method asynchronously\n        response = await request_with_automatic_retry_async(\n            url=\"https://api.example.com/resource\",\n            method=\"HEAD\",\n            request_func=client.head,\n            max_retries=3,\n        )\n        return response.headers.get(\"content-length\")\n\n\ncontent_length = asyncio.run(make_custom_request())\n</code></pre>"},{"location":"user_guide/#advanced-custom-request-example","title":"Advanced Custom Request Example","text":"<pre><code>import httpx\nfrom aresilient import request_with_automatic_retry\n\n\ndef custom_api_call():\n    with httpx.Client(timeout=30.0) as client:\n        # Custom request with specific retry configuration\n        response = request_with_automatic_retry(\n            url=\"https://api.example.com/custom-endpoint\",\n            method=\"PATCH\",\n            request_func=client.patch,\n            max_retries=5,\n            backoff_factor=1.0,\n            status_forcelist=(429, 503),\n            # Additional kwargs passed to client.patch\n            json={\"operation\": \"update\", \"value\": 42},\n            headers={\"X-API-Version\": \"2.0\"},\n        )\n        return response.json()\n</code></pre>"},{"location":"user_guide/#best-practices","title":"Best Practices","text":""},{"location":"user_guide/#1-use-appropriate-timeouts","title":"1. Use Appropriate Timeouts","text":"<p>Set timeouts based on your expected response times:</p> <pre><code># Quick health check\nresponse = get_with_automatic_retry(\"https://api.example.com/health\", timeout=5.0)\n\n# Large data download\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/large-dataset\", timeout=120.0\n)\n</code></pre>"},{"location":"user_guide/#2-use-context-managers-for-multiple-requests","title":"2. Use Context Managers for Multiple Requests","text":"<p>When making multiple requests, use <code>ResilientClient</code> or <code>AsyncResilientClient</code> for better code organization and connection pooling:</p> <pre><code>from aresilient import ResilientClient\n\n# Good: Use ResilientClient for multiple requests\nwith ResilientClient(max_retries=3, timeout=30.0) as client:\n    for url in urls:\n        response = client.get(url)\n        process_response(response)\n\n# Alternative: Reuse httpx client (more verbose)\nimport httpx\nfrom aresilient import get_with_automatic_retry\n\nwith httpx.Client() as client:\n    for url in urls:\n        response = get_with_automatic_retry(url, client=client, max_retries=3)\n        process_response(response)\n\n# Bad: Creates new client for each request\nfrom aresilient import get_with_automatic_retry\n\nfor url in urls:\n    response = get_with_automatic_retry(url, max_retries=3)\n    process_response(response)\n</code></pre>"},{"location":"user_guide/#3-adjust-retry-strategy-based-on-use-case","title":"3. Adjust Retry Strategy Based on Use Case","text":"<p>For user-facing operations, use fewer retries for faster failure:</p> <pre><code># User-facing: fail fast\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/user-data\", max_retries=1, timeout=10.0\n)\n</code></pre> <p>For background jobs, use more retries:</p> <pre><code># Background job: be more resilient\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/batch-process\",\n    max_retries=5,\n    backoff_factor=1.0,\n    timeout=60.0,\n)\n</code></pre>"},{"location":"user_guide/#4-handle-rate-limiting-gracefully","title":"4. Handle Rate Limiting Gracefully","text":"<p>If you're hitting rate limits frequently, consider:</p> <pre><code># Increase backoff for rate-limited endpoints\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/rate-limited\",\n    max_retries=5,\n    backoff_factor=2.0,  # Longer waits\n    status_forcelist=(429,),  # Only retry on rate limit\n)\n</code></pre>"},{"location":"user_guide/#5-use-async-for-io-bound-operations","title":"5. Use Async for I/O-Bound Operations","text":"<p>When making multiple HTTP requests, async can significantly improve performance:</p> <pre><code>import asyncio\nimport httpx\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_all_data(urls):\n    async with httpx.AsyncClient() as client:\n        tasks = [get_with_automatic_retry_async(url, client=client) for url in urls]\n        responses = await asyncio.gather(*tasks)\n        return [r.json() for r in responses]\n\n\n# Fetch 10 URLs concurrently instead of sequentially\nurls = [f\"https://api.example.com/item/{i}\" for i in range(10)]\nresults = asyncio.run(fetch_all_data(urls))\n</code></pre>"},{"location":"user_guide/#6-choose-between-sync-and-async-based-on-your-application","title":"6. Choose Between Sync and Async Based on Your Application","text":"<p>Use synchronous functions when:</p> <ul> <li>Your application is not using asyncio</li> <li>You're making single, occasional requests</li> <li>Your code is primarily synchronous</li> <li>You're writing simple scripts or command-line tools</li> </ul> <p>Use async functions when:</p> <ul> <li>Your application already uses asyncio</li> <li>You need to make multiple concurrent requests</li> <li>You're building a web application (e.g., FastAPI, Sanic)</li> <li>Performance and scalability are critical</li> </ul> <pre><code># Synchronous example - simple script\nfrom aresilient import get_with_automatic_retry\n\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\nprint(response.json())\n</code></pre> <pre><code># Async example - FastAPI application\nfrom fastapi import FastAPI\nfrom aresilient import get_with_automatic_retry_async\n\napp = FastAPI()\n\n\n@app.get(\"/fetch-data\")\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n</code></pre>"},{"location":"user_guide/#7-enable-debug-logging-for-troubleshooting","title":"7. Enable Debug Logging for Troubleshooting","text":"<p><code>aresilient</code> uses Python's standard <code>logging</code> module to provide detailed debug information about retries, backoff times, and errors. This can be helpful for troubleshooting issues or understanding retry behavior.</p> <pre><code>import logging\nfrom aresilient import get_with_automatic_retry\n\n# Enable debug logging to see retry details\nlogging.basicConfig(level=logging.DEBUG)\n\n# This will log:\n# - Each retry attempt\n# - Wait times between retries\n# - Whether Retry-After header is being used\n# - Success/failure of each attempt\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\n</code></pre> <p>Example debug output:</p> <pre><code>DEBUG:aresilient.request:GET request to https://api.example.com/data failed with status 503 (attempt 1/4)\nDEBUG:aresilient.utils:Waiting 0.30s before retry\nDEBUG:aresilient.request:GET request to https://api.example.com/data succeeded on attempt 2\n</code></pre> <p>For production use, keep the default log level (INFO or WARNING) to avoid excessive logging.</p>"},{"location":"user_guide/#8-use-circuit-breakers-for-external-dependencies","title":"8. Use Circuit Breakers for External Dependencies","text":"<p>Protect your application from cascading failures when calling external services:</p> <pre><code>from aresilient import ResilientClient\nfrom aresilient.circuit_breaker import CircuitBreaker\n\n# Create circuit breakers for different services\npayment_circuit = CircuitBreaker(failure_threshold=5, recovery_timeout=60.0)\nuser_service_circuit = CircuitBreaker(failure_threshold=3, recovery_timeout=30.0)\n\n# Use with different endpoints\nwith ResilientClient(circuit_breaker=payment_circuit) as client:\n    response = client.post(\n        \"https://payment-api.example.com/charge\", json={\"amount\": 100}\n    )\n\nwith ResilientClient(circuit_breaker=user_service_circuit) as client:\n    response = client.get(\"https://user-api.example.com/profile\")\n</code></pre>"},{"location":"user_guide/#9-set-time-budgets-for-strict-slas","title":"9. Set Time Budgets for Strict SLAs","text":"<p>Use <code>max_total_time</code> when you have strict time constraints:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Critical user-facing operation with 5-second SLA\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/critical-data\",\n    max_retries=10,  # Try many times...\n    max_total_time=5.0,  # ...but stop after 5 seconds total\n    max_wait_time=2.0,  # ...and don't wait more than 2s between attempts\n)\n</code></pre>"},{"location":"user_guide/#10-choose-the-right-backoff-strategy","title":"10. Choose the Right Backoff Strategy","text":"<p>Select backoff strategies based on your use case:</p> <pre><code>from aresilient import (\n    get_with_automatic_retry,\n    ExponentialBackoff,\n    LinearBackoff,\n    ConstantBackoff,\n)\n\n# Exponential: Most services (default)\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ExponentialBackoff(base_delay=0.5, max_delay=30.0),\n)\n\n# Linear: Predictable recovery times\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/stable-service\",\n    backoff_strategy=LinearBackoff(base_delay=1.0, max_delay=10.0),\n)\n\n# Constant: Testing or specific API requirements\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/polling-endpoint\",\n    backoff_strategy=ConstantBackoff(delay=2.0),\n)\n</code></pre>"},{"location":"user_guide/#11-use-custom-retry-predicates-for-complex-logic","title":"11. Use Custom Retry Predicates for Complex Logic","text":"<p>When status codes aren't enough, use <code>retry_if</code> for custom logic:</p> <pre><code>from aresilient import post_with_automatic_retry\n\n\ndef should_retry_payment(response, exception):\n    \"\"\"Custom retry logic for payment processing.\"\"\"\n    if exception:\n        return True  # Retry on network errors\n\n    if response.status_code &gt;= 500:\n        return True  # Retry on server errors\n\n    # Check for specific business conditions\n    try:\n        data = response.json()\n        # Retry on temporary payment processor issues\n        if data.get(\"error_code\") in (\"temporary_unavailable\", \"rate_limit\"):\n            return True\n    except Exception:\n        pass\n\n    return False\n\n\nresponse = post_with_automatic_retry(\n    \"https://payment-api.example.com/charge\",\n    json={\"amount\": 100},\n    retry_if=should_retry_payment,\n)\n</code></pre>"},{"location":"user_guide/#additional-resources","title":"Additional Resources","text":"<ul> <li>Backoff Strategies - Detailed guide on backoff strategies</li> <li>API Reference - Complete API documentation</li> <li>Get Started - Installation and setup instructions</li> <li>httpx Documentation - Learn more about the underlying library</li> </ul>"},{"location":"refs/","title":"Main classes and functions","text":""},{"location":"refs/#aresilient","title":"aresilient","text":"<p>aresilient - Resilient HTTP request library with automatic retry logic.</p> <p>This package provides resilient HTTP request functionality with automatic retry logic and backoff strategies. Built on top of the modern httpx library, it simplifies handling transient failures in HTTP communications, making your applications more robust and fault-tolerant.</p> Key Features <ul> <li>Automatic retry logic for transient HTTP errors (429, 500, 502, 503, 504)</li> <li>Multiple backoff strategies: Exponential, Linear, Fibonacci, Constant, and custom</li> <li>Optional jitter to prevent thundering herd problems</li> <li>Retry-After header support (both integer seconds and HTTP-date formats)</li> <li>Complete HTTP method support (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS)</li> <li>Full async support for high-performance applications</li> <li>Configurable timeout, retry attempts, backoff factors, and jitter</li> <li>Enhanced error handling with detailed exception information</li> <li>Callback/Event system for observability (logging, metrics, alerting)</li> <li>Context manager API for managing request sessions</li> </ul> Example <pre><code>&gt;&gt;&gt; from aresilient import get_with_automatic_retry\n&gt;&gt;&gt; from aresilient.backoff import LinearBackoff\n&gt;&gt;&gt; # Use default exponential backoff\n&gt;&gt;&gt; response = get_with_automatic_retry(\"https://api.example.com/data\")  # doctest: +SKIP\n&gt;&gt;&gt; # Use linear backoff strategy\n&gt;&gt;&gt; response = get_with_automatic_retry(\n...     \"https://api.example.com/data\", backoff_strategy=LinearBackoff(base_delay=1.0)\n... )  # doctest: +SKIP\n&gt;&gt;&gt; # Use context manager for multiple requests\n&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient(max_retries=5, timeout=30) as client:  # doctest: +SKIP\n...     response1 = client.get(\"https://api.example.com/data1\")\n...     response2 = client.post(\"https://api.example.com/data2\", json={\"key\": \"value\"})\n...\n</code></pre>"},{"location":"refs/#aresilient.AsyncResilientClient","title":"aresilient.AsyncResilientClient","text":"<p>Asynchronous context manager for resilient HTTP requests.</p> <p>This class provides an async context manager interface for making multiple HTTP requests with shared retry configuration. The client automatically manages the lifecycle of the underlying httpx.AsyncClient and applies consistent retry logic across all requests.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for server responses. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy instance.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. Must be &gt; 0 if provided.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Must be &gt; 0 if provided.</p> <code>None</code> <code>circuit_breaker</code> <code>CircuitBreaker | None</code> <p>Optional circuit breaker instance for advanced failure handling.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff).</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted.</p> <code>None</code> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient(max_retries=5, timeout=30) as client:\n...         response1 = await client.get(\"https://api.example.com/data1\")\n...         response2 = await client.post(\n...             \"https://api.example.com/data2\", json={\"key\": \"value\"}\n...         )\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n# Client automatically closed after context exits\n</code></pre> Note <p>All HTTP method calls (get, post, put, delete, patch, head, options, request) support the same parameters as their standalone function counterparts, allowing per-request override of the client's default configuration.</p>"},{"location":"refs/#aresilient.AsyncResilientClient.__aenter__","title":"aresilient.AsyncResilientClient.__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; Self\n</code></pre> <p>Enter the async context manager and create the underlying httpx client.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The AsyncResilientClient instance for making requests.</p>"},{"location":"refs/#aresilient.AsyncResilientClient.__aexit__","title":"aresilient.AsyncResilientClient.__aexit__  <code>async</code>","text":"<pre><code>__aexit__(\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: TracebackType | None,\n) -&gt; None\n</code></pre> <p>Exit the async context manager and close the underlying httpx client.</p> <p>Parameters:</p> Name Type Description Default <code>exc_type</code> <code>type[BaseException] | None</code> <p>Exception type if an exception occurred.</p> required <code>exc_val</code> <code>BaseException | None</code> <p>Exception value if an exception occurred.</p> required <code>exc_tb</code> <code>TracebackType | None</code> <p>Exception traceback if an exception occurred.</p> required"},{"location":"refs/#aresilient.AsyncResilientClient.__init__","title":"aresilient.AsyncResilientClient.__init__","text":"<pre><code>__init__(\n    *,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    circuit_breaker: CircuitBreaker | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None\n) -&gt; None\n</code></pre> <p>Initialize the async resilient client with retry configuration.</p>"},{"location":"refs/#aresilient.AsyncResilientClient.delete","title":"aresilient.AsyncResilientClient.delete  <code>async</code>","text":"<pre><code>delete(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP DELETE request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the DELETE request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient() as client:\n...         response = await client.delete(\"https://api.example.com/data\")\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.AsyncResilientClient.get","title":"aresilient.AsyncResilientClient.get  <code>async</code>","text":"<pre><code>get(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP GET request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient() as client:\n...         response = await client.get(\"https://api.example.com/data\")\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.AsyncResilientClient.head","title":"aresilient.AsyncResilientClient.head  <code>async</code>","text":"<pre><code>head(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP HEAD request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the HEAD request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient() as client:\n...         response = await client.head(\"https://api.example.com/data\")\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.AsyncResilientClient.options","title":"aresilient.AsyncResilientClient.options  <code>async</code>","text":"<pre><code>options(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP OPTIONS request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the OPTIONS request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient() as client:\n...         response = await client.options(\"https://api.example.com/data\")\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.AsyncResilientClient.patch","title":"aresilient.AsyncResilientClient.patch  <code>async</code>","text":"<pre><code>patch(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP PATCH request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PATCH request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient() as client:\n...         response = await client.patch(\n...             \"https://api.example.com/data\", json={\"key\": \"value\"}\n...         )\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.AsyncResilientClient.post","title":"aresilient.AsyncResilientClient.post  <code>async</code>","text":"<pre><code>post(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP POST request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the POST request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient() as client:\n...         response = await client.post(\n...             \"https://api.example.com/data\", json={\"key\": \"value\"}\n...         )\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.AsyncResilientClient.put","title":"aresilient.AsyncResilientClient.put  <code>async</code>","text":"<pre><code>put(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP PUT request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PUT request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient() as client:\n...         response = await client.put(\n...             \"https://api.example.com/data\", json={\"key\": \"value\"}\n...         )\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.AsyncResilientClient.request","title":"aresilient.AsyncResilientClient.request  <code>async</code>","text":"<pre><code>request(\n    method: str,\n    url: str,\n    *,\n    max_retries: int | None = None,\n    backoff_factor: float | None = None,\n    status_forcelist: tuple[int, ...] | None = None,\n    jitter_factor: float | None = None,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    circuit_breaker: CircuitBreaker | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>HTTP method (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS, etc.).</p> required <code>url</code> <code>str</code> <p>The URL to send the request to.</p> required <code>max_retries</code> <code>int | None</code> <p>Override client's max_retries for this request.</p> <code>None</code> <code>backoff_factor</code> <code>float | None</code> <p>Override client's backoff_factor for this request.</p> <code>None</code> <code>status_forcelist</code> <code>tuple[int, ...] | None</code> <p>Override client's status_forcelist for this request.</p> <code>None</code> <code>jitter_factor</code> <code>float | None</code> <p>Override client's jitter_factor for this request.</p> <code>None</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Override client's retry_if for this request.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Override client's backoff_strategy for this request.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Override client's max_total_time for this request.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Override client's max_wait_time for this request.</p> <code>None</code> <code>circuit_breaker</code> <code>CircuitBreaker | None</code> <p>Override client's circuit_breaker for this request.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Override client's on_request callback for this request.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Override client's on_retry callback for this request.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Override client's on_success callback for this request.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Override client's on_failure callback for this request.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to httpx.AsyncClient.request().</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called outside of a context manager.</p> <code>HttpRequestError</code> <p>If the request fails after all retries.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import AsyncResilientClient\n&gt;&gt;&gt; async def main():  # doctest: +SKIP\n...     async with AsyncResilientClient() as client:\n...         response = await client.request(\"GET\", \"https://api.example.com/data\")\n...\n&gt;&gt;&gt; asyncio.run(main())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.HttpRequestError","title":"aresilient.HttpRequestError","text":"<p>               Bases: <code>RuntimeError</code></p> <p>Exception raised when an HTTP request fails.</p> <p>This exception captures comprehensive details about failed HTTP requests, including the request method, URL, status code, and the full response object when available. It supports exception chaining to preserve the original cause of the error.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The HTTP method used for the request (e.g., 'GET', 'POST').</p> required <code>url</code> <code>str</code> <p>The target URL that was requested.</p> required <code>message</code> <code>str</code> <p>A descriptive error message explaining the failure.</p> required <code>status_code</code> <code>int | None</code> <p>The HTTP status code returned by the server, if the request reached the server. Defaults to <code>None</code> if the request failed before receiving a response.</p> <code>None</code> <code>response</code> <code>Response | None</code> <p>The complete httpx.Response object containing headers, body, and other response details. Defaults to <code>None</code> if no response was received.</p> <code>None</code> <code>cause</code> <code>BaseException | None</code> <p>The original exception that caused this error, used for exception chaining. Defaults to <code>None</code>.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>method</code> <p>The HTTP method used for the request.</p> <code>url</code> <p>The target URL that was requested.</p> <code>status_code</code> <p>The HTTP status code, if available.</p> <code>response</code> <p>The full response object, if available.</p> <p>Examples:</p> <p>Raising an error for a failed GET request:</p> <pre><code>&gt;&gt;&gt; from aresilient import HttpRequestError\n&gt;&gt;&gt; raise HttpRequestError(\n...     method=\"GET\",\n...     url=\"https://api.example.com/data\",\n...     message=\"Request failed with status 404\",\n...     status_code=404,\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.ResilientClient","title":"aresilient.ResilientClient","text":"<p>Synchronous context manager for resilient HTTP requests.</p> <p>This class provides a context manager interface for making multiple HTTP requests with shared retry configuration. The client automatically manages the lifecycle of the underlying httpx.Client and applies consistent retry logic across all requests.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for server responses. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy instance.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. Must be &gt; 0 if provided.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Must be &gt; 0 if provided.</p> <code>None</code> <code>circuit_breaker</code> <code>CircuitBreaker | None</code> <p>Optional circuit breaker instance for advanced failure handling.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff).</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted.</p> <code>None</code> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient(max_retries=5, timeout=30) as client:  # doctest: +SKIP\n...     response1 = client.get(\"https://api.example.com/data1\")\n...     response2 = client.post(\"https://api.example.com/data2\", json={\"key\": \"value\"})\n...\n# Client automatically closed after context exits\n</code></pre> Note <p>All HTTP method calls (get, post, put, delete, patch, head, options, request) support the same parameters as their standalone function counterparts, allowing per-request override of the client's default configuration.</p>"},{"location":"refs/#aresilient.ResilientClient.__enter__","title":"aresilient.ResilientClient.__enter__","text":"<pre><code>__enter__() -&gt; Self\n</code></pre> <p>Enter the context manager and create the underlying httpx client.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The ResilientClient instance for making requests.</p>"},{"location":"refs/#aresilient.ResilientClient.__exit__","title":"aresilient.ResilientClient.__exit__","text":"<pre><code>__exit__(\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: TracebackType | None,\n) -&gt; None\n</code></pre> <p>Exit the context manager and close the underlying httpx client.</p> <p>Parameters:</p> Name Type Description Default <code>exc_type</code> <code>type[BaseException] | None</code> <p>Exception type if an exception occurred.</p> required <code>exc_val</code> <code>BaseException | None</code> <p>Exception value if an exception occurred.</p> required <code>exc_tb</code> <code>TracebackType | None</code> <p>Exception traceback if an exception occurred.</p> required"},{"location":"refs/#aresilient.ResilientClient.__init__","title":"aresilient.ResilientClient.__init__","text":"<pre><code>__init__(\n    *,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    circuit_breaker: CircuitBreaker | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None\n) -&gt; None\n</code></pre> <p>Initialize the resilient client with retry configuration.</p>"},{"location":"refs/#aresilient.ResilientClient.delete","title":"aresilient.ResilientClient.delete","text":"<pre><code>delete(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP DELETE request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the DELETE request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient() as client:  # doctest: +SKIP\n...     response = client.delete(\"https://api.example.com/data\")\n...\n</code></pre>"},{"location":"refs/#aresilient.ResilientClient.get","title":"aresilient.ResilientClient.get","text":"<pre><code>get(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP GET request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient() as client:  # doctest: +SKIP\n...     response = client.get(\"https://api.example.com/data\")\n...\n</code></pre>"},{"location":"refs/#aresilient.ResilientClient.head","title":"aresilient.ResilientClient.head","text":"<pre><code>head(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP HEAD request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the HEAD request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient() as client:  # doctest: +SKIP\n...     response = client.head(\"https://api.example.com/data\")\n...\n</code></pre>"},{"location":"refs/#aresilient.ResilientClient.options","title":"aresilient.ResilientClient.options","text":"<pre><code>options(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP OPTIONS request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the OPTIONS request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient() as client:  # doctest: +SKIP\n...     response = client.options(\"https://api.example.com/data\")\n...\n</code></pre>"},{"location":"refs/#aresilient.ResilientClient.patch","title":"aresilient.ResilientClient.patch","text":"<pre><code>patch(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP PATCH request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PATCH request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient() as client:  # doctest: +SKIP\n...     response = client.patch(\"https://api.example.com/data\", json={\"key\": \"value\"})\n...\n</code></pre>"},{"location":"refs/#aresilient.ResilientClient.post","title":"aresilient.ResilientClient.post","text":"<pre><code>post(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP POST request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the POST request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient() as client:  # doctest: +SKIP\n...     response = client.post(\"https://api.example.com/data\", json={\"key\": \"value\"})\n...\n</code></pre>"},{"location":"refs/#aresilient.ResilientClient.put","title":"aresilient.ResilientClient.put","text":"<pre><code>put(url: str, **kwargs: Any) -&gt; Response\n</code></pre> <p>Send an HTTP PUT request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PUT request to.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (see request() method).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient() as client:  # doctest: +SKIP\n...     response = client.put(\"https://api.example.com/data\", json={\"key\": \"value\"})\n...\n</code></pre>"},{"location":"refs/#aresilient.ResilientClient.request","title":"aresilient.ResilientClient.request","text":"<pre><code>request(\n    method: str,\n    url: str,\n    *,\n    max_retries: int | None = None,\n    backoff_factor: float | None = None,\n    status_forcelist: tuple[int, ...] | None = None,\n    jitter_factor: float | None = None,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    circuit_breaker: CircuitBreaker | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP request with automatic retry logic.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>HTTP method (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS, etc.).</p> required <code>url</code> <code>str</code> <p>The URL to send the request to.</p> required <code>max_retries</code> <code>int | None</code> <p>Override client's max_retries for this request.</p> <code>None</code> <code>backoff_factor</code> <code>float | None</code> <p>Override client's backoff_factor for this request.</p> <code>None</code> <code>status_forcelist</code> <code>tuple[int, ...] | None</code> <p>Override client's status_forcelist for this request.</p> <code>None</code> <code>jitter_factor</code> <code>float | None</code> <p>Override client's jitter_factor for this request.</p> <code>None</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Override client's retry_if for this request.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Override client's backoff_strategy for this request.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Override client's max_total_time for this request.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Override client's max_wait_time for this request.</p> <code>None</code> <code>circuit_breaker</code> <code>CircuitBreaker | None</code> <p>Override client's circuit_breaker for this request.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Override client's on_request callback for this request.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Override client's on_retry callback for this request.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Override client's on_success callback for this request.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Override client's on_failure callback for this request.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to httpx.Client.request().</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called outside of a context manager.</p> <code>HttpRequestError</code> <p>If the request fails after all retries.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import ResilientClient\n&gt;&gt;&gt; with ResilientClient() as client:  # doctest: +SKIP\n...     response = client.request(\"GET\", \"https://api.example.com/data\")\n...\n</code></pre>"},{"location":"refs/#aresilient.delete_with_automatic_retry","title":"aresilient.delete_with_automatic_retry","text":"<pre><code>delete_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP DELETE request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP DELETE request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the DELETE request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.delete()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import delete_with_automatic_retry\n&gt;&gt;&gt; response = delete_with_automatic_retry(\n...     \"https://api.example.com/resource/123\"\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.delete_with_automatic_retry_async","title":"aresilient.delete_with_automatic_retry_async  <code>async</code>","text":"<pre><code>delete_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP DELETE request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP DELETE request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the DELETE request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.delete()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import delete_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await delete_with_automatic_retry_async(\n...         \"https://api.example.com/resource/123\"\n...     )\n...     return response.status_code\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.get_with_automatic_retry","title":"aresilient.get_with_automatic_retry","text":"<pre><code>get_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP GET request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP GET request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.get()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import get_with_automatic_retry\n&gt;&gt;&gt; response = get_with_automatic_retry(\"https://api.example.com/data\")  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.get_with_automatic_retry_async","title":"aresilient.get_with_automatic_retry_async  <code>async</code>","text":"<pre><code>get_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP GET request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP GET request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.get()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import get_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.head_with_automatic_retry","title":"aresilient.head_with_automatic_retry","text":"<pre><code>head_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP HEAD request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP HEAD request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>HEAD requests retrieve only the headers without the response body, making them useful for checking resource existence, metadata, ETags, content length, and performing lightweight validation without downloading data.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the HEAD request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.head()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response headers.</p> <code>Response</code> <p>The response body will be empty.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import head_with_automatic_retry\n&gt;&gt;&gt; # Check if a resource exists and get metadata\n&gt;&gt;&gt; response = head_with_automatic_retry(\n...     \"https://api.example.com/large-file.zip\"\n... )  # doctest: +SKIP\n&gt;&gt;&gt; if response.status_code == 200:  # doctest: +SKIP\n...     print(f\"Content-Length: {response.headers.get('Content-Length')}\")  # doctest: +SKIP\n...     print(f\"Last-Modified: {response.headers.get('Last-Modified')}\")  # doctest: +SKIP\n...\n</code></pre>"},{"location":"refs/#aresilient.head_with_automatic_retry_async","title":"aresilient.head_with_automatic_retry_async  <code>async</code>","text":"<pre><code>head_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP HEAD request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP HEAD request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>HEAD requests retrieve only the headers without the response body, making them useful for checking resource existence, metadata, ETags, content length, and performing lightweight validation without downloading data.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the HEAD request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.head()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response headers.</p> <code>Response</code> <p>The response body will be empty.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import head_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await head_with_automatic_retry_async(\n...         \"https://api.example.com/large-file.zip\"\n...     )\n...     if response.status_code == 200:\n...         print(f\"Content-Length: {response.headers.get('Content-Length')}\")\n...     return response\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.options_with_automatic_retry","title":"aresilient.options_with_automatic_retry","text":"<pre><code>options_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP OPTIONS request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP OPTIONS request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>OPTIONS requests are used to describe communication options for a target resource, including CORS preflight requests, discovering allowed HTTP methods via the Allow header, and querying server capabilities.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the OPTIONS request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.options()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response with</p> <code>Response</code> <p>communication options in headers (e.g., Allow, Access-Control-Allow-*).</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import options_with_automatic_retry\n&gt;&gt;&gt; # Check allowed HTTP methods for a resource\n&gt;&gt;&gt; response = options_with_automatic_retry(\n...     \"https://api.example.com/resource\"\n... )  # doctest: +SKIP\n&gt;&gt;&gt; allowed_methods = response.headers.get(\"Allow\")  # doctest: +SKIP\n&gt;&gt;&gt; print(f\"Allowed methods: {allowed_methods}\")  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.options_with_automatic_retry_async","title":"aresilient.options_with_automatic_retry_async  <code>async</code>","text":"<pre><code>options_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP OPTIONS request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP OPTIONS request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>OPTIONS requests are used to describe communication options for a target resource, including CORS preflight requests, discovering allowed HTTP methods via the Allow header, and querying server capabilities.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the OPTIONS request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.options()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response with</p> <code>Response</code> <p>communication options in headers (e.g., Allow, Access-Control-Allow-*).</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import options_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await options_with_automatic_retry_async(\n...         \"https://api.example.com/resource\"\n...     )\n...     allowed_methods = response.headers.get(\"Allow\")\n...     print(f\"Allowed methods: {allowed_methods}\")\n...     return response\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.patch_with_automatic_retry","title":"aresilient.patch_with_automatic_retry","text":"<pre><code>patch_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PATCH request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PATCH request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PATCH request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.patch()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import patch_with_automatic_retry\n&gt;&gt;&gt; response = patch_with_automatic_retry(\n...     \"https://api.example.com/resource/123\", json={\"status\": \"active\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.patch_with_automatic_retry_async","title":"aresilient.patch_with_automatic_retry_async  <code>async</code>","text":"<pre><code>patch_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PATCH request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PATCH request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PATCH request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.patch()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import patch_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await patch_with_automatic_retry_async(\n...         \"https://api.example.com/resource/123\", json={\"status\": \"updated\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.post_with_automatic_retry","title":"aresilient.post_with_automatic_retry","text":"<pre><code>post_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP POST request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP POST request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the POST request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.post()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import post_with_automatic_retry\n&gt;&gt;&gt; response = post_with_automatic_retry(\n...     \"https://api.example.com/data\", json={\"key\": \"value\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.post_with_automatic_retry_async","title":"aresilient.post_with_automatic_retry_async  <code>async</code>","text":"<pre><code>post_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP POST request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP POST request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the POST request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.post()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import post_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await post_with_automatic_retry_async(\n...         \"https://api.example.com/data\", json={\"key\": \"value\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.put_with_automatic_retry","title":"aresilient.put_with_automatic_retry","text":"<pre><code>put_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PUT request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PUT request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PUT request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.put()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import put_with_automatic_retry\n&gt;&gt;&gt; response = put_with_automatic_retry(\n...     \"https://api.example.com/resource/123\", json={\"name\": \"updated\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.put_with_automatic_retry_async","title":"aresilient.put_with_automatic_retry_async  <code>async</code>","text":"<pre><code>put_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PUT request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PUT request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PUT request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.put()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import put_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await put_with_automatic_retry_async(\n...         \"https://api.example.com/resource\", json={\"key\": \"value\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.request_with_automatic_retry","title":"aresilient.request_with_automatic_retry","text":"<pre><code>request_with_automatic_retry(\n    url: str,\n    method: str,\n    request_func: Callable[..., Response],\n    *,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    circuit_breaker: CircuitBreaker | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Perform an HTTP request with automatic retry logic.</p> <p>This function implements a retry mechanism with exponential backoff for handling transient HTTP errors. It attempts the request up to max_retries + 1 times, waiting progressively longer between each retry.</p> <p>The retry logic handles three types of failures: 1. Retryable HTTP status codes (e.g., 429, 500, 502, 503, 504) 2. Timeout exceptions (httpx.TimeoutException) 3. General network errors (httpx.RequestError)</p> <p>Backoff Strategy: - Default: Exponential backoff: backoff_factor * (2 ** attempt) - Custom: Use backoff_strategy parameter for alternative strategies   (Linear, Fibonacci, Constant, or custom implementations) - Jitter: Optional randomization added to prevent thundering herd - Retry-After header: If present in the response (429/503), the server's   suggested wait time is used instead of backoff calculation</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the request to.</p> required <code>method</code> <code>str</code> <p>The HTTP method name (e.g., \"GET\", \"POST\") for logging.</p> required <code>request_func</code> <code>Callable[..., Response]</code> <p>The function to call to make the request (e.g., client.get, client.post).</p> required <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is 0-indexed (0, 1, 2, ...). Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>circuit_breaker</code> <code>CircuitBreaker | None</code> <p>Optional CircuitBreaker instance to use for preventing cascading failures. When provided, the circuit breaker will track failures and stop making requests if the failure threshold is reached, transitioning to an OPEN state where requests fail fast. After a recovery timeout, it will transition to HALF_OPEN to test if the service has recovered.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the request function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> Example <pre><code>&gt;&gt;&gt; import httpx\n&gt;&gt;&gt; from aresilient import request_with_automatic_retry\n&gt;&gt;&gt; from aresilient.backoff import LinearBackoff\n&gt;&gt;&gt; def log_retry(info):\n...     print(f\"Retry {info.attempt}/{info.max_retries + 1}\")\n...\n&gt;&gt;&gt; with httpx.Client() as client:\n...     response = request_with_automatic_retry(\n...         url=\"https://api.example.com/data\",\n...         method=\"GET\",\n...         request_func=client.get,\n...         max_retries=5,\n...         backoff_strategy=LinearBackoff(base_delay=1.0),\n...         jitter_factor=0.1,  # Add 10% jitter\n...         max_total_time=30.0,  # Stop after 30s total\n...         max_wait_time=5.0,  # Cap backoff at 5s max\n...         on_retry=log_retry,\n...     )  # doctest: +SKIP\n...\n</code></pre>"},{"location":"refs/#aresilient.request_with_automatic_retry_async","title":"aresilient.request_with_automatic_retry_async  <code>async</code>","text":"<pre><code>request_with_automatic_retry_async(\n    url: str,\n    method: str,\n    request_func: Callable[..., Awaitable[Response]],\n    *,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    circuit_breaker: CircuitBreaker | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Perform an async HTTP request with automatic retry logic.</p> <p>This function implements a retry mechanism with exponential backoff for handling transient HTTP errors. It attempts the request up to max_retries + 1 times, waiting progressively longer between each retry.</p> <p>The retry logic handles three types of failures: 1. Retryable HTTP status codes (e.g., 429, 500, 502, 503, 504) 2. Timeout exceptions (httpx.TimeoutException) 3. General network errors (httpx.RequestError)</p> <p>Backoff Strategy: - Default: Exponential backoff: backoff_factor * (2 ** attempt) - Custom: Use backoff_strategy parameter for alternative strategies   (Linear, Fibonacci, Constant, or custom implementations) - Jitter: Optional randomization added to prevent thundering herd - Retry-After header: If present in the response (429/503), the server's   suggested wait time is used instead of backoff calculation</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the request to.</p> required <code>method</code> <code>str</code> <p>The HTTP method name (e.g., \"GET\", \"POST\") for logging.</p> required <code>request_func</code> <code>Callable[..., Awaitable[Response]]</code> <p>The async function to call to make the request (e.g., client.get, client.post).</p> required <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is 0-indexed (0, 1, 2, ...). Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>circuit_breaker</code> <code>CircuitBreaker | None</code> <p>Optional CircuitBreaker instance to use for preventing cascading failures. When provided, the circuit breaker will track failures and stop making requests if the failure threshold is reached, transitioning to an OPEN state where requests fail fast. After a recovery timeout, it will transition to HALF_OPEN to test if the service has recovered.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the request function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; import httpx\n&gt;&gt;&gt; from aresilient import request_with_automatic_retry_async\n&gt;&gt;&gt; from aresilient.backoff import LinearBackoff\n&gt;&gt;&gt; def log_retry(info):\n...     print(f\"Retry {info.attempt}/{info.max_retries + 1}\")\n...\n&gt;&gt;&gt; async def example():\n...     async with httpx.AsyncClient() as client:\n...         response = await request_with_automatic_retry_async(\n...             url=\"https://api.example.com/data\",\n...             method=\"GET\",\n...             request_func=client.get,\n...             max_retries=5,\n...             backoff_strategy=LinearBackoff(base_delay=1.0),\n...             jitter_factor=0.1,  # Add 10% jitter\n...             max_total_time=30.0,  # Stop after 30s total\n...             max_wait_time=5.0,  # Cap backoff at 5s max\n...             on_retry=log_retry,\n...         )\n...         return response.status_code\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"}]}