{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p><code>aresilient</code> is a Python library that provides resilient HTTP request functionality with automatic retry logic and exponential backoff. Built on top of the modern httpx library, it simplifies handling transient failures in HTTP communications, making your applications more robust and fault-tolerant.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Automatic Retry Logic: Automatically retries failed requests for configurable HTTP status   codes (429, 500, 502, 503, 504 by default)</li> <li>Exponential Backoff with Optional Jitter: Implements exponential backoff strategy with   optional randomized jitter to prevent thundering herd problems and avoid overwhelming servers</li> <li>Retry-After Header Support: Respects server-specified retry delays from <code>Retry-After</code> headers   (supports both integer seconds and HTTP-date formats)</li> <li>Complete HTTP Method Support: Supports all common HTTP methods (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS)</li> <li>Async Support: Fully supports asynchronous requests for high-performance applications</li> <li>Built on httpx: Leverages the modern, async-capable httpx library</li> <li>Configurable: Customize timeout, retry attempts, backoff factors, jitter, and retryable status codes</li> <li>Callbacks for Observability: Built-in callback system for logging, metrics, and alerting   (on_request, on_retry, on_success, on_failure)</li> <li>Custom Retry Predicates: Define custom logic for retry decisions based on response content or business rules</li> <li>Type-Safe: Fully typed with comprehensive type hints</li> <li>Well-Tested: Extensive test coverage ensuring reliability</li> </ul>"},{"location":"#quick-examples","title":"Quick Examples","text":""},{"location":"#basic-get-request","title":"Basic GET Request","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n# Simple GET request with automatic retry\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\nprint(response.json())\n</code></pre>"},{"location":"#basic-post-request","title":"Basic POST Request","text":"<pre><code>from aresilient import post_with_automatic_retry\n\n# POST request with JSON payload\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\", json={\"key\": \"value\"}\n)\nprint(response.status_code)\n</code></pre>"},{"location":"#customizing-retry-behavior","title":"Customizing Retry Behavior","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n# Custom retry configuration\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=5,  # Retry up to 5 times\n    backoff_factor=1.0,  # Exponential backoff factor\n    timeout=30.0,  # 30 second timeout\n    status_forcelist=(429, 503),  # Only retry on these status codes\n)\n</code></pre>"},{"location":"#using-async","title":"Using Async","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n\n\n# Run the async function\ndata = asyncio.run(fetch_data())\nprint(data)\n</code></pre>"},{"location":"#async-with-multiple-requests","title":"Async with Multiple Requests","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_multiple():\n    urls = [\n        \"https://api.example.com/data1\",\n        \"https://api.example.com/data2\",\n        \"https://api.example.com/data3\",\n    ]\n    tasks = [get_with_automatic_retry_async(url) for url in urls]\n    responses = await asyncio.gather(*tasks)\n    return [r.json() for r in responses]\n\n\n# Fetch multiple URLs concurrently\nresults = asyncio.run(fetch_multiple())\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>Install using <code>uv</code> (recommended):</p> <pre><code>uv pip install aresilient\n</code></pre> <p>Or using <code>pip</code>:</p> <pre><code>pip install aresilient\n</code></pre>"},{"location":"#api-stability","title":"API stability","text":"<p> While <code>aresilient</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>aresilient</code> to a new version will possibly break any code that was using the old version of <code>aresilient</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>aresilient</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-uv-recommended","title":"Installing with <code>uv</code> (recommended)","text":"<p>The following command installs the latest stable version of the library:</p> <pre><code>uv pip install aresilient\n</code></pre> <p>To install the latest development version from GitHub:</p> <pre><code>uv pip install git+https://github.com/durandtibo/aresilient.git\n</code></pre> <p>To install a specific version:</p> <pre><code>uv pip install aresilient==0.3.0\n</code></pre>"},{"location":"get_started/#installing-with-pip","title":"Installing with <code>pip</code>","text":"<p>The following command installs the latest stable version of the library:</p> <pre><code>pip install aresilient\n</code></pre> <p>To install the latest development version from GitHub:</p> <pre><code>pip install git+https://github.com/durandtibo/aresilient.git\n</code></pre> <p>To install a specific version:</p> <pre><code>pip install aresilient==0.3.0\n</code></pre>"},{"location":"get_started/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, you can verify that aresilient is correctly installed by running:</p> <pre><code>python -c \"import aresilient; print(aresilient.__version__)\"\n</code></pre> <p>Or try a simple example:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Make a simple GET request (this is a safe example that won't actually execute)\n# response = get_with_automatic_retry(\"https://api.example.com/data\")\n# print(response.json())\n\n# Verify the module is properly imported\nprint(\"aresilient imported successfully!\")\n</code></pre>"},{"location":"get_started/#testing-async-support","title":"Testing Async Support","text":"<p>To verify async support is working:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def test_async():\n    print(\"Async support is working!\")\n    return True\n\n\nresult = asyncio.run(test_async())\nprint(f\"Test result: {result}\")\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>aresilient</code> from source, you can follow the steps below.</p>"},{"location":"get_started/#prerequisites","title":"Prerequisites","text":"<p>This project uses <code>uv</code> for dependency management. Please refer to the uv installation documentation for installation instructions.</p>"},{"location":"get_started/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone git@github.com:durandtibo/aresilient.git\ncd aresilient\n</code></pre>"},{"location":"get_started/#create-a-virtual-environment","title":"Create a Virtual Environment","text":"<p>It is recommended to create a Python 3.10+ virtual environment:</p> <pre><code>make setup-venv\n</code></pre> <p>This command creates a virtual environment using <code>uv</code> and installs all dependencies including development tools.</p> <p>Alternatively, you can create a conda virtual environment:</p> <pre><code>make conda\nconda activate aresilient\nmake install\n</code></pre>"},{"location":"get_started/#install-dependencies","title":"Install Dependencies","text":"<p>To install only the core dependencies:</p> <pre><code>make install\n</code></pre> <p>To install all dependencies including documentation tools:</p> <pre><code>make install-all\n</code></pre>"},{"location":"get_started/#verify-installation","title":"Verify Installation","text":"<p>You can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre> <p>This will run the test suite with coverage reporting.</p>"},{"location":"get_started/#development-setup","title":"Development Setup","text":"<p>If you plan to contribute to aresilient, please also install the development tools.</p> <p>Using <code>uv</code>:</p> <pre><code>uv pip install -e \".[dev,docs]\"\n</code></pre> <p>Using <code>pip</code>:</p> <pre><code>pip install -e \".[dev,docs]\"\n</code></pre> <p>Then install the pre-commit hooks:</p> <pre><code>pre-commit install\n</code></pre> <p>See CONTRIBUTING.md for more information about contributing.</p>"},{"location":"user_guide/","title":"User Guide","text":"<p>This guide provides comprehensive instructions on how to use <code>aresilient</code> for making resilient HTTP requests with automatic retry logic.</p>"},{"location":"user_guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Basic Usage</li> <li>Async Usage</li> <li>Configuration Options</li> <li>Advanced Usage</li> <li>Callbacks and Observability</li> <li>Error Handling</li> <li>Custom HTTP Methods</li> <li>Best Practices</li> </ul>"},{"location":"user_guide/#basic-usage","title":"Basic Usage","text":""},{"location":"user_guide/#making-get-requests","title":"Making GET Requests","text":"<p>The simplest way to make an HTTP GET request with automatic retry:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Basic GET request\nresponse = get_with_automatic_retry(\"https://api.example.com/users\")\nprint(response.json())\n</code></pre>"},{"location":"user_guide/#making-post-requests","title":"Making POST Requests","text":"<p>POST requests work similarly with support for JSON payloads and form data:</p> <pre><code>from aresilient import post_with_automatic_retry\n\n# POST with JSON payload\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/users\",\n    json={\"name\": \"John Doe\", \"email\": \"john@example.com\"},\n)\nprint(response.status_code)\n\n# POST with form data\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\", data={\"field1\": \"value1\", \"field2\": \"value2\"}\n)\n</code></pre>"},{"location":"user_guide/#other-http-methods","title":"Other HTTP Methods","text":"<p><code>aresilient</code> supports all common HTTP methods:</p> <pre><code>from aresilient import (\n    put_with_automatic_retry,\n    delete_with_automatic_retry,\n    patch_with_automatic_retry,\n)\n\n# PUT request to update a resource\nresponse = put_with_automatic_retry(\n    \"https://api.example.com/resource/123\", json={\"name\": \"updated\"}\n)\n\n# DELETE request to remove a resource\nresponse = delete_with_automatic_retry(\"https://api.example.com/resource/123\")\n\n# PATCH request to partially update a resource\nresponse = patch_with_automatic_retry(\n    \"https://api.example.com/resource/123\", json={\"status\": \"active\"}\n)\n</code></pre>"},{"location":"user_guide/#async-usage","title":"Async Usage","text":"<p><code>aresilient</code> provides asynchronous versions of all HTTP methods for use in async applications. All async functions have the same parameters as their synchronous counterparts.</p>"},{"location":"user_guide/#making-async-get-requests","title":"Making Async GET Requests","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n\n\n# Run the async function\ndata = asyncio.run(fetch_data())\nprint(data)\n</code></pre>"},{"location":"user_guide/#making-async-post-requests","title":"Making Async POST Requests","text":"<pre><code>import asyncio\nfrom aresilient import post_with_automatic_retry_async\n\n\nasync def create_user():\n    response = await post_with_automatic_retry_async(\n        \"https://api.example.com/users\",\n        json={\"name\": \"Jane Doe\", \"email\": \"jane@example.com\"},\n    )\n    return response.status_code\n\n\n# Run the async function\nstatus = asyncio.run(create_user())\nprint(f\"Status: {status}\")\n</code></pre>"},{"location":"user_guide/#other-async-http-methods","title":"Other Async HTTP Methods","text":"<p>All HTTP methods have async versions with identical parameters and callback support:</p> <pre><code>from aresilient import (\n    put_with_automatic_retry_async,\n    delete_with_automatic_retry_async,\n    patch_with_automatic_retry_async,\n    head_with_automatic_retry_async,\n    options_with_automatic_retry_async,\n)\n</code></pre> <p>Note: All async functions support the same parameters as their synchronous counterparts, including: - <code>max_retries</code>, <code>backoff_factor</code>, <code>jitter_factor</code> - <code>status_forcelist</code>, <code>retry_if</code> - <code>on_request</code>, <code>on_retry</code>, <code>on_success</code>, <code>on_failure</code> callbacks</p>"},{"location":"user_guide/#using-async-with-httpxasyncclient","title":"Using Async with httpx.AsyncClient","text":"<p>For better performance with multiple async requests, reuse an <code>httpx.AsyncClient</code>:</p> <pre><code>import asyncio\nimport httpx\nfrom aresilient import get_with_automatic_retry_async, post_with_automatic_retry_async\n\n\nasync def fetch_multiple_resources():\n    async with httpx.AsyncClient(timeout=30.0) as client:\n        # Make multiple concurrent requests\n        users_task = get_with_automatic_retry_async(\n            \"https://api.example.com/users\", client=client\n        )\n        posts_task = get_with_automatic_retry_async(\n            \"https://api.example.com/posts\", client=client\n        )\n\n        # Wait for both requests to complete\n        users, posts = await asyncio.gather(users_task, posts_task)\n\n        return users.json(), posts.json()\n\n\n# Run the async function\nusers_data, posts_data = asyncio.run(fetch_multiple_resources())\n</code></pre>"},{"location":"user_guide/#concurrent-async-requests","title":"Concurrent Async Requests","text":"<p>Process multiple URLs concurrently for better performance:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_all(urls):\n    tasks = [get_with_automatic_retry_async(url) for url in urls]\n    responses = await asyncio.gather(*tasks, return_exceptions=True)\n    return responses\n\n\n# Fetch multiple URLs concurrently\nurls = [\n    \"https://api.example.com/data1\",\n    \"https://api.example.com/data2\",\n    \"https://api.example.com/data3\",\n]\nresponses = asyncio.run(fetch_all(urls))\n</code></pre>"},{"location":"user_guide/#configuration-options","title":"Configuration Options","text":""},{"location":"user_guide/#default-configuration","title":"Default Configuration","text":"<p><code>aresilient</code> comes with sensible defaults:</p> <pre><code>from aresilient import (\n    DEFAULT_TIMEOUT,  # 10.0 seconds\n    DEFAULT_MAX_RETRIES,  # 3 retries (4 total attempts)\n    DEFAULT_BACKOFF_FACTOR,  # 0.3 seconds\n    RETRY_STATUS_CODES,  # (429, 500, 502, 503, 504)\n)\n\nprint(f\"Timeout: {DEFAULT_TIMEOUT}\")\nprint(f\"Max retries: {DEFAULT_MAX_RETRIES}\")\nprint(f\"Backoff factor: {DEFAULT_BACKOFF_FACTOR}\")\nprint(f\"Retry on status codes: {RETRY_STATUS_CODES}\")\n</code></pre>"},{"location":"user_guide/#customizing-timeout","title":"Customizing Timeout","text":"<p>Control how long to wait for a server response:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Short timeout for quick responses\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/health\", timeout=5.0  # 5 seconds\n)\n\n# Longer timeout for slow endpoints\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/slow-endpoint\", timeout=60.0  # 60 seconds\n)\n</code></pre> <p>You can also use httpx.Timeout for fine-grained control:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry\n\n# Different timeouts for different operations\ntimeout = httpx.Timeout(\n    connect=5.0,  # 5 seconds to establish connection\n    read=30.0,  # 30 seconds to read response\n    write=10.0,  # 10 seconds to send request\n    pool=5.0,  # 5 seconds to get connection from pool\n)\n\nresponse = get_with_automatic_retry(\"https://api.example.com/data\", timeout=timeout)\n</code></pre>"},{"location":"user_guide/#customizing-retry-behavior","title":"Customizing Retry Behavior","text":"<p>Control how many times and how long between retries:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# More aggressive retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=5,  # Retry up to 5 times\n    backoff_factor=0.5,  # Longer waits between retries\n)\n\n# Less aggressive retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=1,  # Only retry once\n    backoff_factor=0.1,  # Shorter waits between retries\n)\n\n# With jitter to prevent thundering herd\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=3,\n    backoff_factor=0.5,\n    jitter_factor=0.1,  # Add 10% random jitter\n)\n\n# No retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", max_retries=0  # No retries, fail immediately\n)\n</code></pre>"},{"location":"user_guide/#understanding-exponential-backoff","title":"Understanding Exponential Backoff","text":"<p>The wait time between retries is calculated using the exponential backoff formula:</p> <pre><code>base_wait_time = backoff_factor * (2 ** attempt)\n# If jitter_factor is set (e.g., 0.1 for 10% jitter):\njitter = random(0, jitter_factor) * base_wait_time\ntotal_wait_time = base_wait_time + jitter\n</code></pre> <p>Where <code>attempt</code> is 0-indexed (0, 1, 2, ...).</p>"},{"location":"user_guide/#example-with-default-backoff_factor03-no-jitter","title":"Example with default <code>backoff_factor=0.3</code> (no jitter):","text":"<ul> <li>1st retry: 0.3 * (2^0) = 0.3 seconds</li> <li>2nd retry: 0.3 * (2^1) = 0.6 seconds</li> <li>3rd retry: 0.3 * (2^2) = 1.2 seconds</li> </ul>"},{"location":"user_guide/#example-with-backoff_factor10-and-jitter_factor01","title":"Example with <code>backoff_factor=1.0</code> and <code>jitter_factor=0.1</code>:","text":"<ul> <li>1st retry: 1.0-1.1 seconds (base 1.0s + up to 10% jitter)</li> <li>2nd retry: 2.0-2.2 seconds (base 2.0s + up to 10% jitter)</li> <li>3rd retry: 4.0-4.4 seconds (base 4.0s + up to 10% jitter)</li> </ul> <p>Note: Jitter is optional (disabled by default with <code>jitter_factor=0</code>). When enabled, it's randomized for each retry to prevent multiple clients from retrying simultaneously (thundering herd problem). Set <code>jitter_factor=0.1</code> for 10% jitter, which is recommended for production use.</p>"},{"location":"user_guide/#customizing-retryable-status-codes","title":"Customizing Retryable Status Codes","text":"<p>By default, <code>aresilient</code> retries on status codes 429, 500, 502, 503, and 504. You can customize this:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Only retry on rate limiting\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", status_forcelist=(429,)\n)\n\n# Retry on server errors and rate limiting\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", status_forcelist=(429, 500, 502, 503, 504)\n)\n\n# Add custom status codes\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    status_forcelist=(408, 429, 500, 502, 503, 504),  # Include 408 Request Timeout\n)\n</code></pre>"},{"location":"user_guide/#retry-after-header-support","title":"Retry-After Header Support","text":"<p>When a server returns a <code>Retry-After</code> header (commonly with 429 or 503 status codes), <code>aresilient</code> automatically uses the server's suggested wait time instead of exponential backoff. This ensures compliance with rate limiting and helps avoid overwhelming the server.</p> <p>The <code>Retry-After</code> header supports two formats:</p> <pre><code># Server responds with: Retry-After: 120\n# aresilient will wait 120 seconds before retrying\n\n# Server responds with: Retry-After: Wed, 21 Oct 2015 07:28:00 GMT\n# aresilient will wait until this time before retrying\n</code></pre> <p>The retry delay from the <code>Retry-After</code> header is used automatically - you don't need to configure anything. This works with all HTTP methods (GET, POST, PUT, DELETE, PATCH).</p> <p>Note: If <code>jitter_factor</code> is configured, jitter is still applied to server-specified <code>Retry-After</code> values to prevent thundering herd issues when many clients receive the same retry delay from a server.</p>"},{"location":"user_guide/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user_guide/#using-a-custom-httpx-client","title":"Using a Custom httpx Client","text":"<p>For advanced configurations like custom headers, authentication, or connection pooling:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry\n\n# Create a client with custom headers\nwith httpx.Client(\n    headers={\"User-Agent\": \"MyApp/1.0\", \"Authorization\": \"Bearer your-token-here\"}\n) as client:\n    response = get_with_automatic_retry(\n        \"https://api.example.com/protected\", client=client\n    )\n    print(response.json())\n</code></pre>"},{"location":"user_guide/#reusing-client-for-multiple-requests","title":"Reusing Client for Multiple Requests","text":"<p>When making multiple requests, reuse the same client for better performance:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry, post_with_automatic_retry\n\nwith httpx.Client(headers={\"Authorization\": \"Bearer token\"}, timeout=30.0) as client:\n    # Multiple requests using the same client\n    users = get_with_automatic_retry(\"https://api.example.com/users\", client=client)\n\n    posts = get_with_automatic_retry(\"https://api.example.com/posts\", client=client)\n\n    result = post_with_automatic_retry(\n        \"https://api.example.com/data\", client=client, json={\"data\": \"value\"}\n    )\n</code></pre>"},{"location":"user_guide/#passing-additional-httpx-arguments","title":"Passing Additional httpx Arguments","text":"<p>All <code>**kwargs</code> are passed directly to the underlying httpx methods:</p> <pre><code>from aresilient import get_with_automatic_retry, post_with_automatic_retry\n\n# GET with query parameters\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/search\", params={\"q\": \"python\", \"page\": 1}\n)\n\n# GET with custom headers (without custom client)\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", headers={\"X-Custom-Header\": \"value\"}\n)\n\n# POST with files\nwith open(\"document.pdf\", \"rb\") as f:\n    response = post_with_automatic_retry(\n        \"https://api.example.com/upload\", files={\"file\": f}\n    )\n\n# POST with both data and files\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\",\n    data={\"title\": \"My Document\"},\n    files={\"attachment\": open(\"file.txt\", \"rb\")},\n)\n</code></pre>"},{"location":"user_guide/#callbacks-and-observability","title":"Callbacks and Observability","text":"<p><code>aresilient</code> provides a comprehensive callback/event system for observability, enabling you to hook into the retry lifecycle for logging, metrics collection, alerting, and custom behavior. This is particularly useful for production applications where you need to monitor HTTP request patterns, track retry rates, and integrate with your observability stack.</p>"},{"location":"user_guide/#available-callbacks","title":"Available Callbacks","text":"<p>The library provides four lifecycle hooks:</p> <ul> <li><code>on_request</code>: Called before each request attempt (including the initial request)</li> <li><code>on_retry</code>: Called before each retry (after backoff delay calculation)</li> <li><code>on_success</code>: Called when a request succeeds</li> <li><code>on_failure</code>: Called when all retries are exhausted and the request fails</li> </ul> <p>All callbacks are optional and can be used independently or together. They work with both synchronous and asynchronous functions.</p>"},{"location":"user_guide/#callback-signatures","title":"Callback Signatures","text":"<p>Each callback receives a dataclass with relevant information:</p>"},{"location":"user_guide/#requestinfo-for-on_request","title":"RequestInfo (for <code>on_request</code>)","text":"<pre><code>@dataclass\nclass RequestInfo:\n    url: str          # The URL being requested\n    method: str       # HTTP method (e.g., \"GET\", \"POST\")\n    attempt: int      # Current attempt number (1-indexed, first attempt is 1)\n    max_retries: int  # Maximum number of retry attempts configured\n</code></pre>"},{"location":"user_guide/#retryinfo-for-on_retry","title":"RetryInfo (for <code>on_retry</code>)","text":"<pre><code>@dataclass\nclass RetryInfo:\n    url: str               # The URL being requested\n    method: str            # HTTP method\n    attempt: int           # Current attempt number (1-indexed, first retry is attempt 2)\n    max_retries: int       # Maximum retry attempts configured\n    wait_time: float       # Sleep time in seconds before this retry\n    error: Exception | None      # Exception that triggered the retry (if any)\n    status_code: int | None      # HTTP status code that triggered retry (if any)\n</code></pre>"},{"location":"user_guide/#responseinfo-for-on_success","title":"ResponseInfo (for <code>on_success</code>)","text":"<pre><code>@dataclass\nclass ResponseInfo:\n    url: str                   # The URL that was requested\n    method: str                # HTTP method\n    attempt: int               # Attempt number that succeeded (1-indexed)\n    max_retries: int           # Maximum retry attempts configured\n    response: httpx.Response   # The successful HTTP response object\n    total_time: float          # Total time spent on all attempts including backoff (seconds)\n</code></pre>"},{"location":"user_guide/#failureinfo-for-on_failure","title":"FailureInfo (for <code>on_failure</code>)","text":"<pre><code>@dataclass\nclass FailureInfo:\n    url: str             # The URL that was requested\n    method: str          # HTTP method\n    attempt: int         # Final attempt number (1-indexed)\n    max_retries: int     # Maximum retry attempts configured\n    error: Exception     # The final exception that caused failure\n    status_code: int | None  # Final HTTP status code (if any)\n    total_time: float    # Total time spent on all attempts including backoff (seconds)\n</code></pre>"},{"location":"user_guide/#basic-logging-example","title":"Basic Logging Example","text":"<p>Track each phase of the request lifecycle:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\ndef log_request(info):\n    print(f\"[REQUEST] {info.method} {info.url} - Attempt {info.attempt}/{info.max_retries + 1}\")\n\n\ndef log_retry(info):\n    reason = f\"status={info.status_code}\" if info.status_code else f\"error={type(info.error).__name__}\"\n    print(\n        f\"[RETRY] {info.method} {info.url} - \"\n        f\"Attempt {info.attempt}/{info.max_retries + 1}, \"\n        f\"waiting {info.wait_time:.2f}s, reason={reason}\"\n    )\n\n\ndef log_success(info):\n    print(\n        f\"[SUCCESS] {info.method} {info.url} - \"\n        f\"Succeeded on attempt {info.attempt} \"\n        f\"({info.total_time:.2f}s total, status={info.response.status_code})\"\n    )\n\n\ndef log_failure(info):\n    reason = f\"status={info.status_code}\" if info.status_code else f\"error={type(info.error).__name__}\"\n    print(\n        f\"[FAILURE] {info.method} {info.url} - \"\n        f\"Failed after {info.attempt} attempts \"\n        f\"({info.total_time:.2f}s total), reason={reason}\"\n    )\n\n\n# Use callbacks for comprehensive logging\ntry:\n    response = get_with_automatic_retry(\n        \"https://api.example.com/data\",\n        max_retries=3,\n        on_request=log_request,\n        on_retry=log_retry,\n        on_success=log_success,\n        on_failure=log_failure,\n    )\nexcept Exception as e:\n    pass  # Error already logged in on_failure\n</code></pre> <p>Example output: <pre><code>[REQUEST] GET https://api.example.com/data - Attempt 1/4\n[RETRY] GET https://api.example.com/data - Attempt 2/4, waiting 0.30s, reason=status=503\n[REQUEST] GET https://api.example.com/data - Attempt 2/4\n[RETRY] GET https://api.example.com/data - Attempt 3/4, waiting 0.60s, reason=status=503\n[REQUEST] GET https://api.example.com/data - Attempt 3/4\n[SUCCESS] GET https://api.example.com/data - Succeeded on attempt 3 (1.15s total, status=200)\n</code></pre></p>"},{"location":"user_guide/#metrics-collection-example","title":"Metrics Collection Example","text":"<p>Track statistics across multiple requests:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass RequestMetrics:\n    \"\"\"Collect metrics for HTTP requests with retries.\"\"\"\n\n    def __init__(self):\n        self.total_requests = 0\n        self.total_retries = 0\n        self.successes = 0\n        self.failures = 0\n        self.total_time = 0.0\n        self.retry_reasons = {}  # Track why retries happened\n\n    def on_request(self, info):\n        self.total_requests += 1\n\n    def on_retry(self, info):\n        self.total_retries += 1\n        # Track retry reasons\n        reason = info.status_code if info.status_code else type(info.error).__name__\n        self.retry_reasons[reason] = self.retry_reasons.get(reason, 0) + 1\n\n    def on_success(self, info):\n        self.successes += 1\n        self.total_time += info.total_time\n\n    def on_failure(self, info):\n        self.failures += 1\n        self.total_time += info.total_time\n\n    def summary(self):\n        \"\"\"Print a summary of collected metrics.\"\"\"\n        total_completed = self.successes + self.failures\n        success_rate = (self.successes / total_completed * 100) if total_completed &gt; 0 else 0\n        avg_time = (self.total_time / total_completed) if total_completed &gt; 0 else 0\n\n        print(f\"=== Request Metrics Summary ===\")\n        print(f\"Total requests made: {self.total_requests}\")\n        print(f\"Total retries: {self.total_retries}\")\n        print(f\"Successes: {self.successes}\")\n        print(f\"Failures: {self.failures}\")\n        print(f\"Success rate: {success_rate:.1f}%\")\n        print(f\"Average time: {avg_time:.2f}s\")\n        print(f\"Retry reasons: {self.retry_reasons}\")\n\n\n# Collect metrics across multiple requests\nmetrics = RequestMetrics()\n\nurls = [\n    \"https://api.example.com/endpoint1\",\n    \"https://api.example.com/endpoint2\",\n    \"https://api.example.com/endpoint3\",\n]\n\nfor url in urls:\n    try:\n        response = get_with_automatic_retry(\n            url,\n            on_request=metrics.on_request,\n            on_retry=metrics.on_retry,\n            on_success=metrics.on_success,\n            on_failure=metrics.on_failure,\n        )\n    except Exception:\n        pass  # Metrics already tracked\n\nmetrics.summary()\n</code></pre>"},{"location":"user_guide/#integration-with-logging-frameworks","title":"Integration with Logging Frameworks","text":"<p>Integrate with Python's standard logging module:</p> <pre><code>import logging\nfrom aresilient import get_with_automatic_retry\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n)\n\nlogger = logging.getLogger(\"http_client\")\n\n\ndef log_retry_event(info):\n    \"\"\"Log retry events with structured information.\"\"\"\n    logger.warning(\n        \"HTTP request retry\",\n        extra={\n            \"url\": info.url,\n            \"method\": info.method,\n            \"attempt\": info.attempt,\n            \"max_retries\": info.max_retries,\n            \"wait_time\": info.wait_time,\n            \"status_code\": info.status_code,\n            \"error\": str(info.error) if info.error else None,\n        },\n    )\n\n\ndef log_failure_event(info):\n    \"\"\"Log failure events with full context.\"\"\"\n    logger.error(\n        \"HTTP request failed after retries\",\n        extra={\n            \"url\": info.url,\n            \"method\": info.method,\n            \"attempts\": info.attempt,\n            \"total_time\": info.total_time,\n            \"status_code\": info.status_code,\n            \"error\": str(info.error),\n        },\n    )\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_retry=log_retry_event,\n    on_failure=log_failure_event,\n)\n</code></pre>"},{"location":"user_guide/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>Send metrics to a monitoring system:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass MonitoringClient:\n    \"\"\"Send metrics to your monitoring system (e.g., Prometheus, Datadog, CloudWatch).\"\"\"\n\n    def __init__(self):\n        # Initialize your metrics client here\n        pass\n\n    def increment_counter(self, metric_name, tags=None):\n        \"\"\"Increment a counter metric.\"\"\"\n        # Your implementation here\n        pass\n\n    def record_histogram(self, metric_name, value, tags=None):\n        \"\"\"Record a histogram/distribution value.\"\"\"\n        # Your implementation here\n        pass\n\n\nmonitoring = MonitoringClient()\n\n\ndef track_retry(info):\n    \"\"\"Track retry events in monitoring system.\"\"\"\n    monitoring.increment_counter(\n        \"http.retries\",\n        tags={\n            \"method\": info.method,\n            \"status_code\": str(info.status_code) if info.status_code else \"network_error\",\n        },\n    )\n\n\ndef track_success(info):\n    \"\"\"Track successful requests.\"\"\"\n    monitoring.increment_counter(\"http.success\", tags={\"method\": info.method})\n    monitoring.record_histogram(\"http.duration\", info.total_time, tags={\"method\": info.method})\n\n\ndef track_failure(info):\n    \"\"\"Track failed requests.\"\"\"\n    monitoring.increment_counter(\n        \"http.failure\",\n        tags={\n            \"method\": info.method,\n            \"status_code\": str(info.status_code) if info.status_code else \"network_error\",\n        },\n    )\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_retry=track_retry,\n    on_success=track_success,\n    on_failure=track_failure,\n)\n</code></pre>"},{"location":"user_guide/#async-callbacks","title":"Async Callbacks","text":"<p>Callbacks work identically with async functions:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def async_log_retry(info):\n    \"\"\"Callbacks for async functions are still synchronous.\"\"\"\n    print(f\"Retrying {info.url} after {info.wait_time:.2f}s\")\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\n        \"https://api.example.com/data\", on_retry=async_log_retry\n    )\n    return response.json()\n\n\nasyncio.run(fetch_data())\n</code></pre> <p>Note: Callbacks themselves are synchronous functions even when used with async HTTP methods. If you need to perform async operations in callbacks (e.g., async logging), you'll need to handle that separately.</p>"},{"location":"user_guide/#custom-alerting-on-failures","title":"Custom Alerting on Failures","text":"<p>Send alerts when requests fail after all retries:</p> <pre><code>from aresilient import post_with_automatic_retry\n\n\ndef send_alert_on_failure(info):\n    \"\"\"Send an alert when a critical API request fails.\"\"\"\n    if \"critical-api\" in info.url:\n        alert_message = (\n            f\"CRITICAL: API request failed!\\n\"\n            f\"URL: {info.url}\\n\"\n            f\"Method: {info.method}\\n\"\n            f\"Attempts: {info.attempt}\\n\"\n            f\"Total Time: {info.total_time:.2f}s\\n\"\n            f\"Error: {info.error}\\n\"\n            f\"Status Code: {info.status_code}\"\n        )\n        # Send to your alerting system (PagerDuty, Slack, email, etc.)\n        # send_slack_alert(alert_message)\n        # send_email_alert(alert_message)\n        print(alert_message)\n\n\ntry:\n    response = post_with_automatic_retry(\n        \"https://critical-api.example.com/important\",\n        json={\"data\": \"value\"},\n        on_failure=send_alert_on_failure,\n    )\nexcept Exception:\n    pass  # Alert already sent\n</code></pre>"},{"location":"user_guide/#combining-multiple-callbacks","title":"Combining Multiple Callbacks","text":"<p>You can use multiple callbacks together for comprehensive observability:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass RequestObserver:\n    \"\"\"Comprehensive request observer combining logging, metrics, and alerting.\"\"\"\n\n    def __init__(self, logger, metrics, alerting):\n        self.logger = logger\n        self.metrics = metrics\n        self.alerting = alerting\n\n    def on_request(self, info):\n        self.logger.debug(f\"Starting {info.method} {info.url}\")\n        self.metrics.on_request(info)\n\n    def on_retry(self, info):\n        self.logger.warning(f\"Retrying {info.method} {info.url}\")\n        self.metrics.on_retry(info)\n\n    def on_success(self, info):\n        self.logger.info(f\"Success {info.method} {info.url} in {info.total_time:.2f}s\")\n        self.metrics.on_success(info)\n\n    def on_failure(self, info):\n        self.logger.error(f\"Failed {info.method} {info.url}\")\n        self.metrics.on_failure(info)\n        self.alerting.send_alert(info)\n\n\n# Create observer with your components\nobserver = RequestObserver(logger, metrics, alerting)\n\n# Use all callbacks\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_request=observer.on_request,\n    on_retry=observer.on_retry,\n    on_success=observer.on_success,\n    on_failure=observer.on_failure,\n)\n</code></pre>"},{"location":"user_guide/#best-practices-for-callbacks","title":"Best Practices for Callbacks","text":"<ol> <li> <p>Keep callbacks lightweight: Callbacks are called synchronously and will block the request flow. Avoid heavy computations or blocking I/O.</p> </li> <li> <p>Handle exceptions in callbacks: If a callback raises an exception, it will propagate and potentially abort the request. Wrap callback code in try/except if needed.</p> </li> <li> <p>Use structured logging: Include relevant context (URL, method, attempt number) in log messages for better debugging.</p> </li> <li> <p>Sample high-volume metrics: For high-traffic applications, consider sampling metrics to reduce overhead.</p> </li> <li> <p>Separate concerns: Use <code>on_retry</code> for retry-specific metrics, <code>on_success</code> for latency tracking, and <code>on_failure</code> for alerting.</p> </li> </ol>"},{"location":"user_guide/#error-handling","title":"Error Handling","text":""},{"location":"user_guide/#understanding-httprequesterror","title":"Understanding HttpRequestError","text":"<p><code>aresilient</code> raises <code>HttpRequestError</code> when a request fails after all retries:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/data\")\nexcept HttpRequestError as e:\n    print(f\"Request failed: {e}\")\n    print(f\"Method: {e.method}\")  # 'GET'\n    print(f\"URL: {e.url}\")  # 'https://api.example.com/data'\n    print(f\"Status Code: {e.status_code}\")  # e.g., 500\n    if e.response:\n        print(f\"Response body: {e.response.text}\")\n</code></pre>"},{"location":"user_guide/#common-error-scenarios","title":"Common Error Scenarios","text":""},{"location":"user_guide/#timeout-errors","title":"Timeout Errors","text":"<p>When a request times out after all retries:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\n        \"https://slow-api.example.com/data\", timeout=1.0, max_retries=2\n    )\nexcept HttpRequestError as e:\n    # status_code will be None for timeout errors\n    if e.status_code is None:\n        print(\"Request timed out\")\n</code></pre>"},{"location":"user_guide/#network-errors","title":"Network Errors","text":"<p>When the connection fails (DNS errors, connection refused, etc.):</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://nonexistent-domain.invalid\")\nexcept HttpRequestError as e:\n    if e.status_code is None:\n        print(f\"Network error: {e}\")\n</code></pre>"},{"location":"user_guide/#http-error-responses","title":"HTTP Error Responses","text":"<p>When the server returns an error status code:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/not-found\")\nexcept HttpRequestError as e:\n    if e.status_code == 404:\n        print(\"Resource not found\")\n    elif e.status_code == 401:\n        print(\"Unauthorized\")\n    elif e.status_code == 403:\n        print(\"Forbidden\")\n</code></pre>"},{"location":"user_guide/#validating-responses","title":"Validating Responses","text":"<p>Check response status and content:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/data\")\n\n    # Response is automatically successful (2xx or 3xx)\n    # if we get here\n    data = response.json()\n\n    # Additional validation if needed\n    if \"error\" in data:\n        print(f\"API returned an error: {data['error']}\")\n\nexcept HttpRequestError as e:\n    print(f\"Request failed: {e}\")\nexcept ValueError as e:\n    print(f\"Invalid JSON response: {e}\")\n</code></pre>"},{"location":"user_guide/#error-handling-with-async","title":"Error Handling with Async","text":"<p>Error handling works the same way with async functions:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async, HttpRequestError\n\n\nasync def fetch_with_error_handling():\n    try:\n        response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n        return response.json()\n    except HttpRequestError as e:\n        print(f\"Async request failed: {e}\")\n        print(f\"Status Code: {e.status_code}\")\n        return None\n\n\nresult = asyncio.run(fetch_with_error_handling())\n</code></pre>"},{"location":"user_guide/#custom-http-methods","title":"Custom HTTP Methods","text":"<p>For HTTP methods not directly supported or for custom needs, use the <code>request_with_automatic_retry</code> and <code>request_with_automatic_retry_async</code> functions.</p>"},{"location":"user_guide/#synchronous-custom-requests","title":"Synchronous Custom Requests","text":"<pre><code>import httpx\nfrom aresilient import request_with_automatic_retry\n\n# Example: Using HEAD method\nwith httpx.Client() as client:\n    response = request_with_automatic_retry(\n        url=\"https://api.example.com/resource\",\n        method=\"HEAD\",\n        request_func=client.head,\n        max_retries=3,\n    )\n    print(f\"Content-Length: {response.headers.get('content-length')}\")\n\n# Example: Using OPTIONS method\nwith httpx.Client() as client:\n    response = request_with_automatic_retry(\n        url=\"https://api.example.com/resource\",\n        method=\"OPTIONS\",\n        request_func=client.options,\n    )\n    print(f\"Allowed methods: {response.headers.get('allow')}\")\n</code></pre>"},{"location":"user_guide/#async-custom-requests","title":"Async Custom Requests","text":"<pre><code>import asyncio\nimport httpx\nfrom aresilient import request_with_automatic_retry_async\n\n\nasync def make_custom_request():\n    async with httpx.AsyncClient() as client:\n        # Using HEAD method asynchronously\n        response = await request_with_automatic_retry_async(\n            url=\"https://api.example.com/resource\",\n            method=\"HEAD\",\n            request_func=client.head,\n            max_retries=3,\n        )\n        return response.headers.get(\"content-length\")\n\n\ncontent_length = asyncio.run(make_custom_request())\n</code></pre>"},{"location":"user_guide/#advanced-custom-request-example","title":"Advanced Custom Request Example","text":"<pre><code>import httpx\nfrom aresilient import request_with_automatic_retry\n\n\ndef custom_api_call():\n    with httpx.Client(timeout=30.0) as client:\n        # Custom request with specific retry configuration\n        response = request_with_automatic_retry(\n            url=\"https://api.example.com/custom-endpoint\",\n            method=\"PATCH\",\n            request_func=client.patch,\n            max_retries=5,\n            backoff_factor=1.0,\n            status_forcelist=(429, 503),\n            # Additional kwargs passed to client.patch\n            json={\"operation\": \"update\", \"value\": 42},\n            headers={\"X-API-Version\": \"2.0\"},\n        )\n        return response.json()\n</code></pre>"},{"location":"user_guide/#best-practices","title":"Best Practices","text":""},{"location":"user_guide/#1-use-appropriate-timeouts","title":"1. Use Appropriate Timeouts","text":"<p>Set timeouts based on your expected response times:</p> <pre><code># Quick health check\nresponse = get_with_automatic_retry(\"https://api.example.com/health\", timeout=5.0)\n\n# Large data download\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/large-dataset\", timeout=120.0\n)\n</code></pre>"},{"location":"user_guide/#2-reuse-http-clients","title":"2. Reuse HTTP Clients","text":"<p>When making multiple requests, reuse the client to benefit from connection pooling:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry\n\n# Good: Reuse client\nwith httpx.Client() as client:\n    for url in urls:\n        response = get_with_automatic_retry(url, client=client)\n        process_response(response)\n\n# Bad: Creates new client for each request\nfor url in urls:\n    response = get_with_automatic_retry(url)\n    process_response(response)\n</code></pre>"},{"location":"user_guide/#3-adjust-retry-strategy-based-on-use-case","title":"3. Adjust Retry Strategy Based on Use Case","text":"<p>For user-facing operations, use fewer retries for faster failure:</p> <pre><code># User-facing: fail fast\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/user-data\", max_retries=1, timeout=10.0\n)\n</code></pre> <p>For background jobs, use more retries:</p> <pre><code># Background job: be more resilient\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/batch-process\",\n    max_retries=5,\n    backoff_factor=1.0,\n    timeout=60.0,\n)\n</code></pre>"},{"location":"user_guide/#4-handle-rate-limiting-gracefully","title":"4. Handle Rate Limiting Gracefully","text":"<p>If you're hitting rate limits frequently, consider:</p> <pre><code># Increase backoff for rate-limited endpoints\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/rate-limited\",\n    max_retries=5,\n    backoff_factor=2.0,  # Longer waits\n    status_forcelist=(429,),  # Only retry on rate limit\n)\n</code></pre>"},{"location":"user_guide/#5-use-async-for-io-bound-operations","title":"5. Use Async for I/O-Bound Operations","text":"<p>When making multiple HTTP requests, async can significantly improve performance:</p> <pre><code>import asyncio\nimport httpx\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_all_data(urls):\n    async with httpx.AsyncClient() as client:\n        tasks = [get_with_automatic_retry_async(url, client=client) for url in urls]\n        responses = await asyncio.gather(*tasks)\n        return [r.json() for r in responses]\n\n\n# Fetch 10 URLs concurrently instead of sequentially\nurls = [f\"https://api.example.com/item/{i}\" for i in range(10)]\nresults = asyncio.run(fetch_all_data(urls))\n</code></pre>"},{"location":"user_guide/#6-choose-between-sync-and-async-based-on-your-application","title":"6. Choose Between Sync and Async Based on Your Application","text":"<p>Use synchronous functions when:</p> <ul> <li>Your application is not using asyncio</li> <li>You're making single, occasional requests</li> <li>Your code is primarily synchronous</li> <li>You're writing simple scripts or command-line tools</li> </ul> <p>Use async functions when:</p> <ul> <li>Your application already uses asyncio</li> <li>You need to make multiple concurrent requests</li> <li>You're building a web application (e.g., FastAPI, Sanic)</li> <li>Performance and scalability are critical</li> </ul> <pre><code># Synchronous example - simple script\nfrom aresilient import get_with_automatic_retry\n\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\nprint(response.json())\n</code></pre> <pre><code># Async example - FastAPI application\nfrom fastapi import FastAPI\nfrom aresilient import get_with_automatic_retry_async\n\napp = FastAPI()\n\n\n@app.get(\"/fetch-data\")\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n</code></pre>"},{"location":"user_guide/#7-enable-debug-logging-for-troubleshooting","title":"7. Enable Debug Logging for Troubleshooting","text":"<p><code>aresilient</code> uses Python's standard <code>logging</code> module to provide detailed debug information about retries, backoff times, and errors. This can be helpful for troubleshooting issues or understanding retry behavior.</p> <pre><code>import logging\nfrom aresilient import get_with_automatic_retry\n\n# Enable debug logging to see retry details\nlogging.basicConfig(level=logging.DEBUG)\n\n# This will log:\n# - Each retry attempt\n# - Wait times between retries\n# - Whether Retry-After header is being used\n# - Success/failure of each attempt\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\n</code></pre> <p>Example debug output: <pre><code>DEBUG:aresilient.request:GET request to https://api.example.com/data failed with status 503 (attempt 1/4)\nDEBUG:aresilient.utils:Waiting 0.30s before retry\nDEBUG:aresilient.request:GET request to https://api.example.com/data succeeded on attempt 2\n</code></pre></p> <p>For production use, keep the default log level (INFO or WARNING) to avoid excessive logging.</p>"},{"location":"user_guide/#additional-resources","title":"Additional Resources","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Get Started - Installation and setup instructions</li> <li>httpx Documentation - Learn more about the underlying library</li> </ul>"},{"location":"refs/","title":"Main classes and functions","text":""},{"location":"refs/#aresilient","title":"aresilient","text":"<p>aresilient - Resilient HTTP request library with automatic retry logic.</p> <p>This package provides resilient HTTP request functionality with automatic retry logic and exponential backoff. Built on top of the modern httpx library, it simplifies handling transient failures in HTTP communications, making your applications more robust and fault-tolerant.</p> Key Features <ul> <li>Automatic retry logic for transient HTTP errors (429, 500, 502, 503, 504)</li> <li>Exponential backoff with optional jitter to prevent thundering herd problems</li> <li>Retry-After header support (both integer seconds and HTTP-date formats)</li> <li>Complete HTTP method support (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS)</li> <li>Full async support for high-performance applications</li> <li>Configurable timeout, retry attempts, backoff factors, and jitter</li> <li>Enhanced error handling with detailed exception information</li> <li>Callback/Event system for observability (logging, metrics, alerting)</li> </ul> Example <pre><code>&gt;&gt;&gt; from aresilient import get_with_automatic_retry\n&gt;&gt;&gt; response = get_with_automatic_retry(\"https://api.example.com/data\")  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.FailureInfo","title":"aresilient.FailureInfo  <code>dataclass</code>","text":"<p>Information passed to on_failure callback.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL that was requested.</p> <code>method</code> <code>str</code> <p>The HTTP method (e.g., \"GET\", \"POST\").</p> <code>attempt</code> <code>int</code> <p>The final attempt number (1-indexed).</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts configured.</p> <code>error</code> <code>Exception</code> <p>The final exception that caused the failure.</p> <code>status_code</code> <code>int | None</code> <p>The final HTTP status code (if any).</p> <code>total_time</code> <code>float</code> <p>Total time spent on all attempts including backoff (seconds).</p>"},{"location":"refs/#aresilient.HttpRequestError","title":"aresilient.HttpRequestError","text":"<p>               Bases: <code>RuntimeError</code></p> <p>Exception raised when an HTTP request fails.</p> <p>This exception captures comprehensive details about failed HTTP requests, including the request method, URL, status code, and the full response object when available. It supports exception chaining to preserve the original cause of the error.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The HTTP method used for the request (e.g., 'GET', 'POST').</p> required <code>url</code> <code>str</code> <p>The target URL that was requested.</p> required <code>message</code> <code>str</code> <p>A descriptive error message explaining the failure.</p> required <code>status_code</code> <code>int | None</code> <p>The HTTP status code returned by the server, if the request reached the server. Defaults to <code>None</code> if the request failed before receiving a response.</p> <code>None</code> <code>response</code> <code>Response | None</code> <p>The complete httpx.Response object containing headers, body, and other response details. Defaults to <code>None</code> if no response was received.</p> <code>None</code> <code>cause</code> <code>BaseException | None</code> <p>The original exception that caused this error, used for exception chaining. Defaults to <code>None</code>.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>The HTTP method used for the request.</p> <code>url</code> <code>str</code> <p>The target URL that was requested.</p> <code>status_code</code> <code>int | None</code> <p>The HTTP status code, if available.</p> <code>response</code> <code>Response | None</code> <p>The full response object, if available.</p> <p>Examples:</p> <p>Raising an error for a failed GET request:</p> <pre><code>&gt;&gt;&gt; from aresilient import HttpRequestError\n&gt;&gt;&gt; raise HttpRequestError(\n...     method=\"GET\",\n...     url=\"https://api.example.com/data\",\n...     message=\"Request failed with status 404\",\n...     status_code=404,\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.RequestInfo","title":"aresilient.RequestInfo  <code>dataclass</code>","text":"<p>Information passed to on_request callback.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL being requested.</p> <code>method</code> <code>str</code> <p>The HTTP method (e.g., \"GET\", \"POST\").</p> <code>attempt</code> <code>int</code> <p>The current attempt number (1-indexed). First attempt is 1.</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts configured.</p>"},{"location":"refs/#aresilient.ResponseInfo","title":"aresilient.ResponseInfo  <code>dataclass</code>","text":"<p>Information passed to on_success callback.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL that was requested.</p> <code>method</code> <code>str</code> <p>The HTTP method (e.g., \"GET\", \"POST\").</p> <code>attempt</code> <code>int</code> <p>The attempt number that succeeded (1-indexed).</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts configured.</p> <code>response</code> <code>Response</code> <p>The successful HTTP response object.</p> <code>total_time</code> <code>float</code> <p>Total time spent on all attempts including backoff (seconds).</p>"},{"location":"refs/#aresilient.RetryInfo","title":"aresilient.RetryInfo  <code>dataclass</code>","text":"<p>Information passed to on_retry callback.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL being requested.</p> <code>method</code> <code>str</code> <p>The HTTP method (e.g., \"GET\", \"POST\").</p> <code>attempt</code> <code>int</code> <p>The current attempt number (1-indexed). First retry is attempt 2.</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts configured.</p> <code>wait_time</code> <code>float</code> <p>The sleep time in seconds before this retry.</p> <code>error</code> <code>Exception | None</code> <p>The exception that triggered the retry (if any).</p> <code>status_code</code> <code>int | None</code> <p>The HTTP status code that triggered the retry (if any).</p>"},{"location":"refs/#aresilient.delete_with_automatic_retry","title":"aresilient.delete_with_automatic_retry","text":"<pre><code>delete_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP DELETE request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP DELETE request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the DELETE request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.delete()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import delete_with_automatic_retry\n&gt;&gt;&gt; response = delete_with_automatic_retry(\n...     \"https://api.example.com/resource/123\"\n... )  # doctest: +SKIP\n&gt;&gt;&gt; response.status_code  # doctest: +SKIP\n204\n</code></pre>"},{"location":"refs/#aresilient.delete_with_automatic_retry_async","title":"aresilient.delete_with_automatic_retry_async  <code>async</code>","text":"<pre><code>delete_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP DELETE request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP DELETE request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the DELETE request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.delete()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import delete_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await delete_with_automatic_retry_async(\n...         \"https://api.example.com/resource/123\"\n...     )\n...     return response.status_code\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.get_with_automatic_retry","title":"aresilient.get_with_automatic_retry","text":"<pre><code>get_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP GET request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP GET request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.get()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import get_with_automatic_retry\n&gt;&gt;&gt; response = get_with_automatic_retry(\"https://api.example.com/data\")  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.get_with_automatic_retry_async","title":"aresilient.get_with_automatic_retry_async  <code>async</code>","text":"<pre><code>get_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP GET request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP GET request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.get()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import get_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.head_with_automatic_retry","title":"aresilient.head_with_automatic_retry","text":"<pre><code>head_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP HEAD request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP HEAD request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>HEAD requests retrieve only the headers without the response body, making them useful for checking resource existence, metadata, ETags, content length, and performing lightweight validation without downloading data.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the HEAD request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.head()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response headers.</p> <code>Response</code> <p>The response body will be empty.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import head_with_automatic_retry\n&gt;&gt;&gt; # Check if a resource exists and get metadata\n&gt;&gt;&gt; response = head_with_automatic_retry(\n...     \"https://api.example.com/large-file.zip\"\n... )  # doctest: +SKIP\n&gt;&gt;&gt; if response.status_code == 200:  # doctest: +SKIP\n...     print(f\"Content-Length: {response.headers.get('Content-Length')}\")  # doctest: +SKIP\n...     print(f\"Last-Modified: {response.headers.get('Last-Modified')}\")  # doctest: +SKIP\n...\n</code></pre>"},{"location":"refs/#aresilient.head_with_automatic_retry_async","title":"aresilient.head_with_automatic_retry_async  <code>async</code>","text":"<pre><code>head_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP HEAD request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP HEAD request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>HEAD requests retrieve only the headers without the response body, making them useful for checking resource existence, metadata, ETags, content length, and performing lightweight validation without downloading data.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the HEAD request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.head()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response headers.</p> <code>Response</code> <p>The response body will be empty.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import head_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await head_with_automatic_retry_async(\n...         \"https://api.example.com/large-file.zip\"\n...     )\n...     if response.status_code == 200:\n...         print(f\"Content-Length: {response.headers.get('Content-Length')}\")\n...     return response\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.options_with_automatic_retry","title":"aresilient.options_with_automatic_retry","text":"<pre><code>options_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP OPTIONS request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP OPTIONS request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>OPTIONS requests are used to describe communication options for a target resource, including CORS preflight requests, discovering allowed HTTP methods via the Allow header, and querying server capabilities.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the OPTIONS request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.options()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response with</p> <code>Response</code> <p>communication options in headers (e.g., Allow, Access-Control-Allow-*).</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import options_with_automatic_retry\n&gt;&gt;&gt; # Check allowed HTTP methods for a resource\n&gt;&gt;&gt; response = options_with_automatic_retry(\n...     \"https://api.example.com/resource\"\n... )  # doctest: +SKIP\n&gt;&gt;&gt; allowed_methods = response.headers.get(\"Allow\")  # doctest: +SKIP\n&gt;&gt;&gt; print(f\"Allowed methods: {allowed_methods}\")  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.options_with_automatic_retry_async","title":"aresilient.options_with_automatic_retry_async  <code>async</code>","text":"<pre><code>options_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP OPTIONS request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP OPTIONS request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>OPTIONS requests are used to describe communication options for a target resource, including CORS preflight requests, discovering allowed HTTP methods via the Allow header, and querying server capabilities.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the OPTIONS request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.options()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response with</p> <code>Response</code> <p>communication options in headers (e.g., Allow, Access-Control-Allow-*).</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import options_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await options_with_automatic_retry_async(\n...         \"https://api.example.com/resource\"\n...     )\n...     allowed_methods = response.headers.get(\"Allow\")\n...     print(f\"Allowed methods: {allowed_methods}\")\n...     return response\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.patch_with_automatic_retry","title":"aresilient.patch_with_automatic_retry","text":"<pre><code>patch_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PATCH request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PATCH request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PATCH request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.patch()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import patch_with_automatic_retry\n&gt;&gt;&gt; response = patch_with_automatic_retry(\n...     \"https://api.example.com/resource/123\", json={\"status\": \"active\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.patch_with_automatic_retry_async","title":"aresilient.patch_with_automatic_retry_async  <code>async</code>","text":"<pre><code>patch_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PATCH request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PATCH request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PATCH request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.patch()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import patch_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await patch_with_automatic_retry_async(\n...         \"https://api.example.com/resource/123\", json={\"status\": \"updated\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.post_with_automatic_retry","title":"aresilient.post_with_automatic_retry","text":"<pre><code>post_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP POST request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP POST request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the POST request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.post()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import post_with_automatic_retry\n&gt;&gt;&gt; response = post_with_automatic_retry(\n...     \"https://api.example.com/data\", json={\"key\": \"value\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.post_with_automatic_retry_async","title":"aresilient.post_with_automatic_retry_async  <code>async</code>","text":"<pre><code>post_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP POST request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP POST request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the POST request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.post()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import post_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await post_with_automatic_retry_async(\n...         \"https://api.example.com/data\", json={\"key\": \"value\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.put_with_automatic_retry","title":"aresilient.put_with_automatic_retry","text":"<pre><code>put_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PUT request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PUT request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PUT request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.put()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import put_with_automatic_retry\n&gt;&gt;&gt; response = put_with_automatic_retry(\n...     \"https://api.example.com/resource/123\", json={\"name\": \"updated\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.put_with_automatic_retry_async","title":"aresilient.put_with_automatic_retry_async  <code>async</code>","text":"<pre><code>put_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PUT request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PUT request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies an exponential backoff retry strategy. The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PUT request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** retry_number) seconds. Must be &gt;= 0.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.put()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout is non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import put_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await put_with_automatic_retry_async(\n...         \"https://api.example.com/resource\", json={\"key\": \"value\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.request_with_automatic_retry","title":"aresilient.request_with_automatic_retry","text":"<pre><code>request_with_automatic_retry(\n    url: str,\n    method: str,\n    request_func: Callable[..., Response],\n    *,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Perform an HTTP request with automatic retry logic.</p> <p>This function implements a retry mechanism with exponential backoff for handling transient HTTP errors. It attempts the request up to max_retries + 1 times, waiting progressively longer between each retry.</p> <p>The retry logic handles three types of failures: 1. Retryable HTTP status codes (e.g., 429, 500, 502, 503, 504) 2. Timeout exceptions (httpx.TimeoutException) 3. General network errors (httpx.RequestError)</p> <p>Backoff Strategy: - Exponential backoff: backoff_factor * (2 ** attempt) - Jitter: Optional randomization added to prevent thundering herd - Retry-After header: If present in the response (429/503), the server's   suggested wait time is used instead of exponential backoff</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the request to.</p> required <code>method</code> <code>str</code> <p>The HTTP method name (e.g., \"GET\", \"POST\") for logging.</p> required <code>request_func</code> <code>Callable[..., Response]</code> <p>The function to call to make the request (e.g., client.get, client.post).</p> required <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is 0-indexed (0, 1, 2, ...).</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the request function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> Example <pre><code>&gt;&gt;&gt; import httpx\n&gt;&gt;&gt; from aresilient import request_with_automatic_retry\n&gt;&gt;&gt; def log_retry(info):\n...     print(f\"Retry {info['attempt']}/{info['max_retries']}\")\n...\n&gt;&gt;&gt; with httpx.Client() as client:\n...     response = request_with_automatic_retry(\n...         url=\"https://api.example.com/data\",\n...         method=\"GET\",\n...         request_func=client.get,\n...         max_retries=5,\n...         backoff_factor=1.0,\n...         jitter_factor=0.1,  # Add 10% jitter\n...         on_retry=log_retry,\n...     )  # doctest: +SKIP\n...\n</code></pre>"},{"location":"refs/#aresilient.request_with_automatic_retry_async","title":"aresilient.request_with_automatic_retry_async  <code>async</code>","text":"<pre><code>request_with_automatic_retry_async(\n    url: str,\n    method: str,\n    request_func: Callable[..., Awaitable[Response]],\n    *,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Perform an async HTTP request with automatic retry logic.</p> <p>This function implements a retry mechanism with exponential backoff for handling transient HTTP errors. It attempts the request up to max_retries + 1 times, waiting progressively longer between each retry.</p> <p>The retry logic handles three types of failures: 1. Retryable HTTP status codes (e.g., 429, 500, 502, 503, 504) 2. Timeout exceptions (httpx.TimeoutException) 3. General network errors (httpx.RequestError)</p> <p>Backoff Strategy: - Exponential backoff: backoff_factor * (2 ** attempt) - Jitter: Optional randomization added to prevent thundering herd - Retry-After header: If present in the response (429/503), the server's   suggested wait time is used instead of exponential backoff</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the request to.</p> required <code>method</code> <code>str</code> <p>The HTTP method name (e.g., \"GET\", \"POST\") for logging.</p> required <code>request_func</code> <code>Callable[..., Awaitable[Response]]</code> <p>The async function to call to make the request (e.g., client.get, client.post).</p> required <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is 0-indexed (0, 1, 2, ...).</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the request function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; import httpx\n&gt;&gt;&gt; from aresilient import request_with_automatic_retry_async\n&gt;&gt;&gt; def log_retry(info):\n...     print(f\"Retry {info['attempt']}/{info['max_retries']}\")\n...\n&gt;&gt;&gt; async def example():\n...     async with httpx.AsyncClient() as client:\n...         response = await request_with_automatic_retry_async(\n...             url=\"https://api.example.com/data\",\n...             method=\"GET\",\n...             request_func=client.get,\n...             max_retries=5,\n...             backoff_factor=1.0,\n...             jitter_factor=0.1,  # Add 10% jitter\n...             on_retry=log_retry,\n...         )\n...         return response.status_code\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"}]}