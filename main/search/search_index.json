{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p><code>aresilient</code> is a Python library that provides resilient HTTP request functionality with automatic retry logic and exponential backoff. Built on top of the modern httpx library, it simplifies handling transient failures in HTTP communications, making your applications more robust and fault-tolerant.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Automatic Retry Logic: Automatically retries failed requests for configurable HTTP status   codes (429, 500, 502, 503, 504 by default)</li> <li>Exponential Backoff with Optional Jitter: Implements exponential backoff strategy with   optional randomized jitter to prevent thundering herd problems and avoid overwhelming servers</li> <li>Retry-After Header Support: Respects server-specified retry delays from <code>Retry-After</code> headers   (supports both integer seconds and HTTP-date formats)</li> <li>Complete HTTP Method Support: Supports all common HTTP methods (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS)</li> <li>Async Support: Fully supports asynchronous requests for high-performance applications</li> <li>Built on httpx: Leverages the modern, async-capable httpx library</li> <li>Configurable: Customize timeout, retry attempts, backoff factors, jitter, and retryable status codes</li> <li>Callbacks for Observability: Built-in callback system for logging, metrics, and alerting   (on_request, on_retry, on_success, on_failure)</li> <li>Custom Retry Predicates: Define custom logic for retry decisions based on response content or business rules</li> <li>Type-Safe: Fully typed with comprehensive type hints</li> <li>Well-Tested: Extensive test coverage ensuring reliability</li> </ul>"},{"location":"#quick-examples","title":"Quick Examples","text":""},{"location":"#basic-get-request","title":"Basic GET Request","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n# Simple GET request with automatic retry\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\nprint(response.json())\n</code></pre>"},{"location":"#basic-post-request","title":"Basic POST Request","text":"<pre><code>from aresilient import post_with_automatic_retry\n\n# POST request with JSON payload\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\", json={\"key\": \"value\"}\n)\nprint(response.status_code)\n</code></pre>"},{"location":"#customizing-retry-behavior","title":"Customizing Retry Behavior","text":"<pre><code>from aresilient import get_with_automatic_retry\n\n# Custom retry configuration\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=5,  # Retry up to 5 times\n    backoff_factor=1.0,  # Exponential backoff factor\n    timeout=30.0,  # 30 second timeout\n    status_forcelist=(429, 503),  # Only retry on these status codes\n)\n</code></pre>"},{"location":"#using-async","title":"Using Async","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n\n\n# Run the async function\ndata = asyncio.run(fetch_data())\nprint(data)\n</code></pre>"},{"location":"#async-with-multiple-requests","title":"Async with Multiple Requests","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_multiple():\n    urls = [\n        \"https://api.example.com/data1\",\n        \"https://api.example.com/data2\",\n        \"https://api.example.com/data3\",\n    ]\n    tasks = [get_with_automatic_retry_async(url) for url in urls]\n    responses = await asyncio.gather(*tasks)\n    return [r.json() for r in responses]\n\n\n# Fetch multiple URLs concurrently\nresults = asyncio.run(fetch_multiple())\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>Install using <code>uv</code> (recommended):</p> <pre><code>uv pip install aresilient\n</code></pre> <p>Or using <code>pip</code>:</p> <pre><code>pip install aresilient\n</code></pre>"},{"location":"#api-stability","title":"API stability","text":"<p> While <code>aresilient</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>aresilient</code> to a new version will possibly break any code that was using the old version of <code>aresilient</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>aresilient</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p>"},{"location":"backoff_strategies/","title":"Backoff Strategies","text":"<p>This guide explains the different backoff strategies available in <code>aresilient</code> and how to use them to fine-tune retry behavior for your specific use case.</p>"},{"location":"backoff_strategies/#overview","title":"Overview","text":"<p>Backoff strategies determine how long to wait between retry attempts when a request fails. Choosing the right strategy can significantly improve the resilience and efficiency of your application when dealing with transient failures or rate-limited APIs.</p>"},{"location":"backoff_strategies/#available-strategies","title":"Available Strategies","text":""},{"location":"backoff_strategies/#exponential-backoff-default","title":"Exponential Backoff (Default)","text":"<p>Exponential backoff doubles the delay with each retry attempt. This is the default strategy and works well for most scenarios where you want progressively longer delays between retries.</p> <p>Formula: <code>base_delay * (2 ** attempt)</code></p> <p>When to use: - Most general-purpose retry scenarios - Services that need time to recover from failures - Preventing overwhelming a struggling service</p> <p>Example:</p> <pre><code>from aresilient import get_with_automatic_retry, ExponentialBackoff\n\n# Explicit exponential backoff with max delay cap\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ExponentialBackoff(base_delay=0.5, max_delay=10.0),\n)\n# Delays: 0.5s, 1s, 2s, 4s, 8s, 10s (capped), 10s (capped)...\n</code></pre> <p>Default behavior (when no <code>backoff_strategy</code> is specified):</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Uses exponential backoff with backoff_factor\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_factor=0.3,  # Equivalent to ExponentialBackoff(base_delay=0.3)\n)\n# Delays: 0.3s, 0.6s, 1.2s, 2.4s...\n</code></pre>"},{"location":"backoff_strategies/#linear-backoff","title":"Linear Backoff","text":"<p>Linear backoff provides evenly spaced retry delays, increasing linearly with each attempt. This is useful for services with predictable recovery times.</p> <p>Formula: <code>base_delay * (attempt + 1)</code></p> <p>When to use: - Services that recover quickly and predictably - Testing scenarios where you want consistent delays - APIs with linear rate limit recovery</p> <p>Example:</p> <pre><code>from aresilient import get_with_automatic_retry, LinearBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=LinearBackoff(base_delay=1.0),\n)\n# Delays: 1s, 2s, 3s, 4s, 5s...\n\n# With max_delay cap\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=LinearBackoff(base_delay=2.0, max_delay=8.0),\n)\n# Delays: 2s, 4s, 6s, 8s (capped), 8s (capped)...\n</code></pre>"},{"location":"backoff_strategies/#fibonacci-backoff","title":"Fibonacci Backoff","text":"<p>Fibonacci backoff provides a middle ground between linear and exponential backoff, with delays following the Fibonacci sequence. This provides a more gradual increase than exponential backoff.</p> <p>Formula: <code>base_delay * fibonacci(attempt + 1)</code></p> <p>When to use: - When exponential backoff is too aggressive - Services that need gradual recovery time - Balancing between quick retries and giving services time to recover</p> <p>Example:</p> <pre><code>from aresilient import get_with_automatic_retry, FibonacciBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=FibonacciBackoff(base_delay=1.0),\n)\n# Delays: 1s, 1s, 2s, 3s, 5s, 8s, 13s...\n\n# With max_delay cap\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=FibonacciBackoff(base_delay=1.0, max_delay=10.0),\n)\n# Delays: 1s, 1s, 2s, 3s, 5s, 8s, 10s (capped)...\n</code></pre>"},{"location":"backoff_strategies/#constant-backoff","title":"Constant Backoff","text":"<p>Constant backoff uses a fixed delay for all retry attempts, regardless of the attempt number. This is useful for testing or when you know the exact delay that works best.</p> <p>Formula: <code>delay</code> (constant)</p> <p>When to use: - Testing and debugging scenarios - APIs with specific retry delay requirements - Situations where you know the optimal wait time</p> <p>Example:</p> <pre><code>from aresilient import get_with_automatic_retry, ConstantBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ConstantBackoff(delay=2.5),\n)\n# Delays: 2.5s, 2.5s, 2.5s, 2.5s...\n</code></pre>"},{"location":"backoff_strategies/#custom-backoff-strategy","title":"Custom Backoff Strategy","text":"<p>You can implement your own backoff strategy by subclassing <code>BackoffStrategy</code> and implementing the <code>calculate()</code> method:</p> <pre><code>from aresilient import get_with_automatic_retry, BackoffStrategy\n\n\nclass SquareBackoff(BackoffStrategy):\n    \"\"\"Custom backoff using square of attempt number.\"\"\"\n\n    def __init__(self, base_delay: float = 1.0):\n        self.base_delay = base_delay\n\n    def calculate(self, attempt: int) -&gt; float:\n        \"\"\"Calculate delay as square of (attempt + 1).\"\"\"\n        return self.base_delay * ((attempt + 1) ** 2)\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=SquareBackoff(base_delay=0.5),\n)\n# Delays: 0.5s, 2s, 4.5s, 8s, 12.5s...\n</code></pre>"},{"location":"backoff_strategies/#using-backoff-strategies-with-jitter","title":"Using Backoff Strategies with Jitter","text":"<p>Jitter adds randomization to backoff delays to prevent the \"thundering herd\" problem where multiple clients retry simultaneously. Jitter works with all backoff strategies:</p> <pre><code>from aresilient import get_with_automatic_retry, LinearBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=LinearBackoff(base_delay=1.0),\n    jitter_factor=0.1,  # Add up to 10% random jitter\n)\n# Delays: 1.0-1.1s, 2.0-2.2s, 3.0-3.3s...\n</code></pre>"},{"location":"backoff_strategies/#retry-after-header-support","title":"Retry-After Header Support","text":"<p>When a server returns a <code>Retry-After</code> header (commonly with 429 or 503 status codes), the library automatically uses the server's suggested wait time instead of the configured backoff strategy. This ensures compliance with server requirements:</p> <pre><code>from aresilient import get_with_automatic_retry, ExponentialBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ExponentialBackoff(base_delay=1.0),\n)\n# If server returns \"Retry-After: 60\", waits 60 seconds\n# Otherwise uses the configured strategy\n</code></pre>"},{"location":"backoff_strategies/#max-delay-cap","title":"Max Delay Cap","text":"<p>Most strategies support an optional <code>max_delay</code> parameter to prevent extremely long waits:</p> <pre><code>from aresilient import get_with_automatic_retry, ExponentialBackoff\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    backoff_strategy=ExponentialBackoff(base_delay=1.0, max_delay=30.0),\n    max_retries=10,\n)\n# Delays won't exceed 30 seconds, even with many retries\n</code></pre>"},{"location":"backoff_strategies/#comparison-of-strategies","title":"Comparison of Strategies","text":"<p>Here's how different strategies compare for the first 6 retry attempts (with <code>base_delay=1.0</code>):</p> Attempt Exponential Linear Fibonacci Constant 1 1s 1s 1s 1s 2 2s 2s 1s 1s 3 4s 3s 2s 1s 4 8s 4s 3s 1s 5 16s 5s 5s 1s 6 32s 6s 8s 1s"},{"location":"backoff_strategies/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use exponential backoff by default - It works well for most scenarios and prevents    overwhelming failing services.</p> </li> <li> <p>Add jitter in production - Set <code>jitter_factor=0.1</code> to prevent thundering herd issues when    multiple clients retry simultaneously.</p> </li> <li> <p>Set max_delay caps - Prevent extremely long waits by setting a reasonable <code>max_delay</code>,    especially with exponential or Fibonacci backoff.</p> </li> <li> <p>Respect Retry-After headers - The library automatically honors these, but be aware that they    take precedence over your configured strategy.</p> </li> <li> <p>Choose strategy based on service behavior:</p> </li> <li>Exponential: Services that need increasing recovery time</li> <li>Linear: Services with predictable recovery patterns</li> <li>Fibonacci: When you want gradual increase without exponential growth</li> <li> <p>Constant: Testing or APIs with specific requirements</p> </li> <li> <p>Test your strategy - Use different strategies in staging to find what works best for your    specific API.</p> </li> </ol>"},{"location":"backoff_strategies/#async-support","title":"Async Support","text":"<p>All backoff strategies work identically with async functions:</p> <pre><code>from aresilient import get_with_automatic_retry_async, FibonacciBackoff\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\n        \"https://api.example.com/data\",\n        backoff_strategy=FibonacciBackoff(base_delay=1.0, max_delay=10.0),\n    )\n    return response.json()\n</code></pre>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-uv-recommended","title":"Installing with <code>uv</code> (recommended)","text":"<p>The following command installs the latest stable version of the library:</p> <pre><code>uv pip install aresilient\n</code></pre> <p>To install the latest development version from GitHub:</p> <pre><code>uv pip install git+https://github.com/durandtibo/aresilient.git\n</code></pre> <p>To install a specific version:</p> <pre><code>uv pip install aresilient==0.3.0\n</code></pre>"},{"location":"get_started/#installing-with-pip","title":"Installing with <code>pip</code>","text":"<p>The following command installs the latest stable version of the library:</p> <pre><code>pip install aresilient\n</code></pre> <p>To install the latest development version from GitHub:</p> <pre><code>pip install git+https://github.com/durandtibo/aresilient.git\n</code></pre> <p>To install a specific version:</p> <pre><code>pip install aresilient==0.3.0\n</code></pre>"},{"location":"get_started/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, you can verify that aresilient is correctly installed by running:</p> <pre><code>python -c \"import aresilient; print(aresilient.__version__)\"\n</code></pre> <p>Or try a simple example:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Make a simple GET request (this is a safe example that won't actually execute)\n# response = get_with_automatic_retry(\"https://api.example.com/data\")\n# print(response.json())\n\n# Verify the module is properly imported\nprint(\"aresilient imported successfully!\")\n</code></pre>"},{"location":"get_started/#testing-async-support","title":"Testing Async Support","text":"<p>To verify async support is working:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def test_async():\n    print(\"Async support is working!\")\n    return True\n\n\nresult = asyncio.run(test_async())\nprint(f\"Test result: {result}\")\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>aresilient</code> from source, you can follow the steps below.</p>"},{"location":"get_started/#prerequisites","title":"Prerequisites","text":"<p>This project uses <code>uv</code> for dependency management. Please refer to the uv installation documentation for installation instructions.</p>"},{"location":"get_started/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone git@github.com:durandtibo/aresilient.git\ncd aresilient\n</code></pre>"},{"location":"get_started/#create-a-virtual-environment","title":"Create a Virtual Environment","text":"<p>It is recommended to create a Python 3.10+ virtual environment:</p> <pre><code>make setup-venv\n</code></pre> <p>This command creates a virtual environment using <code>uv</code> and installs all dependencies including development tools.</p> <p>Alternatively, you can create a conda virtual environment:</p> <pre><code>make conda\nconda activate aresilient\nmake install\n</code></pre>"},{"location":"get_started/#install-dependencies","title":"Install Dependencies","text":"<p>To install only the core dependencies:</p> <pre><code>make install\n</code></pre> <p>To install all dependencies including documentation tools:</p> <pre><code>make install-all\n</code></pre>"},{"location":"get_started/#verify-installation","title":"Verify Installation","text":"<p>You can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre> <p>This will run the test suite with coverage reporting.</p>"},{"location":"get_started/#development-setup","title":"Development Setup","text":"<p>If you plan to contribute to aresilient, please also install the development tools.</p> <p>Using <code>uv</code>:</p> <pre><code>uv pip install -e \".[dev,docs]\"\n</code></pre> <p>Using <code>pip</code>:</p> <pre><code>pip install -e \".[dev,docs]\"\n</code></pre> <p>Then install the pre-commit hooks:</p> <pre><code>pre-commit install\n</code></pre> <p>See CONTRIBUTING.md for more information about contributing.</p>"},{"location":"user_guide/","title":"User Guide","text":"<p>This guide provides comprehensive instructions on how to use <code>aresilient</code> for making resilient HTTP requests with automatic retry logic.</p>"},{"location":"user_guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Basic Usage</li> <li>Async Usage</li> <li>Configuration Options</li> <li>Advanced Usage</li> <li>Callbacks and Observability</li> <li>Error Handling</li> <li>Custom HTTP Methods</li> <li>Best Practices</li> </ul>"},{"location":"user_guide/#basic-usage","title":"Basic Usage","text":""},{"location":"user_guide/#making-get-requests","title":"Making GET Requests","text":"<p>The simplest way to make an HTTP GET request with automatic retry:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Basic GET request\nresponse = get_with_automatic_retry(\"https://api.example.com/users\")\nprint(response.json())\n</code></pre>"},{"location":"user_guide/#making-post-requests","title":"Making POST Requests","text":"<p>POST requests work similarly with support for JSON payloads and form data:</p> <pre><code>from aresilient import post_with_automatic_retry\n\n# POST with JSON payload\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/users\",\n    json={\"name\": \"John Doe\", \"email\": \"john@example.com\"},\n)\nprint(response.status_code)\n\n# POST with form data\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\", data={\"field1\": \"value1\", \"field2\": \"value2\"}\n)\n</code></pre>"},{"location":"user_guide/#other-http-methods","title":"Other HTTP Methods","text":"<p><code>aresilient</code> supports all common HTTP methods:</p> <pre><code>from aresilient import (\n    put_with_automatic_retry,\n    delete_with_automatic_retry,\n    patch_with_automatic_retry,\n)\n\n# PUT request to update a resource\nresponse = put_with_automatic_retry(\n    \"https://api.example.com/resource/123\", json={\"name\": \"updated\"}\n)\n\n# DELETE request to remove a resource\nresponse = delete_with_automatic_retry(\"https://api.example.com/resource/123\")\n\n# PATCH request to partially update a resource\nresponse = patch_with_automatic_retry(\n    \"https://api.example.com/resource/123\", json={\"status\": \"active\"}\n)\n</code></pre>"},{"location":"user_guide/#async-usage","title":"Async Usage","text":"<p><code>aresilient</code> provides asynchronous versions of all HTTP methods for use in async applications. All async functions have the same parameters as their synchronous counterparts.</p>"},{"location":"user_guide/#making-async-get-requests","title":"Making Async GET Requests","text":"<pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n\n\n# Run the async function\ndata = asyncio.run(fetch_data())\nprint(data)\n</code></pre>"},{"location":"user_guide/#making-async-post-requests","title":"Making Async POST Requests","text":"<pre><code>import asyncio\nfrom aresilient import post_with_automatic_retry_async\n\n\nasync def create_user():\n    response = await post_with_automatic_retry_async(\n        \"https://api.example.com/users\",\n        json={\"name\": \"Jane Doe\", \"email\": \"jane@example.com\"},\n    )\n    return response.status_code\n\n\n# Run the async function\nstatus = asyncio.run(create_user())\nprint(f\"Status: {status}\")\n</code></pre>"},{"location":"user_guide/#other-async-http-methods","title":"Other Async HTTP Methods","text":"<p>All HTTP methods have async versions with identical parameters and callback support:</p> <pre><code>from aresilient import (\n    put_with_automatic_retry_async,\n    delete_with_automatic_retry_async,\n    patch_with_automatic_retry_async,\n    head_with_automatic_retry_async,\n    options_with_automatic_retry_async,\n)\n</code></pre> <p>Note: All async functions support the same parameters as their synchronous counterparts, including: - <code>max_retries</code>, <code>backoff_factor</code>, <code>jitter_factor</code> - <code>status_forcelist</code>, <code>retry_if</code> - <code>on_request</code>, <code>on_retry</code>, <code>on_success</code>, <code>on_failure</code> callbacks</p>"},{"location":"user_guide/#using-async-with-httpxasyncclient","title":"Using Async with httpx.AsyncClient","text":"<p>For better performance with multiple async requests, reuse an <code>httpx.AsyncClient</code>:</p> <pre><code>import asyncio\nimport httpx\nfrom aresilient import get_with_automatic_retry_async, post_with_automatic_retry_async\n\n\nasync def fetch_multiple_resources():\n    async with httpx.AsyncClient(timeout=30.0) as client:\n        # Make multiple concurrent requests\n        users_task = get_with_automatic_retry_async(\n            \"https://api.example.com/users\", client=client\n        )\n        posts_task = get_with_automatic_retry_async(\n            \"https://api.example.com/posts\", client=client\n        )\n\n        # Wait for both requests to complete\n        users, posts = await asyncio.gather(users_task, posts_task)\n\n        return users.json(), posts.json()\n\n\n# Run the async function\nusers_data, posts_data = asyncio.run(fetch_multiple_resources())\n</code></pre>"},{"location":"user_guide/#concurrent-async-requests","title":"Concurrent Async Requests","text":"<p>Process multiple URLs concurrently for better performance:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_all(urls):\n    tasks = [get_with_automatic_retry_async(url) for url in urls]\n    responses = await asyncio.gather(*tasks, return_exceptions=True)\n    return responses\n\n\n# Fetch multiple URLs concurrently\nurls = [\n    \"https://api.example.com/data1\",\n    \"https://api.example.com/data2\",\n    \"https://api.example.com/data3\",\n]\nresponses = asyncio.run(fetch_all(urls))\n</code></pre>"},{"location":"user_guide/#configuration-options","title":"Configuration Options","text":""},{"location":"user_guide/#default-configuration","title":"Default Configuration","text":"<p><code>aresilient</code> comes with sensible defaults:</p> <pre><code>from aresilient import (\n    DEFAULT_TIMEOUT,  # 10.0 seconds\n    DEFAULT_MAX_RETRIES,  # 3 retries (4 total attempts)\n    DEFAULT_BACKOFF_FACTOR,  # 0.3 seconds\n    RETRY_STATUS_CODES,  # (429, 500, 502, 503, 504)\n)\n\nprint(f\"Timeout: {DEFAULT_TIMEOUT}\")\nprint(f\"Max retries: {DEFAULT_MAX_RETRIES}\")\nprint(f\"Backoff factor: {DEFAULT_BACKOFF_FACTOR}\")\nprint(f\"Retry on status codes: {RETRY_STATUS_CODES}\")\n</code></pre>"},{"location":"user_guide/#customizing-timeout","title":"Customizing Timeout","text":"<p>Control how long to wait for a server response:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Short timeout for quick responses\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/health\", timeout=5.0  # 5 seconds\n)\n\n# Longer timeout for slow endpoints\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/slow-endpoint\", timeout=60.0  # 60 seconds\n)\n</code></pre> <p>You can also use httpx.Timeout for fine-grained control:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry\n\n# Different timeouts for different operations\ntimeout = httpx.Timeout(\n    connect=5.0,  # 5 seconds to establish connection\n    read=30.0,  # 30 seconds to read response\n    write=10.0,  # 10 seconds to send request\n    pool=5.0,  # 5 seconds to get connection from pool\n)\n\nresponse = get_with_automatic_retry(\"https://api.example.com/data\", timeout=timeout)\n</code></pre>"},{"location":"user_guide/#customizing-retry-behavior","title":"Customizing Retry Behavior","text":"<p>Control how many times and how long between retries:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# More aggressive retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=5,  # Retry up to 5 times\n    backoff_factor=0.5,  # Longer waits between retries\n)\n\n# Less aggressive retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=1,  # Only retry once\n    backoff_factor=0.1,  # Shorter waits between retries\n)\n\n# With jitter to prevent thundering herd\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    max_retries=3,\n    backoff_factor=0.5,\n    jitter_factor=0.1,  # Add 10% random jitter\n)\n\n# No retry\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", max_retries=0  # No retries, fail immediately\n)\n</code></pre>"},{"location":"user_guide/#understanding-exponential-backoff","title":"Understanding Exponential Backoff","text":"<p>The wait time between retries is calculated using the exponential backoff formula:</p> <pre><code>base_wait_time = backoff_factor * (2 ** attempt)\n# If jitter_factor is set (e.g., 0.1 for 10% jitter):\njitter = random(0, jitter_factor) * base_wait_time\ntotal_wait_time = base_wait_time + jitter\n</code></pre> <p>Where <code>attempt</code> is 0-indexed (0, 1, 2, ...).</p>"},{"location":"user_guide/#example-with-default-backoff_factor03-no-jitter","title":"Example with default <code>backoff_factor=0.3</code> (no jitter):","text":"<ul> <li>1st retry: 0.3 * (2^0) = 0.3 seconds</li> <li>2nd retry: 0.3 * (2^1) = 0.6 seconds</li> <li>3rd retry: 0.3 * (2^2) = 1.2 seconds</li> </ul>"},{"location":"user_guide/#example-with-backoff_factor10-and-jitter_factor01","title":"Example with <code>backoff_factor=1.0</code> and <code>jitter_factor=0.1</code>:","text":"<ul> <li>1st retry: 1.0-1.1 seconds (base 1.0s + up to 10% jitter)</li> <li>2nd retry: 2.0-2.2 seconds (base 2.0s + up to 10% jitter)</li> <li>3rd retry: 4.0-4.4 seconds (base 4.0s + up to 10% jitter)</li> </ul> <p>Note: Jitter is optional (disabled by default with <code>jitter_factor=0</code>). When enabled, it's randomized for each retry to prevent multiple clients from retrying simultaneously (thundering herd problem). Set <code>jitter_factor=0.1</code> for 10% jitter, which is recommended for production use.</p>"},{"location":"user_guide/#customizing-retryable-status-codes","title":"Customizing Retryable Status Codes","text":"<p>By default, <code>aresilient</code> retries on status codes 429, 500, 502, 503, and 504. You can customize this:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n# Only retry on rate limiting\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", status_forcelist=(429,)\n)\n\n# Retry on server errors and rate limiting\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", status_forcelist=(429, 500, 502, 503, 504)\n)\n\n# Add custom status codes\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    status_forcelist=(408, 429, 500, 502, 503, 504),  # Include 408 Request Timeout\n)\n</code></pre>"},{"location":"user_guide/#retry-after-header-support","title":"Retry-After Header Support","text":"<p>When a server returns a <code>Retry-After</code> header (commonly with 429 or 503 status codes), <code>aresilient</code> automatically uses the server's suggested wait time instead of exponential backoff. This ensures compliance with rate limiting and helps avoid overwhelming the server.</p> <p>The <code>Retry-After</code> header supports two formats:</p> <pre><code># Server responds with: Retry-After: 120\n# aresilient will wait 120 seconds before retrying\n\n# Server responds with: Retry-After: Wed, 21 Oct 2015 07:28:00 GMT\n# aresilient will wait until this time before retrying\n</code></pre> <p>The retry delay from the <code>Retry-After</code> header is used automatically - you don't need to configure anything. This works with all HTTP methods (GET, POST, PUT, DELETE, PATCH).</p> <p>Note: If <code>jitter_factor</code> is configured, jitter is still applied to server-specified <code>Retry-After</code> values to prevent thundering herd issues when many clients receive the same retry delay from a server.</p>"},{"location":"user_guide/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user_guide/#using-a-custom-httpx-client","title":"Using a Custom httpx Client","text":"<p>For advanced configurations like custom headers, authentication, or connection pooling:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry\n\n# Create a client with custom headers\nwith httpx.Client(\n    headers={\"User-Agent\": \"MyApp/1.0\", \"Authorization\": \"Bearer your-token-here\"}\n) as client:\n    response = get_with_automatic_retry(\n        \"https://api.example.com/protected\", client=client\n    )\n    print(response.json())\n</code></pre>"},{"location":"user_guide/#reusing-client-for-multiple-requests","title":"Reusing Client for Multiple Requests","text":"<p>When making multiple requests, reuse the same client for better performance:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry, post_with_automatic_retry\n\nwith httpx.Client(headers={\"Authorization\": \"Bearer token\"}, timeout=30.0) as client:\n    # Multiple requests using the same client\n    users = get_with_automatic_retry(\"https://api.example.com/users\", client=client)\n\n    posts = get_with_automatic_retry(\"https://api.example.com/posts\", client=client)\n\n    result = post_with_automatic_retry(\n        \"https://api.example.com/data\", client=client, json={\"data\": \"value\"}\n    )\n</code></pre>"},{"location":"user_guide/#passing-additional-httpx-arguments","title":"Passing Additional httpx Arguments","text":"<p>All <code>**kwargs</code> are passed directly to the underlying httpx methods:</p> <pre><code>from aresilient import get_with_automatic_retry, post_with_automatic_retry\n\n# GET with query parameters\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/search\", params={\"q\": \"python\", \"page\": 1}\n)\n\n# GET with custom headers (without custom client)\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\", headers={\"X-Custom-Header\": \"value\"}\n)\n\n# POST with files\nwith open(\"document.pdf\", \"rb\") as f:\n    response = post_with_automatic_retry(\n        \"https://api.example.com/upload\", files={\"file\": f}\n    )\n\n# POST with both data and files\nresponse = post_with_automatic_retry(\n    \"https://api.example.com/submit\",\n    data={\"title\": \"My Document\"},\n    files={\"attachment\": open(\"file.txt\", \"rb\")},\n)\n</code></pre>"},{"location":"user_guide/#callbacks-and-observability","title":"Callbacks and Observability","text":"<p><code>aresilient</code> provides a comprehensive callback/event system for observability, enabling you to hook into the retry lifecycle for logging, metrics collection, alerting, and custom behavior. This is particularly useful for production applications where you need to monitor HTTP request patterns, track retry rates, and integrate with your observability stack.</p>"},{"location":"user_guide/#available-callbacks","title":"Available Callbacks","text":"<p>The library provides four lifecycle hooks:</p> <ul> <li><code>on_request</code>: Called before each request attempt (including the initial request)</li> <li><code>on_retry</code>: Called before each retry (after backoff delay calculation)</li> <li><code>on_success</code>: Called when a request succeeds</li> <li><code>on_failure</code>: Called when all retries are exhausted and the request fails</li> </ul> <p>All callbacks are optional and can be used independently or together. They work with both synchronous and asynchronous functions.</p>"},{"location":"user_guide/#callback-signatures","title":"Callback Signatures","text":"<p>Each callback receives a dataclass with relevant information:</p>"},{"location":"user_guide/#requestinfo-for-on_request","title":"RequestInfo (for <code>on_request</code>)","text":"<pre><code>@dataclass\nclass RequestInfo:\n    url: str  # The URL being requested\n    method: str  # HTTP method (e.g., \"GET\", \"POST\")\n    attempt: int  # Current attempt number (1-indexed, first attempt is 1)\n    max_retries: int  # Maximum number of retry attempts configured\n</code></pre>"},{"location":"user_guide/#retryinfo-for-on_retry","title":"RetryInfo (for <code>on_retry</code>)","text":"<pre><code>@dataclass\nclass RetryInfo:\n    url: str  # The URL being requested\n    method: str  # HTTP method\n    attempt: int  # Current attempt number (1-indexed, first retry is attempt 2)\n    max_retries: int  # Maximum retry attempts configured\n    wait_time: float  # Sleep time in seconds before this retry\n    error: Exception | None  # Exception that triggered the retry (if any)\n    status_code: int | None  # HTTP status code that triggered retry (if any)\n</code></pre>"},{"location":"user_guide/#responseinfo-for-on_success","title":"ResponseInfo (for <code>on_success</code>)","text":"<pre><code>@dataclass\nclass ResponseInfo:\n    url: str  # The URL that was requested\n    method: str  # HTTP method\n    attempt: int  # Attempt number that succeeded (1-indexed)\n    max_retries: int  # Maximum retry attempts configured\n    response: httpx.Response  # The successful HTTP response object\n    total_time: float  # Total time spent on all attempts including backoff (seconds)\n</code></pre>"},{"location":"user_guide/#failureinfo-for-on_failure","title":"FailureInfo (for <code>on_failure</code>)","text":"<pre><code>@dataclass\nclass FailureInfo:\n    url: str  # The URL that was requested\n    method: str  # HTTP method\n    attempt: int  # Final attempt number (1-indexed)\n    max_retries: int  # Maximum retry attempts configured\n    error: Exception  # The final exception that caused failure\n    status_code: int | None  # Final HTTP status code (if any)\n    total_time: float  # Total time spent on all attempts including backoff (seconds)\n</code></pre>"},{"location":"user_guide/#basic-logging-example","title":"Basic Logging Example","text":"<p>Track each phase of the request lifecycle:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\ndef log_request(info):\n    print(\n        f\"[REQUEST] {info.method} {info.url} - Attempt {info.attempt}/{info.max_retries + 1}\"\n    )\n\n\ndef log_retry(info):\n    reason = (\n        f\"status={info.status_code}\"\n        if info.status_code\n        else f\"error={type(info.error).__name__}\"\n    )\n    print(\n        f\"[RETRY] {info.method} {info.url} - \"\n        f\"Attempt {info.attempt}/{info.max_retries + 1}, \"\n        f\"waiting {info.wait_time:.2f}s, reason={reason}\"\n    )\n\n\ndef log_success(info):\n    print(\n        f\"[SUCCESS] {info.method} {info.url} - \"\n        f\"Succeeded on attempt {info.attempt} \"\n        f\"({info.total_time:.2f}s total, status={info.response.status_code})\"\n    )\n\n\ndef log_failure(info):\n    reason = (\n        f\"status={info.status_code}\"\n        if info.status_code\n        else f\"error={type(info.error).__name__}\"\n    )\n    print(\n        f\"[FAILURE] {info.method} {info.url} - \"\n        f\"Failed after {info.attempt} attempts \"\n        f\"({info.total_time:.2f}s total), reason={reason}\"\n    )\n\n\n# Use callbacks for comprehensive logging\ntry:\n    response = get_with_automatic_retry(\n        \"https://api.example.com/data\",\n        max_retries=3,\n        on_request=log_request,\n        on_retry=log_retry,\n        on_success=log_success,\n        on_failure=log_failure,\n    )\nexcept Exception as e:\n    pass  # Error already logged in on_failure\n</code></pre> <p>Example output: <pre><code>[REQUEST] GET https://api.example.com/data - Attempt 1/4\n[RETRY] GET https://api.example.com/data - Attempt 2/4, waiting 0.30s, reason=status=503\n[REQUEST] GET https://api.example.com/data - Attempt 2/4\n[RETRY] GET https://api.example.com/data - Attempt 3/4, waiting 0.60s, reason=status=503\n[REQUEST] GET https://api.example.com/data - Attempt 3/4\n[SUCCESS] GET https://api.example.com/data - Succeeded on attempt 3 (1.15s total, status=200)\n</code></pre></p>"},{"location":"user_guide/#metrics-collection-example","title":"Metrics Collection Example","text":"<p>Track statistics across multiple requests:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass RequestMetrics:\n    \"\"\"Collect metrics for HTTP requests with retries.\"\"\"\n\n    def __init__(self):\n        self.total_requests = 0\n        self.total_retries = 0\n        self.successes = 0\n        self.failures = 0\n        self.total_time = 0.0\n        self.retry_reasons = {}  # Track why retries happened\n\n    def on_request(self, info):\n        self.total_requests += 1\n\n    def on_retry(self, info):\n        self.total_retries += 1\n        # Track retry reasons\n        reason = info.status_code if info.status_code else type(info.error).__name__\n        self.retry_reasons[reason] = self.retry_reasons.get(reason, 0) + 1\n\n    def on_success(self, info):\n        self.successes += 1\n        self.total_time += info.total_time\n\n    def on_failure(self, info):\n        self.failures += 1\n        self.total_time += info.total_time\n\n    def summary(self):\n        \"\"\"Print a summary of collected metrics.\"\"\"\n        total_completed = self.successes + self.failures\n        success_rate = (\n            (self.successes / total_completed * 100) if total_completed &gt; 0 else 0\n        )\n        avg_time = (self.total_time / total_completed) if total_completed &gt; 0 else 0\n\n        print(f\"=== Request Metrics Summary ===\")\n        print(f\"Total requests made: {self.total_requests}\")\n        print(f\"Total retries: {self.total_retries}\")\n        print(f\"Successes: {self.successes}\")\n        print(f\"Failures: {self.failures}\")\n        print(f\"Success rate: {success_rate:.1f}%\")\n        print(f\"Average time: {avg_time:.2f}s\")\n        print(f\"Retry reasons: {self.retry_reasons}\")\n\n\n# Collect metrics across multiple requests\nmetrics = RequestMetrics()\n\nurls = [\n    \"https://api.example.com/endpoint1\",\n    \"https://api.example.com/endpoint2\",\n    \"https://api.example.com/endpoint3\",\n]\n\nfor url in urls:\n    try:\n        response = get_with_automatic_retry(\n            url,\n            on_request=metrics.on_request,\n            on_retry=metrics.on_retry,\n            on_success=metrics.on_success,\n            on_failure=metrics.on_failure,\n        )\n    except Exception:\n        pass  # Metrics already tracked\n\nmetrics.summary()\n</code></pre>"},{"location":"user_guide/#integration-with-logging-frameworks","title":"Integration with Logging Frameworks","text":"<p>Integrate with Python's standard logging module:</p> <pre><code>import logging\nfrom aresilient import get_with_automatic_retry\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n)\n\nlogger = logging.getLogger(\"http_client\")\n\n\ndef log_retry_event(info):\n    \"\"\"Log retry events with structured information.\"\"\"\n    logger.warning(\n        \"HTTP request retry\",\n        extra={\n            \"url\": info.url,\n            \"method\": info.method,\n            \"attempt\": info.attempt,\n            \"max_retries\": info.max_retries,\n            \"wait_time\": info.wait_time,\n            \"status_code\": info.status_code,\n            \"error\": str(info.error) if info.error else None,\n        },\n    )\n\n\ndef log_failure_event(info):\n    \"\"\"Log failure events with full context.\"\"\"\n    logger.error(\n        \"HTTP request failed after retries\",\n        extra={\n            \"url\": info.url,\n            \"method\": info.method,\n            \"attempts\": info.attempt,\n            \"total_time\": info.total_time,\n            \"status_code\": info.status_code,\n            \"error\": str(info.error),\n        },\n    )\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_retry=log_retry_event,\n    on_failure=log_failure_event,\n)\n</code></pre>"},{"location":"user_guide/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>Send metrics to a monitoring system:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass MonitoringClient:\n    \"\"\"Send metrics to your monitoring system (e.g., Prometheus, Datadog, CloudWatch).\"\"\"\n\n    def __init__(self):\n        # Initialize your metrics client here\n        pass\n\n    def increment_counter(self, metric_name, tags=None):\n        \"\"\"Increment a counter metric.\"\"\"\n        # Your implementation here\n        pass\n\n    def record_histogram(self, metric_name, value, tags=None):\n        \"\"\"Record a histogram/distribution value.\"\"\"\n        # Your implementation here\n        pass\n\n\nmonitoring = MonitoringClient()\n\n\ndef track_retry(info):\n    \"\"\"Track retry events in monitoring system.\"\"\"\n    monitoring.increment_counter(\n        \"http.retries\",\n        tags={\n            \"method\": info.method,\n            \"status_code\": (\n                str(info.status_code) if info.status_code else \"network_error\"\n            ),\n        },\n    )\n\n\ndef track_success(info):\n    \"\"\"Track successful requests.\"\"\"\n    monitoring.increment_counter(\"http.success\", tags={\"method\": info.method})\n    monitoring.record_histogram(\n        \"http.duration\", info.total_time, tags={\"method\": info.method}\n    )\n\n\ndef track_failure(info):\n    \"\"\"Track failed requests.\"\"\"\n    monitoring.increment_counter(\n        \"http.failure\",\n        tags={\n            \"method\": info.method,\n            \"status_code\": (\n                str(info.status_code) if info.status_code else \"network_error\"\n            ),\n        },\n    )\n\n\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_retry=track_retry,\n    on_success=track_success,\n    on_failure=track_failure,\n)\n</code></pre>"},{"location":"user_guide/#async-callbacks","title":"Async Callbacks","text":"<p>Callbacks work identically with async functions:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def async_log_retry(info):\n    \"\"\"Callbacks for async functions are still synchronous.\"\"\"\n    print(f\"Retrying {info.url} after {info.wait_time:.2f}s\")\n\n\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\n        \"https://api.example.com/data\", on_retry=async_log_retry\n    )\n    return response.json()\n\n\nasyncio.run(fetch_data())\n</code></pre> <p>Note: Callbacks themselves are synchronous functions even when used with async HTTP methods. If you need to perform async operations in callbacks (e.g., async logging), you'll need to handle that separately.</p>"},{"location":"user_guide/#custom-alerting-on-failures","title":"Custom Alerting on Failures","text":"<p>Send alerts when requests fail after all retries:</p> <pre><code>from aresilient import post_with_automatic_retry\n\n\ndef send_alert_on_failure(info):\n    \"\"\"Send an alert when a critical API request fails.\"\"\"\n    if \"critical-api\" in info.url:\n        alert_message = (\n            f\"CRITICAL: API request failed!\\n\"\n            f\"URL: {info.url}\\n\"\n            f\"Method: {info.method}\\n\"\n            f\"Attempts: {info.attempt}\\n\"\n            f\"Total Time: {info.total_time:.2f}s\\n\"\n            f\"Error: {info.error}\\n\"\n            f\"Status Code: {info.status_code}\"\n        )\n        # Send to your alerting system (PagerDuty, Slack, email, etc.)\n        # send_slack_alert(alert_message)\n        # send_email_alert(alert_message)\n        print(alert_message)\n\n\ntry:\n    response = post_with_automatic_retry(\n        \"https://critical-api.example.com/important\",\n        json={\"data\": \"value\"},\n        on_failure=send_alert_on_failure,\n    )\nexcept Exception:\n    pass  # Alert already sent\n</code></pre>"},{"location":"user_guide/#combining-multiple-callbacks","title":"Combining Multiple Callbacks","text":"<p>You can use multiple callbacks together for comprehensive observability:</p> <pre><code>from aresilient import get_with_automatic_retry\n\n\nclass RequestObserver:\n    \"\"\"Comprehensive request observer combining logging, metrics, and alerting.\"\"\"\n\n    def __init__(self, logger, metrics, alerting):\n        self.logger = logger\n        self.metrics = metrics\n        self.alerting = alerting\n\n    def on_request(self, info):\n        self.logger.debug(f\"Starting {info.method} {info.url}\")\n        self.metrics.on_request(info)\n\n    def on_retry(self, info):\n        self.logger.warning(f\"Retrying {info.method} {info.url}\")\n        self.metrics.on_retry(info)\n\n    def on_success(self, info):\n        self.logger.info(f\"Success {info.method} {info.url} in {info.total_time:.2f}s\")\n        self.metrics.on_success(info)\n\n    def on_failure(self, info):\n        self.logger.error(f\"Failed {info.method} {info.url}\")\n        self.metrics.on_failure(info)\n        self.alerting.send_alert(info)\n\n\n# Create observer with your components\nobserver = RequestObserver(logger, metrics, alerting)\n\n# Use all callbacks\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/data\",\n    on_request=observer.on_request,\n    on_retry=observer.on_retry,\n    on_success=observer.on_success,\n    on_failure=observer.on_failure,\n)\n</code></pre>"},{"location":"user_guide/#best-practices-for-callbacks","title":"Best Practices for Callbacks","text":"<ol> <li> <p>Keep callbacks lightweight: Callbacks are called synchronously and will block the request flow. Avoid heavy computations or blocking I/O.</p> </li> <li> <p>Handle exceptions in callbacks: If a callback raises an exception, it will propagate and potentially abort the request. Wrap callback code in try/except if needed.</p> </li> <li> <p>Use structured logging: Include relevant context (URL, method, attempt number) in log messages for better debugging.</p> </li> <li> <p>Sample high-volume metrics: For high-traffic applications, consider sampling metrics to reduce overhead.</p> </li> <li> <p>Separate concerns: Use <code>on_retry</code> for retry-specific metrics, <code>on_success</code> for latency tracking, and <code>on_failure</code> for alerting.</p> </li> </ol>"},{"location":"user_guide/#error-handling","title":"Error Handling","text":""},{"location":"user_guide/#understanding-httprequesterror","title":"Understanding HttpRequestError","text":"<p><code>aresilient</code> raises <code>HttpRequestError</code> when a request fails after all retries:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/data\")\nexcept HttpRequestError as e:\n    print(f\"Request failed: {e}\")\n    print(f\"Method: {e.method}\")  # 'GET'\n    print(f\"URL: {e.url}\")  # 'https://api.example.com/data'\n    print(f\"Status Code: {e.status_code}\")  # e.g., 500\n    if e.response:\n        print(f\"Response body: {e.response.text}\")\n</code></pre>"},{"location":"user_guide/#common-error-scenarios","title":"Common Error Scenarios","text":""},{"location":"user_guide/#timeout-errors","title":"Timeout Errors","text":"<p>When a request times out after all retries:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\n        \"https://slow-api.example.com/data\", timeout=1.0, max_retries=2\n    )\nexcept HttpRequestError as e:\n    # status_code will be None for timeout errors\n    if e.status_code is None:\n        print(\"Request timed out\")\n</code></pre>"},{"location":"user_guide/#network-errors","title":"Network Errors","text":"<p>When the connection fails (DNS errors, connection refused, etc.):</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://nonexistent-domain.invalid\")\nexcept HttpRequestError as e:\n    if e.status_code is None:\n        print(f\"Network error: {e}\")\n</code></pre>"},{"location":"user_guide/#http-error-responses","title":"HTTP Error Responses","text":"<p>When the server returns an error status code:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/not-found\")\nexcept HttpRequestError as e:\n    if e.status_code == 404:\n        print(\"Resource not found\")\n    elif e.status_code == 401:\n        print(\"Unauthorized\")\n    elif e.status_code == 403:\n        print(\"Forbidden\")\n</code></pre>"},{"location":"user_guide/#validating-responses","title":"Validating Responses","text":"<p>Check response status and content:</p> <pre><code>from aresilient import get_with_automatic_retry, HttpRequestError\n\ntry:\n    response = get_with_automatic_retry(\"https://api.example.com/data\")\n\n    # Response is automatically successful (2xx or 3xx)\n    # if we get here\n    data = response.json()\n\n    # Additional validation if needed\n    if \"error\" in data:\n        print(f\"API returned an error: {data['error']}\")\n\nexcept HttpRequestError as e:\n    print(f\"Request failed: {e}\")\nexcept ValueError as e:\n    print(f\"Invalid JSON response: {e}\")\n</code></pre>"},{"location":"user_guide/#error-handling-with-async","title":"Error Handling with Async","text":"<p>Error handling works the same way with async functions:</p> <pre><code>import asyncio\nfrom aresilient import get_with_automatic_retry_async, HttpRequestError\n\n\nasync def fetch_with_error_handling():\n    try:\n        response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n        return response.json()\n    except HttpRequestError as e:\n        print(f\"Async request failed: {e}\")\n        print(f\"Status Code: {e.status_code}\")\n        return None\n\n\nresult = asyncio.run(fetch_with_error_handling())\n</code></pre>"},{"location":"user_guide/#custom-http-methods","title":"Custom HTTP Methods","text":"<p>For HTTP methods not directly supported or for custom needs, use the <code>request_with_automatic_retry</code> and <code>request_with_automatic_retry_async</code> functions.</p>"},{"location":"user_guide/#synchronous-custom-requests","title":"Synchronous Custom Requests","text":"<pre><code>import httpx\nfrom aresilient import request_with_automatic_retry\n\n# Example: Using HEAD method\nwith httpx.Client() as client:\n    response = request_with_automatic_retry(\n        url=\"https://api.example.com/resource\",\n        method=\"HEAD\",\n        request_func=client.head,\n        max_retries=3,\n    )\n    print(f\"Content-Length: {response.headers.get('content-length')}\")\n\n# Example: Using OPTIONS method\nwith httpx.Client() as client:\n    response = request_with_automatic_retry(\n        url=\"https://api.example.com/resource\",\n        method=\"OPTIONS\",\n        request_func=client.options,\n    )\n    print(f\"Allowed methods: {response.headers.get('allow')}\")\n</code></pre>"},{"location":"user_guide/#async-custom-requests","title":"Async Custom Requests","text":"<pre><code>import asyncio\nimport httpx\nfrom aresilient import request_with_automatic_retry_async\n\n\nasync def make_custom_request():\n    async with httpx.AsyncClient() as client:\n        # Using HEAD method asynchronously\n        response = await request_with_automatic_retry_async(\n            url=\"https://api.example.com/resource\",\n            method=\"HEAD\",\n            request_func=client.head,\n            max_retries=3,\n        )\n        return response.headers.get(\"content-length\")\n\n\ncontent_length = asyncio.run(make_custom_request())\n</code></pre>"},{"location":"user_guide/#advanced-custom-request-example","title":"Advanced Custom Request Example","text":"<pre><code>import httpx\nfrom aresilient import request_with_automatic_retry\n\n\ndef custom_api_call():\n    with httpx.Client(timeout=30.0) as client:\n        # Custom request with specific retry configuration\n        response = request_with_automatic_retry(\n            url=\"https://api.example.com/custom-endpoint\",\n            method=\"PATCH\",\n            request_func=client.patch,\n            max_retries=5,\n            backoff_factor=1.0,\n            status_forcelist=(429, 503),\n            # Additional kwargs passed to client.patch\n            json={\"operation\": \"update\", \"value\": 42},\n            headers={\"X-API-Version\": \"2.0\"},\n        )\n        return response.json()\n</code></pre>"},{"location":"user_guide/#best-practices","title":"Best Practices","text":""},{"location":"user_guide/#1-use-appropriate-timeouts","title":"1. Use Appropriate Timeouts","text":"<p>Set timeouts based on your expected response times:</p> <pre><code># Quick health check\nresponse = get_with_automatic_retry(\"https://api.example.com/health\", timeout=5.0)\n\n# Large data download\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/large-dataset\", timeout=120.0\n)\n</code></pre>"},{"location":"user_guide/#2-reuse-http-clients","title":"2. Reuse HTTP Clients","text":"<p>When making multiple requests, reuse the client to benefit from connection pooling:</p> <pre><code>import httpx\nfrom aresilient import get_with_automatic_retry\n\n# Good: Reuse client\nwith httpx.Client() as client:\n    for url in urls:\n        response = get_with_automatic_retry(url, client=client)\n        process_response(response)\n\n# Bad: Creates new client for each request\nfor url in urls:\n    response = get_with_automatic_retry(url)\n    process_response(response)\n</code></pre>"},{"location":"user_guide/#3-adjust-retry-strategy-based-on-use-case","title":"3. Adjust Retry Strategy Based on Use Case","text":"<p>For user-facing operations, use fewer retries for faster failure:</p> <pre><code># User-facing: fail fast\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/user-data\", max_retries=1, timeout=10.0\n)\n</code></pre> <p>For background jobs, use more retries:</p> <pre><code># Background job: be more resilient\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/batch-process\",\n    max_retries=5,\n    backoff_factor=1.0,\n    timeout=60.0,\n)\n</code></pre>"},{"location":"user_guide/#4-handle-rate-limiting-gracefully","title":"4. Handle Rate Limiting Gracefully","text":"<p>If you're hitting rate limits frequently, consider:</p> <pre><code># Increase backoff for rate-limited endpoints\nresponse = get_with_automatic_retry(\n    \"https://api.example.com/rate-limited\",\n    max_retries=5,\n    backoff_factor=2.0,  # Longer waits\n    status_forcelist=(429,),  # Only retry on rate limit\n)\n</code></pre>"},{"location":"user_guide/#5-use-async-for-io-bound-operations","title":"5. Use Async for I/O-Bound Operations","text":"<p>When making multiple HTTP requests, async can significantly improve performance:</p> <pre><code>import asyncio\nimport httpx\nfrom aresilient import get_with_automatic_retry_async\n\n\nasync def fetch_all_data(urls):\n    async with httpx.AsyncClient() as client:\n        tasks = [get_with_automatic_retry_async(url, client=client) for url in urls]\n        responses = await asyncio.gather(*tasks)\n        return [r.json() for r in responses]\n\n\n# Fetch 10 URLs concurrently instead of sequentially\nurls = [f\"https://api.example.com/item/{i}\" for i in range(10)]\nresults = asyncio.run(fetch_all_data(urls))\n</code></pre>"},{"location":"user_guide/#6-choose-between-sync-and-async-based-on-your-application","title":"6. Choose Between Sync and Async Based on Your Application","text":"<p>Use synchronous functions when:</p> <ul> <li>Your application is not using asyncio</li> <li>You're making single, occasional requests</li> <li>Your code is primarily synchronous</li> <li>You're writing simple scripts or command-line tools</li> </ul> <p>Use async functions when:</p> <ul> <li>Your application already uses asyncio</li> <li>You need to make multiple concurrent requests</li> <li>You're building a web application (e.g., FastAPI, Sanic)</li> <li>Performance and scalability are critical</li> </ul> <pre><code># Synchronous example - simple script\nfrom aresilient import get_with_automatic_retry\n\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\nprint(response.json())\n</code></pre> <pre><code># Async example - FastAPI application\nfrom fastapi import FastAPI\nfrom aresilient import get_with_automatic_retry_async\n\napp = FastAPI()\n\n\n@app.get(\"/fetch-data\")\nasync def fetch_data():\n    response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n    return response.json()\n</code></pre>"},{"location":"user_guide/#7-enable-debug-logging-for-troubleshooting","title":"7. Enable Debug Logging for Troubleshooting","text":"<p><code>aresilient</code> uses Python's standard <code>logging</code> module to provide detailed debug information about retries, backoff times, and errors. This can be helpful for troubleshooting issues or understanding retry behavior.</p> <pre><code>import logging\nfrom aresilient import get_with_automatic_retry\n\n# Enable debug logging to see retry details\nlogging.basicConfig(level=logging.DEBUG)\n\n# This will log:\n# - Each retry attempt\n# - Wait times between retries\n# - Whether Retry-After header is being used\n# - Success/failure of each attempt\nresponse = get_with_automatic_retry(\"https://api.example.com/data\")\n</code></pre> <p>Example debug output: <pre><code>DEBUG:aresilient.request:GET request to https://api.example.com/data failed with status 503 (attempt 1/4)\nDEBUG:aresilient.utils:Waiting 0.30s before retry\nDEBUG:aresilient.request:GET request to https://api.example.com/data succeeded on attempt 2\n</code></pre></p> <p>For production use, keep the default log level (INFO or WARNING) to avoid excessive logging.</p>"},{"location":"user_guide/#additional-resources","title":"Additional Resources","text":"<ul> <li>API Reference - Complete API documentation</li> <li>Get Started - Installation and setup instructions</li> <li>httpx Documentation - Learn more about the underlying library</li> </ul>"},{"location":"refs/","title":"Main classes and functions","text":""},{"location":"refs/#aresilient","title":"aresilient","text":"<p>aresilient - Resilient HTTP request library with automatic retry logic.</p> <p>This package provides resilient HTTP request functionality with automatic retry logic and backoff strategies. Built on top of the modern httpx library, it simplifies handling transient failures in HTTP communications, making your applications more robust and fault-tolerant.</p> Key Features <ul> <li>Automatic retry logic for transient HTTP errors (429, 500, 502, 503, 504)</li> <li>Multiple backoff strategies: Exponential, Linear, Fibonacci, Constant, and custom</li> <li>Optional jitter to prevent thundering herd problems</li> <li>Retry-After header support (both integer seconds and HTTP-date formats)</li> <li>Complete HTTP method support (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS)</li> <li>Full async support for high-performance applications</li> <li>Configurable timeout, retry attempts, backoff factors, and jitter</li> <li>Enhanced error handling with detailed exception information</li> <li>Callback/Event system for observability (logging, metrics, alerting)</li> </ul> Example <pre><code>&gt;&gt;&gt; from aresilient import get_with_automatic_retry, LinearBackoff\n&gt;&gt;&gt; # Use default exponential backoff\n&gt;&gt;&gt; response = get_with_automatic_retry(\"https://api.example.com/data\")  # doctest: +SKIP\n&gt;&gt;&gt; # Use linear backoff strategy\n&gt;&gt;&gt; response = get_with_automatic_retry(\n...     \"https://api.example.com/data\", backoff_strategy=LinearBackoff(base_delay=1.0)\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.BackoffStrategy","title":"aresilient.BackoffStrategy","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for backoff strategies.</p> <p>A backoff strategy determines how long to wait before retrying a failed request based on the attempt number and other parameters.</p>"},{"location":"refs/#aresilient.BackoffStrategy.calculate","title":"aresilient.BackoffStrategy.calculate  <code>abstractmethod</code>","text":"<pre><code>calculate(attempt: int) -&gt; float\n</code></pre> <p>Calculate the backoff delay for a given retry attempt.</p> <p>Parameters:</p> Name Type Description Default <code>attempt</code> <code>int</code> <p>The current attempt number (0-indexed). For example, attempt=0 is the first retry, attempt=1 is the second retry, etc.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The calculated delay in seconds before the next retry attempt.</p>"},{"location":"refs/#aresilient.CircuitBreaker","title":"aresilient.CircuitBreaker","text":"<p>Circuit breaker for preventing cascading failures.</p> <p>The circuit breaker pattern stops making requests after consecutive failures to prevent overwhelming a failing service. It has three states:</p> <ul> <li>CLOSED: Normal operation, requests go through</li> <li>OPEN: After N consecutive failures, stop making requests (fail fast)</li> <li>HALF_OPEN: After timeout, try one request to check recovery</li> </ul> <p>Thread-safe implementation using locks.</p> <p>Parameters:</p> Name Type Description Default <code>failure_threshold</code> <code>int</code> <p>Number of consecutive failures before opening the circuit. Must be &gt; 0. Default is 5.</p> <code>5</code> <code>recovery_timeout</code> <code>float</code> <p>Time in seconds to wait in OPEN state before transitioning to HALF_OPEN to test recovery. Must be &gt; 0. Default is 60.0 seconds.</p> <code>60.0</code> <code>expected_exception</code> <code>type[Exception] | tuple[type[Exception], ...] | None</code> <p>Optional exception type or tuple of exception types that should count as failures. If None, any exception counts as a failure. Default is None.</p> <code>None</code> <code>on_state_change</code> <code>Callable[[CircuitState, CircuitState], None] | None</code> <p>Optional callback function called when circuit state changes. Receives (old_state: CircuitState, new_state: CircuitState).</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>state</code> <code>CircuitState</code> <p>Current circuit state (CLOSED, OPEN, or HALF_OPEN).</p> <code>failure_count</code> <code>int</code> <p>Current count of consecutive failures.</p> <code>last_failure_time</code> <code>float | None</code> <p>Timestamp of the last failure (None if no failures).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If failure_threshold or recovery_timeout are invalid.</p> Example <p>Basic usage with default settings:</p> <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreaker\n&gt;&gt;&gt; cb = CircuitBreaker()\n&gt;&gt;&gt; cb.state\n&lt;CircuitState.CLOSED: 'closed'&gt;\n&gt;&gt;&gt; # Simulate failures\n&gt;&gt;&gt; for _ in range(5):\n...     cb.record_failure(Exception(\"error\"))\n...\n&gt;&gt;&gt; cb.state\n&lt;CircuitState.OPEN: 'open'&gt;\n</code></pre> <p>Custom configuration:</p> <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreaker, HttpRequestError\n&gt;&gt;&gt; def on_change(old_state, new_state):\n...     print(f\"Circuit {old_state.value} -&gt; {new_state.value}\")\n...\n&gt;&gt;&gt; cb = CircuitBreaker(\n...     failure_threshold=3,\n...     recovery_timeout=30.0,\n...     expected_exception=HttpRequestError,\n...     on_state_change=on_change,\n... )\n</code></pre> <p>Usage with HTTP requests:</p> <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreaker, get_with_automatic_retry\n&gt;&gt;&gt; circuit_breaker = CircuitBreaker(\n...     failure_threshold=5,\n...     recovery_timeout=60.0,\n... )\n&gt;&gt;&gt; response = get_with_automatic_retry(\n...     \"https://api.example.com/data\",\n...     circuit_breaker=circuit_breaker,\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.CircuitBreaker.failure_count","title":"aresilient.CircuitBreaker.failure_count  <code>property</code>","text":"<pre><code>failure_count: int\n</code></pre> <p>Get the current failure count.</p> <p>Thread-safe property that returns the number of consecutive failures.</p> <p>Returns:</p> Type Description <code>int</code> <p>The current consecutive failure count.</p>"},{"location":"refs/#aresilient.CircuitBreaker.last_failure_time","title":"aresilient.CircuitBreaker.last_failure_time  <code>property</code>","text":"<pre><code>last_failure_time: float | None\n</code></pre> <p>Get the timestamp of the last failure.</p> <p>Thread-safe property that returns when the last failure occurred.</p> <p>Returns:</p> Type Description <code>float | None</code> <p>The timestamp of the last failure, or None if no failures have occurred.</p>"},{"location":"refs/#aresilient.CircuitBreaker.state","title":"aresilient.CircuitBreaker.state  <code>property</code>","text":"<pre><code>state: CircuitState\n</code></pre> <p>Get the current circuit state.</p> <p>Thread-safe property that returns the current state.</p> <p>Returns:</p> Type Description <code>CircuitState</code> <p>The current circuit state (CLOSED, OPEN, or HALF_OPEN).</p>"},{"location":"refs/#aresilient.CircuitBreaker.call","title":"aresilient.CircuitBreaker.call","text":"<pre><code>call(func: Callable[[], object]) -&gt; object\n</code></pre> <p>Execute a function through the circuit breaker.</p> <p>This is the primary method to use when protecting calls with the circuit breaker. It checks the circuit state, executes the function if allowed, and records success or failure.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[[], object]</code> <p>A callable function to execute through the circuit breaker. The function should take no arguments.</p> required <p>Returns:</p> Type Description <code>object</code> <p>The return value from the executed function.</p> <p>Raises:</p> Type Description <code>CircuitBreakerError</code> <p>If the circuit is OPEN and not ready for retry.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreaker\n&gt;&gt;&gt; cb = CircuitBreaker(failure_threshold=3)\n&gt;&gt;&gt; def my_request():\n...     return \"success\"\n...\n&gt;&gt;&gt; result = cb.call(my_request)\n&gt;&gt;&gt; result\n'success'\n</code></pre>"},{"location":"refs/#aresilient.CircuitBreaker.check","title":"aresilient.CircuitBreaker.check","text":"<pre><code>check() -&gt; None\n</code></pre> <p>Check if the circuit allows requests to proceed.</p> <p>This method checks the circuit breaker state and raises an exception if the circuit is OPEN. If the recovery timeout has elapsed, it transitions to HALF_OPEN state to allow a test request.</p> <p>Raises:</p> Type Description <code>CircuitBreakerError</code> <p>If the circuit is OPEN and recovery timeout has not elapsed.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreaker\n&gt;&gt;&gt; cb = CircuitBreaker(failure_threshold=2)\n&gt;&gt;&gt; cb.check()  # Passes when circuit is CLOSED\n&gt;&gt;&gt; cb.record_failure(Exception(\"error\"))\n&gt;&gt;&gt; cb.record_failure(Exception(\"error\"))\n&gt;&gt;&gt; cb.check()  # Raises CircuitBreakerError when circuit is OPEN\nTraceback (most recent call last):\n    ...\naresilient.circuit_breaker.CircuitBreakerError: Circuit breaker is OPEN...\n</code></pre>"},{"location":"refs/#aresilient.CircuitBreaker.record_failure","title":"aresilient.CircuitBreaker.record_failure","text":"<pre><code>record_failure(exception: Exception) -&gt; None\n</code></pre> <p>Record a failed request.</p> <p>Increments the failure count and opens the circuit if threshold is reached. Thread-safe.</p> <p>Parameters:</p> Name Type Description Default <code>exception</code> <code>Exception</code> <p>The exception that caused the failure. If expected_exception was configured, only matching exceptions will count as failures.</p> required Example <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreaker\n&gt;&gt;&gt; cb = CircuitBreaker(failure_threshold=2)\n&gt;&gt;&gt; cb.record_failure(Exception(\"error\"))\n&gt;&gt;&gt; cb.failure_count\n1\n&gt;&gt;&gt; cb.state\n&lt;CircuitState.CLOSED: 'closed'&gt;\n&gt;&gt;&gt; cb.record_failure(Exception(\"error\"))\n&gt;&gt;&gt; cb.state\n&lt;CircuitState.OPEN: 'open'&gt;\n</code></pre>"},{"location":"refs/#aresilient.CircuitBreaker.record_success","title":"aresilient.CircuitBreaker.record_success","text":"<pre><code>record_success() -&gt; None\n</code></pre> <p>Record a successful request.</p> <p>Resets the failure count and closes the circuit if it was HALF_OPEN. Thread-safe.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreaker\n&gt;&gt;&gt; cb = CircuitBreaker()\n&gt;&gt;&gt; cb.record_success()\n&gt;&gt;&gt; cb.failure_count\n0\n&gt;&gt;&gt; cb.state\n&lt;CircuitState.CLOSED: 'closed'&gt;\n</code></pre>"},{"location":"refs/#aresilient.CircuitBreaker.reset","title":"aresilient.CircuitBreaker.reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Manually reset the circuit breaker to CLOSED state.</p> <p>Resets failure count and closes the circuit. Use with caution in production - typically you want the circuit to recover naturally. Thread-safe.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreaker\n&gt;&gt;&gt; cb = CircuitBreaker(failure_threshold=1)\n&gt;&gt;&gt; cb.record_failure(Exception(\"error\"))\n&gt;&gt;&gt; cb.state\n&lt;CircuitState.OPEN: 'open'&gt;\n&gt;&gt;&gt; cb.reset()\n&gt;&gt;&gt; cb.state\n&lt;CircuitState.CLOSED: 'closed'&gt;\n&gt;&gt;&gt; cb.failure_count\n0\n</code></pre>"},{"location":"refs/#aresilient.CircuitBreakerError","title":"aresilient.CircuitBreakerError","text":"<p>               Bases: <code>RuntimeError</code></p> <p>Exception raised when circuit breaker is open.</p> <p>This exception is raised when attempting to make a request while the circuit breaker is in the OPEN state, preventing the request from being attempted to protect the failing service.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>A descriptive error message.</p> required Example <pre><code>&gt;&gt;&gt; from aresilient import CircuitBreakerError\n&gt;&gt;&gt; raise CircuitBreakerError(\"Circuit breaker is open\")\nTraceback (most recent call last):\n    ...\naresilient.circuit_breaker.CircuitBreakerError: Circuit breaker is open\n</code></pre>"},{"location":"refs/#aresilient.CircuitState","title":"aresilient.CircuitState","text":"<p>               Bases: <code>Enum</code></p> <p>Circuit breaker states.</p> <p>Attributes:</p> Name Type Description <code>CLOSED</code> <p>Normal operation, requests are allowed.</p> <code>OPEN</code> <p>Circuit is open, requests fail fast without being attempted.</p> <code>HALF_OPEN</code> <p>Testing if service recovered, allows one test request.</p>"},{"location":"refs/#aresilient.ConstantBackoff","title":"aresilient.ConstantBackoff","text":"<p>               Bases: <code>BackoffStrategy</code></p> <p>Constant/fixed backoff strategy.</p> <p>Returns the same delay for every retry attempt, regardless of the attempt number.</p> <p>This strategy is useful for testing or when you know the exact delay that works best for a particular service.</p> <p>Parameters:</p> Name Type Description Default <code>delay</code> <code>float</code> <p>The fixed delay in seconds to use for all retry attempts (default: 1.0).</p> <code>1.0</code> Example <pre><code>&gt;&gt;&gt; from aresilient.backoff import ConstantBackoff\n&gt;&gt;&gt; backoff = ConstantBackoff(delay=2.5)\n&gt;&gt;&gt; backoff.calculate(0)  # First retry\n2.5\n&gt;&gt;&gt; backoff.calculate(1)  # Second retry\n2.5\n&gt;&gt;&gt; backoff.calculate(10)  # Tenth retry\n2.5\n</code></pre>"},{"location":"refs/#aresilient.ConstantBackoff.__init__","title":"aresilient.ConstantBackoff.__init__","text":"<pre><code>__init__(delay: float = 1.0) -&gt; None\n</code></pre> <p>Initialize constant backoff strategy.</p> <p>Parameters:</p> Name Type Description Default <code>delay</code> <code>float</code> <p>The fixed delay in seconds (default: 1.0).</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If delay is negative.</p>"},{"location":"refs/#aresilient.ConstantBackoff.calculate","title":"aresilient.ConstantBackoff.calculate","text":"<pre><code>calculate(attempt: int) -&gt; float\n</code></pre> <p>Calculate constant backoff delay.</p> <p>Parameters:</p> Name Type Description Default <code>attempt</code> <code>int</code> <p>The current attempt number (0-indexed, unused).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The fixed delay value.</p>"},{"location":"refs/#aresilient.ExponentialBackoff","title":"aresilient.ExponentialBackoff","text":"<p>               Bases: <code>BackoffStrategy</code></p> <p>Exponential backoff strategy.</p> <p>Calculates delay as: base_delay * (2 ** attempt), with optional max_delay cap.</p> <p>This is the default backoff strategy and works well for most scenarios where you want progressively longer delays between retries.</p> <p>Parameters:</p> Name Type Description Default <code>base_delay</code> <code>float</code> <p>The base delay factor (default: 0.3). The actual delay is calculated as base_delay * (2 ** attempt).</p> <code>0.3</code> <code>max_delay</code> <code>float | None</code> <p>Optional maximum delay cap in seconds. If specified, delays will not exceed this value.</p> <code>None</code> Example <pre><code>&gt;&gt;&gt; from aresilient.backoff import ExponentialBackoff\n&gt;&gt;&gt; backoff = ExponentialBackoff(base_delay=0.3)\n&gt;&gt;&gt; backoff.calculate(0)  # First retry\n0.3\n&gt;&gt;&gt; backoff.calculate(1)  # Second retry\n0.6\n&gt;&gt;&gt; backoff.calculate(2)  # Third retry\n1.2\n&gt;&gt;&gt; # With max_delay cap\n&gt;&gt;&gt; backoff = ExponentialBackoff(base_delay=1.0, max_delay=5.0)\n&gt;&gt;&gt; backoff.calculate(10)  # Would be 1024.0, but capped\n5.0\n</code></pre>"},{"location":"refs/#aresilient.ExponentialBackoff.__init__","title":"aresilient.ExponentialBackoff.__init__","text":"<pre><code>__init__(\n    base_delay: float = 0.3, max_delay: float | None = None\n) -&gt; None\n</code></pre> <p>Initialize exponential backoff strategy.</p> <p>Parameters:</p> Name Type Description Default <code>base_delay</code> <code>float</code> <p>The base delay factor (default: 0.3).</p> <code>0.3</code> <code>max_delay</code> <code>float | None</code> <p>Optional maximum delay cap in seconds.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If base_delay is negative or max_delay is non-positive.</p>"},{"location":"refs/#aresilient.ExponentialBackoff.calculate","title":"aresilient.ExponentialBackoff.calculate","text":"<pre><code>calculate(attempt: int) -&gt; float\n</code></pre> <p>Calculate exponential backoff delay.</p> <p>Parameters:</p> Name Type Description Default <code>attempt</code> <code>int</code> <p>The current attempt number (0-indexed).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The calculated delay: base_delay * (2 ** attempt), capped at max_delay if set.</p>"},{"location":"refs/#aresilient.FailureInfo","title":"aresilient.FailureInfo  <code>dataclass</code>","text":"<p>Information passed to on_failure callback.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL that was requested.</p> <code>method</code> <code>str</code> <p>The HTTP method (e.g., \"GET\", \"POST\").</p> <code>attempt</code> <code>int</code> <p>The final attempt number (1-indexed).</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts configured.</p> <code>error</code> <code>Exception</code> <p>The final exception that caused the failure.</p> <code>status_code</code> <code>int | None</code> <p>The final HTTP status code (if any).</p> <code>total_time</code> <code>float</code> <p>Total time spent on all attempts including backoff (seconds).</p>"},{"location":"refs/#aresilient.FibonacciBackoff","title":"aresilient.FibonacciBackoff","text":"<p>               Bases: <code>BackoffStrategy</code></p> <p>Fibonacci backoff strategy.</p> <p>Calculates delay as: base_delay * fibonacci(attempt + 1), with optional max_delay cap.</p> <p>This strategy provides a middle ground between linear and exponential backoff, starting slow and ramping up gradually. The Fibonacci sequence (1, 1, 2, 3, 5, 8, 13, ...) provides a more gradual increase than exponential backoff.</p> <p>Parameters:</p> Name Type Description Default <code>base_delay</code> <code>float</code> <p>The base delay in seconds (default: 1.0). The actual delay is calculated as base_delay * fibonacci(attempt + 1).</p> <code>1.0</code> <code>max_delay</code> <code>float | None</code> <p>Optional maximum delay cap in seconds. If specified, delays will not exceed this value.</p> <code>None</code> Example <pre><code>&gt;&gt;&gt; from aresilient.backoff import FibonacciBackoff\n&gt;&gt;&gt; backoff = FibonacciBackoff(base_delay=1.0)\n&gt;&gt;&gt; backoff.calculate(0)  # First retry: 1.0 * fib(1) = 1.0\n1.0\n&gt;&gt;&gt; backoff.calculate(1)  # Second retry: 1.0 * fib(2) = 1.0\n1.0\n&gt;&gt;&gt; backoff.calculate(2)  # Third retry: 1.0 * fib(3) = 2.0\n2.0\n&gt;&gt;&gt; backoff.calculate(3)  # Fourth retry: 1.0 * fib(4) = 3.0\n3.0\n&gt;&gt;&gt; backoff.calculate(4)  # Fifth retry: 1.0 * fib(5) = 5.0\n5.0\n&gt;&gt;&gt; # With max_delay cap\n&gt;&gt;&gt; backoff = FibonacciBackoff(base_delay=1.0, max_delay=10.0)\n&gt;&gt;&gt; backoff.calculate(10)  # fib(11) = 89, would be 89.0, but capped\n10.0\n</code></pre>"},{"location":"refs/#aresilient.FibonacciBackoff.__init__","title":"aresilient.FibonacciBackoff.__init__","text":"<pre><code>__init__(\n    base_delay: float = 1.0, max_delay: float | None = None\n) -&gt; None\n</code></pre> <p>Initialize Fibonacci backoff strategy.</p> <p>Parameters:</p> Name Type Description Default <code>base_delay</code> <code>float</code> <p>The base delay in seconds (default: 1.0).</p> <code>1.0</code> <code>max_delay</code> <code>float | None</code> <p>Optional maximum delay cap in seconds.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If base_delay is negative or max_delay is non-positive.</p>"},{"location":"refs/#aresilient.FibonacciBackoff.calculate","title":"aresilient.FibonacciBackoff.calculate","text":"<pre><code>calculate(attempt: int) -&gt; float\n</code></pre> <p>Calculate Fibonacci backoff delay.</p> <p>Parameters:</p> Name Type Description Default <code>attempt</code> <code>int</code> <p>The current attempt number (0-indexed).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The calculated delay: base_delay * fibonacci(attempt + 1), capped at max_delay if set.</p>"},{"location":"refs/#aresilient.HttpRequestError","title":"aresilient.HttpRequestError","text":"<p>               Bases: <code>RuntimeError</code></p> <p>Exception raised when an HTTP request fails.</p> <p>This exception captures comprehensive details about failed HTTP requests, including the request method, URL, status code, and the full response object when available. It supports exception chaining to preserve the original cause of the error.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>The HTTP method used for the request (e.g., 'GET', 'POST').</p> required <code>url</code> <code>str</code> <p>The target URL that was requested.</p> required <code>message</code> <code>str</code> <p>A descriptive error message explaining the failure.</p> required <code>status_code</code> <code>int | None</code> <p>The HTTP status code returned by the server, if the request reached the server. Defaults to <code>None</code> if the request failed before receiving a response.</p> <code>None</code> <code>response</code> <code>Response | None</code> <p>The complete httpx.Response object containing headers, body, and other response details. Defaults to <code>None</code> if no response was received.</p> <code>None</code> <code>cause</code> <code>BaseException | None</code> <p>The original exception that caused this error, used for exception chaining. Defaults to <code>None</code>.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>method</code> <code>str</code> <p>The HTTP method used for the request.</p> <code>url</code> <code>str</code> <p>The target URL that was requested.</p> <code>status_code</code> <code>int | None</code> <p>The HTTP status code, if available.</p> <code>response</code> <code>Response | None</code> <p>The full response object, if available.</p> <p>Examples:</p> <p>Raising an error for a failed GET request:</p> <pre><code>&gt;&gt;&gt; from aresilient import HttpRequestError\n&gt;&gt;&gt; raise HttpRequestError(\n...     method=\"GET\",\n...     url=\"https://api.example.com/data\",\n...     message=\"Request failed with status 404\",\n...     status_code=404,\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.LinearBackoff","title":"aresilient.LinearBackoff","text":"<p>               Bases: <code>BackoffStrategy</code></p> <p>Linear backoff strategy.</p> <p>Calculates delay as: base_delay * (attempt + 1), with optional max_delay cap.</p> <p>This strategy provides evenly spaced retry delays, which can be useful for services that recover quickly or when you want predictable timing.</p> <p>Parameters:</p> Name Type Description Default <code>base_delay</code> <code>float</code> <p>The base delay in seconds (default: 1.0). The actual delay is calculated as base_delay * (attempt + 1).</p> <code>1.0</code> <code>max_delay</code> <code>float | None</code> <p>Optional maximum delay cap in seconds. If specified, delays will not exceed this value.</p> <code>None</code> Example <pre><code>&gt;&gt;&gt; from aresilient.backoff import LinearBackoff\n&gt;&gt;&gt; backoff = LinearBackoff(base_delay=1.0)\n&gt;&gt;&gt; backoff.calculate(0)  # First retry: 1.0 * 1\n1.0\n&gt;&gt;&gt; backoff.calculate(1)  # Second retry: 1.0 * 2\n2.0\n&gt;&gt;&gt; backoff.calculate(2)  # Third retry: 1.0 * 3\n3.0\n&gt;&gt;&gt; # With max_delay cap\n&gt;&gt;&gt; backoff = LinearBackoff(base_delay=2.0, max_delay=5.0)\n&gt;&gt;&gt; backoff.calculate(5)  # Would be 12.0, but capped\n5.0\n</code></pre>"},{"location":"refs/#aresilient.LinearBackoff.__init__","title":"aresilient.LinearBackoff.__init__","text":"<pre><code>__init__(\n    base_delay: float = 1.0, max_delay: float | None = None\n) -&gt; None\n</code></pre> <p>Initialize linear backoff strategy.</p> <p>Parameters:</p> Name Type Description Default <code>base_delay</code> <code>float</code> <p>The base delay in seconds (default: 1.0).</p> <code>1.0</code> <code>max_delay</code> <code>float | None</code> <p>Optional maximum delay cap in seconds.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If base_delay is negative or max_delay is non-positive.</p>"},{"location":"refs/#aresilient.LinearBackoff.calculate","title":"aresilient.LinearBackoff.calculate","text":"<pre><code>calculate(attempt: int) -&gt; float\n</code></pre> <p>Calculate linear backoff delay.</p> <p>Parameters:</p> Name Type Description Default <code>attempt</code> <code>int</code> <p>The current attempt number (0-indexed).</p> required <p>Returns:</p> Type Description <code>float</code> <p>The calculated delay: base_delay * (attempt + 1), capped at max_delay if set.</p>"},{"location":"refs/#aresilient.RequestInfo","title":"aresilient.RequestInfo  <code>dataclass</code>","text":"<p>Information passed to on_request callback.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL being requested.</p> <code>method</code> <code>str</code> <p>The HTTP method (e.g., \"GET\", \"POST\").</p> <code>attempt</code> <code>int</code> <p>The current attempt number (1-indexed). First attempt is 1.</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts configured.</p>"},{"location":"refs/#aresilient.ResponseInfo","title":"aresilient.ResponseInfo  <code>dataclass</code>","text":"<p>Information passed to on_success callback.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL that was requested.</p> <code>method</code> <code>str</code> <p>The HTTP method (e.g., \"GET\", \"POST\").</p> <code>attempt</code> <code>int</code> <p>The attempt number that succeeded (1-indexed).</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts configured.</p> <code>response</code> <code>Response</code> <p>The successful HTTP response object.</p> <code>total_time</code> <code>float</code> <p>Total time spent on all attempts including backoff (seconds).</p>"},{"location":"refs/#aresilient.RetryInfo","title":"aresilient.RetryInfo  <code>dataclass</code>","text":"<p>Information passed to on_retry callback.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The URL being requested.</p> <code>method</code> <code>str</code> <p>The HTTP method (e.g., \"GET\", \"POST\").</p> <code>attempt</code> <code>int</code> <p>The current attempt number (1-indexed). First retry is attempt 2.</p> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts configured.</p> <code>wait_time</code> <code>float</code> <p>The sleep time in seconds before this retry.</p> <code>error</code> <code>Exception | None</code> <p>The exception that triggered the retry (if any).</p> <code>status_code</code> <code>int | None</code> <p>The HTTP status code that triggered the retry (if any).</p>"},{"location":"refs/#aresilient.delete_with_automatic_retry","title":"aresilient.delete_with_automatic_retry","text":"<pre><code>delete_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP DELETE request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP DELETE request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the DELETE request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.delete()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import delete_with_automatic_retry\n&gt;&gt;&gt; response = delete_with_automatic_retry(\n...     \"https://api.example.com/resource/123\"\n... )  # doctest: +SKIP\n&gt;&gt;&gt; response.status_code  # doctest: +SKIP\n204\n</code></pre>"},{"location":"refs/#aresilient.delete_with_automatic_retry_async","title":"aresilient.delete_with_automatic_retry_async  <code>async</code>","text":"<pre><code>delete_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP DELETE request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP DELETE request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the DELETE request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.delete()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import delete_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await delete_with_automatic_retry_async(\n...         \"https://api.example.com/resource/123\"\n...     )\n...     return response.status_code\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.get_with_automatic_retry","title":"aresilient.get_with_automatic_retry","text":"<pre><code>get_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP GET request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP GET request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.get()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import get_with_automatic_retry\n&gt;&gt;&gt; response = get_with_automatic_retry(\"https://api.example.com/data\")  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.get_with_automatic_retry_async","title":"aresilient.get_with_automatic_retry_async  <code>async</code>","text":"<pre><code>get_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP GET request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP GET request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the GET request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.get()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import get_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await get_with_automatic_retry_async(\"https://api.example.com/data\")\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.head_with_automatic_retry","title":"aresilient.head_with_automatic_retry","text":"<pre><code>head_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP HEAD request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP HEAD request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>HEAD requests retrieve only the headers without the response body, making them useful for checking resource existence, metadata, ETags, content length, and performing lightweight validation without downloading data.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the HEAD request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.head()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response headers.</p> <code>Response</code> <p>The response body will be empty.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import head_with_automatic_retry\n&gt;&gt;&gt; # Check if a resource exists and get metadata\n&gt;&gt;&gt; response = head_with_automatic_retry(\n...     \"https://api.example.com/large-file.zip\"\n... )  # doctest: +SKIP\n&gt;&gt;&gt; if response.status_code == 200:  # doctest: +SKIP\n...     print(f\"Content-Length: {response.headers.get('Content-Length')}\")  # doctest: +SKIP\n...     print(f\"Last-Modified: {response.headers.get('Last-Modified')}\")  # doctest: +SKIP\n...\n</code></pre>"},{"location":"refs/#aresilient.head_with_automatic_retry_async","title":"aresilient.head_with_automatic_retry_async  <code>async</code>","text":"<pre><code>head_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP HEAD request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP HEAD request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>HEAD requests retrieve only the headers without the response body, making them useful for checking resource existence, metadata, ETags, content length, and performing lightweight validation without downloading data.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the HEAD request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.head()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response headers.</p> <code>Response</code> <p>The response body will be empty.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import head_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await head_with_automatic_retry_async(\n...         \"https://api.example.com/large-file.zip\"\n...     )\n...     if response.status_code == 200:\n...         print(f\"Content-Length: {response.headers.get('Content-Length')}\")\n...     return response\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.options_with_automatic_retry","title":"aresilient.options_with_automatic_retry","text":"<pre><code>options_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP OPTIONS request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP OPTIONS request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>OPTIONS requests are used to describe communication options for a target resource, including CORS preflight requests, discovering allowed HTTP methods via the Allow header, and querying server capabilities.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the OPTIONS request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.options()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response with</p> <code>Response</code> <p>communication options in headers (e.g., Allow, Access-Control-Allow-*).</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import options_with_automatic_retry\n&gt;&gt;&gt; # Check allowed HTTP methods for a resource\n&gt;&gt;&gt; response = options_with_automatic_retry(\n...     \"https://api.example.com/resource\"\n... )  # doctest: +SKIP\n&gt;&gt;&gt; allowed_methods = response.headers.get(\"Allow\")  # doctest: +SKIP\n&gt;&gt;&gt; print(f\"Allowed methods: {allowed_methods}\")  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.options_with_automatic_retry_async","title":"aresilient.options_with_automatic_retry_async  <code>async</code>","text":"<pre><code>options_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP OPTIONS request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP OPTIONS request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>OPTIONS requests are used to describe communication options for a target resource, including CORS preflight requests, discovering allowed HTTP methods via the Allow header, and querying server capabilities.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the OPTIONS request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.options()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response with</p> <code>Response</code> <p>communication options in headers (e.g., Allow, Access-Control-Allow-*).</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import options_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await options_with_automatic_retry_async(\n...         \"https://api.example.com/resource\"\n...     )\n...     allowed_methods = response.headers.get(\"Allow\")\n...     print(f\"Allowed methods: {allowed_methods}\")\n...     return response\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.patch_with_automatic_retry","title":"aresilient.patch_with_automatic_retry","text":"<pre><code>patch_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PATCH request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PATCH request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PATCH request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.patch()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import patch_with_automatic_retry\n&gt;&gt;&gt; response = patch_with_automatic_retry(\n...     \"https://api.example.com/resource/123\", json={\"status\": \"active\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.patch_with_automatic_retry_async","title":"aresilient.patch_with_automatic_retry_async  <code>async</code>","text":"<pre><code>patch_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PATCH request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PATCH request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PATCH request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.patch()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import patch_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await patch_with_automatic_retry_async(\n...         \"https://api.example.com/resource/123\", json={\"status\": \"updated\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.post_with_automatic_retry","title":"aresilient.post_with_automatic_retry","text":"<pre><code>post_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP POST request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP POST request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the POST request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.post()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import post_with_automatic_retry\n&gt;&gt;&gt; response = post_with_automatic_retry(\n...     \"https://api.example.com/data\", json={\"key\": \"value\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.post_with_automatic_retry_async","title":"aresilient.post_with_automatic_retry_async  <code>async</code>","text":"<pre><code>post_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP POST request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP POST request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the POST request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.post()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import post_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await post_with_automatic_retry_async(\n...         \"https://api.example.com/data\", json={\"key\": \"value\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.put_with_automatic_retry","title":"aresilient.put_with_automatic_retry","text":"<pre><code>put_with_automatic_retry(\n    url: str,\n    *,\n    client: Client | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PUT request with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PUT request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PUT request to.</p> required <code>client</code> <code>Client | None</code> <p>An optional httpx.Client object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.Client.put()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; from aresilient import put_with_automatic_retry\n&gt;&gt;&gt; response = put_with_automatic_retry(\n...     \"https://api.example.com/resource/123\", json={\"name\": \"updated\"}\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.put_with_automatic_retry_async","title":"aresilient.put_with_automatic_retry_async  <code>async</code>","text":"<pre><code>put_with_automatic_retry_async(\n    url: str,\n    *,\n    client: AsyncClient | None = None,\n    timeout: float | Timeout = DEFAULT_TIMEOUT,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Send an HTTP PUT request asynchronously with automatic retry logic for transient errors.</p> <p>This function performs an HTTP PUT request with a configured retry policy for transient server errors (429, 500, 502, 503, 504). It applies a backoff retry strategy (exponential by default). The function validates the HTTP response and raises detailed errors for failures.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the PUT request to.</p> required <code>client</code> <code>AsyncClient | None</code> <p>An optional httpx.AsyncClient object to use for making requests. If None, a new client will be created and closed after use.</p> <code>None</code> <code>timeout</code> <code>float | Timeout</code> <p>Maximum seconds to wait for the server response. Only used if client is None. Must be &gt; 0.</p> <code>DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is the 0-indexed retry number (0, 1, 2, ...). Must be &gt;= 0. Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues. Must be &gt;= 0.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to <code>httpx.AsyncClient.put()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> <code>ValueError</code> <p>If max_retries, backoff_factor, or jitter_factor are negative, or if timeout, max_total_time, or max_wait_time are non-positive.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; from aresilient import put_with_automatic_retry_async\n&gt;&gt;&gt; async def example():\n...     response = await put_with_automatic_retry_async(\n...         \"https://api.example.com/resource\", json={\"key\": \"value\"}\n...     )\n...     return response.json()\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"},{"location":"refs/#aresilient.request_with_automatic_retry","title":"aresilient.request_with_automatic_retry","text":"<pre><code>request_with_automatic_retry(\n    url: str,\n    method: str,\n    request_func: Callable[..., Response],\n    *,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    circuit_breaker: CircuitBreaker | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Perform an HTTP request with automatic retry logic.</p> <p>This function implements a retry mechanism with exponential backoff for handling transient HTTP errors. It attempts the request up to max_retries + 1 times, waiting progressively longer between each retry.</p> <p>The retry logic handles three types of failures: 1. Retryable HTTP status codes (e.g., 429, 500, 502, 503, 504) 2. Timeout exceptions (httpx.TimeoutException) 3. General network errors (httpx.RequestError)</p> <p>Backoff Strategy: - Default: Exponential backoff: backoff_factor * (2 ** attempt) - Custom: Use backoff_strategy parameter for alternative strategies   (Linear, Fibonacci, Constant, or custom implementations) - Jitter: Optional randomization added to prevent thundering herd - Retry-After header: If present in the response (429/503), the server's   suggested wait time is used instead of backoff calculation</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the request to.</p> required <code>method</code> <code>str</code> <p>The HTTP method name (e.g., \"GET\", \"POST\") for logging.</p> required <code>request_func</code> <code>Callable[..., Response]</code> <p>The function to call to make the request (e.g., client.get, client.post).</p> required <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is 0-indexed (0, 1, 2, ...). Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>circuit_breaker</code> <code>CircuitBreaker | None</code> <p>Optional CircuitBreaker instance to use for preventing cascading failures. When provided, the circuit breaker will track failures and stop making requests if the failure threshold is reached, transitioning to an OPEN state where requests fail fast. After a recovery timeout, it will transition to HALF_OPEN to test if the service has recovered.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the request function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> Example <pre><code>&gt;&gt;&gt; import httpx\n&gt;&gt;&gt; from aresilient import request_with_automatic_retry\n&gt;&gt;&gt; from aresilient import LinearBackoff\n&gt;&gt;&gt; def log_retry(info):\n...     print(f\"Retry {info.attempt}/{info.max_retries + 1}\")\n...\n&gt;&gt;&gt; with httpx.Client() as client:\n...     response = request_with_automatic_retry(\n...         url=\"https://api.example.com/data\",\n...         method=\"GET\",\n...         request_func=client.get,\n...         max_retries=5,\n...         backoff_strategy=LinearBackoff(base_delay=1.0),\n...         jitter_factor=0.1,  # Add 10% jitter\n...         max_total_time=30.0,  # Stop after 30s total\n...         max_wait_time=5.0,  # Cap backoff at 5s max\n...         on_retry=log_retry,\n...     )  # doctest: +SKIP\n...\n</code></pre>"},{"location":"refs/#aresilient.request_with_automatic_retry_async","title":"aresilient.request_with_automatic_retry_async  <code>async</code>","text":"<pre><code>request_with_automatic_retry_async(\n    url: str,\n    method: str,\n    request_func: Callable[..., Awaitable[Response]],\n    *,\n    max_retries: int = DEFAULT_MAX_RETRIES,\n    backoff_factor: float = DEFAULT_BACKOFF_FACTOR,\n    status_forcelist: tuple[int, ...] = RETRY_STATUS_CODES,\n    jitter_factor: float = 0.0,\n    retry_if: (\n        Callable[[Response | None, Exception | None], bool]\n        | None\n    ) = None,\n    backoff_strategy: BackoffStrategy | None = None,\n    max_total_time: float | None = None,\n    max_wait_time: float | None = None,\n    circuit_breaker: CircuitBreaker | None = None,\n    on_request: Callable[[RequestInfo], None] | None = None,\n    on_retry: Callable[[RetryInfo], None] | None = None,\n    on_success: (\n        Callable[[ResponseInfo], None] | None\n    ) = None,\n    on_failure: Callable[[FailureInfo], None] | None = None,\n    **kwargs: Any\n) -&gt; Response\n</code></pre> <p>Perform an async HTTP request with automatic retry logic.</p> <p>This function implements a retry mechanism with exponential backoff for handling transient HTTP errors. It attempts the request up to max_retries + 1 times, waiting progressively longer between each retry.</p> <p>The retry logic handles three types of failures: 1. Retryable HTTP status codes (e.g., 429, 500, 502, 503, 504) 2. Timeout exceptions (httpx.TimeoutException) 3. General network errors (httpx.RequestError)</p> <p>Backoff Strategy: - Default: Exponential backoff: backoff_factor * (2 ** attempt) - Custom: Use backoff_strategy parameter for alternative strategies   (Linear, Fibonacci, Constant, or custom implementations) - Jitter: Optional randomization added to prevent thundering herd - Retry-After header: If present in the response (429/503), the server's   suggested wait time is used instead of backoff calculation</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to send the request to.</p> required <code>method</code> <code>str</code> <p>The HTTP method name (e.g., \"GET\", \"POST\") for logging.</p> required <code>request_func</code> <code>Callable[..., Awaitable[Response]]</code> <p>The async function to call to make the request (e.g., client.get, client.post).</p> required <code>max_retries</code> <code>int</code> <p>Maximum number of retry attempts for failed requests. Must be &gt;= 0.</p> <code>DEFAULT_MAX_RETRIES</code> <code>backoff_factor</code> <code>float</code> <p>Factor for exponential backoff between retries. The wait time is calculated as: backoff_factor * (2 ** attempt) seconds, where attempt is 0-indexed (0, 1, 2, ...). Ignored if backoff_strategy is provided.</p> <code>DEFAULT_BACKOFF_FACTOR</code> <code>status_forcelist</code> <code>tuple[int, ...]</code> <p>Tuple of HTTP status codes that should trigger a retry.</p> <code>RETRY_STATUS_CODES</code> <code>jitter_factor</code> <code>float</code> <p>Factor for adding random jitter to backoff delays. The jitter is calculated as: random.uniform(0, jitter_factor) * base_sleep_time, and this jitter is ADDED to the base sleep time. Set to 0 to disable jitter (default). Recommended value is 0.1 for 10% jitter to prevent thundering herd issues.</p> <code>0.0</code> <code>retry_if</code> <code>Callable[[Response | None, Exception | None], bool] | None</code> <p>Optional custom predicate function to determine whether to retry based on the response or exception. Called with (response, exception) where at least one will be non-None. Should return True to retry, False to not retry. If provided, this takes precedence over status_forcelist for determining retry behavior.</p> <code>None</code> <code>backoff_strategy</code> <code>BackoffStrategy | None</code> <p>Optional custom backoff strategy (e.g., LinearBackoff, FibonacciBackoff, ConstantBackoff, or custom BackoffStrategy implementation). If provided, this strategy's calculate() method will be used instead of the default exponential backoff. The backoff_factor parameter is ignored when a custom strategy is provided.</p> <code>None</code> <code>max_total_time</code> <code>float | None</code> <p>Optional maximum total time budget in seconds for all retry attempts. If the total elapsed time exceeds this value, the retry loop will stop and raise an error even if max_retries has not been reached. Must be &gt; 0 if provided. Useful for enforcing strict SLA guarantees.</p> <code>None</code> <code>max_wait_time</code> <code>float | None</code> <p>Optional maximum backoff delay cap in seconds. Individual backoff delays will not exceed this value, even with exponential backoff growth or Retry-After headers. Must be &gt; 0 if provided. Useful for preventing very long waits in exponential backoff scenarios.</p> <code>None</code> <code>circuit_breaker</code> <code>CircuitBreaker | None</code> <p>Optional CircuitBreaker instance to use for preventing cascading failures. When provided, the circuit breaker will track failures and stop making requests if the failure threshold is reached, transitioning to an OPEN state where requests fail fast. After a recovery timeout, it will transition to HALF_OPEN to test if the service has recovered.</p> <code>None</code> <code>on_request</code> <code>Callable[[RequestInfo], None] | None</code> <p>Optional callback called before each request attempt. Receives RequestInfo with url, method, attempt, max_retries.</p> <code>None</code> <code>on_retry</code> <code>Callable[[RetryInfo], None] | None</code> <p>Optional callback called before each retry (after backoff). Receives RetryInfo with url, method, attempt, max_retries, wait_time, error, status_code.</p> <code>None</code> <code>on_success</code> <code>Callable[[ResponseInfo], None] | None</code> <p>Optional callback called when request succeeds. Receives ResponseInfo with url, method, attempt, max_retries, response, total_time.</p> <code>None</code> <code>on_failure</code> <code>Callable[[FailureInfo], None] | None</code> <p>Optional callback called when all retries are exhausted. Receives FailureInfo with url, method, attempt, max_retries, error, status_code, total_time.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to the request function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Response</code> <p>An httpx.Response object containing the server's HTTP response.</p> <p>Raises:</p> Type Description <code>HttpRequestError</code> <p>If the request times out, encounters network errors, or fails after exhausting all retries, or if max_total_time is exceeded.</p> Example <pre><code>&gt;&gt;&gt; import asyncio\n&gt;&gt;&gt; import httpx\n&gt;&gt;&gt; from aresilient import request_with_automatic_retry_async\n&gt;&gt;&gt; from aresilient import LinearBackoff\n&gt;&gt;&gt; def log_retry(info):\n...     print(f\"Retry {info.attempt}/{info.max_retries + 1}\")\n...\n&gt;&gt;&gt; async def example():\n...     async with httpx.AsyncClient() as client:\n...         response = await request_with_automatic_retry_async(\n...             url=\"https://api.example.com/data\",\n...             method=\"GET\",\n...             request_func=client.get,\n...             max_retries=5,\n...             backoff_strategy=LinearBackoff(base_delay=1.0),\n...             jitter_factor=0.1,  # Add 10% jitter\n...             max_total_time=30.0,  # Stop after 30s total\n...             max_wait_time=5.0,  # Cap backoff at 5s max\n...             on_retry=log_retry,\n...         )\n...         return response.status_code\n...\n&gt;&gt;&gt; asyncio.run(example())  # doctest: +SKIP\n</code></pre>"}]}